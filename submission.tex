%  LaTeX support: latex@mdpi.com 
%  For support, please attach all files needed for compiling as well as the log file, and specify your operating system, LaTeX version, and LaTeX editor.

%=================================================================
\documentclass[philosophies,article,submit,pdftex,moreauthors]{Definitions/mdpi} 
%\documentclass[preprints,article,submit,pdftex,moreauthors]{Definitions/mdpi} 
% For posting an early version of this manuscript as a preprint, you may use "preprints" as the journal. Changing "submit" to "accept" before posting will remove line numbers.

%--------------------
% Class Options:
%--------------------
%----------
% journal
%----------
% Choose between the following MDPI journals:
% ...  philosophies, ...

%---------
% article
%---------
% The default type of manuscript is "article", but can be replaced by: 
% abstract, addendum, article, benchmark, book, bookreview, briefcommunication, briefreport, casereport, changes, clinicopathologicalchallenge, comment, commentary, communication, conceptpaper, conferenceproceedings, correction, conferencereport, creative, datadescriptor, discussion, entry, expressionofconcern, extendedabstract, editorial, essay, erratum, fieldguide, hypothesis, interestingimages, letter, meetingreport, monograph, newbookreceived, obituary, opinion, proceedingpaper, projectreport, reply, retraction, review, perspective, protocol, shortnote, studyprotocol, supfile, systematicreview, technicalnote, viewpoint, guidelines, registeredreport, tutorial,  giantsinurology, urologyaroundtheworld
% supfile = supplementary materials

%----------
% submit
%----------
% The class option "submit" will be changed to "accept" by the Editorial Office when the paper is accepted. This will only make changes to the frontpage (e.g., the logo of the journal will get visible), the headings, and the copyright information. Also, line numbering will be removed. Journal info and pagination for accepted papers will also be assigned by the Editorial Office.

%------------------
% moreauthors
%------------------
% If there is only one author the class option oneauthor should be used. Otherwise use the class option moreauthors.

%---------
% pdftex
%---------
% The option pdftex is for use with pdfLaTeX. Remove "pdftex" for (1) compiling with LaTeX & dvi2pdf (if eps figures are used) or for (2) compiling with XeLaTeX.

%=================================================================
% MDPI internal commands - do not modify
\firstpage{1} 
\makeatletter 
\setcounter{page}{\@firstpage} 
\makeatother
\pubvolume{1}
\issuenum{1}
\articlenumber{0}
\pubyear{2025}
\copyrightyear{2025}
%\externaleditor{Firstname Lastname} % More than 1 editor, please add `` and '' before the last editor name
\datereceived{ } 
\daterevised{ } % Comment out if no revised date
\dateaccepted{ } 
\datepublished{ } 
%\datecorrected{} % For corrected papers: "Corrected: XXX" date in the original paper.
%\dateretracted{} % For retracted papers: "Retracted: XXX" date in the original paper.
\hreflink{https://doi.org/} % If needed use \linebreak
%\doinum{}
%\pdfoutput=1 % Uncommented for upload to arXiv.org
%\CorrStatement{yes}  % For updates
%\longauthorlist{yes} % For many authors that exceed the left citation part
%\IsAssociation{yes} % For association journals

%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, inputenc, calc, indentfirst, fancyhdr, graphicx, epstopdf, lastpage, ifthen, float, amsmath, amssymb, lineno, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, tabto, xcolor, colortbl, soul, multirow, microtype, tikz, totcount, changepage, attrib, upgreek, array, tabularx, pbox, ragged2e, tocloft, marginnote, marginfix, enotez, amsthm, natbib, hyperref, cleveref, scrextend, url, geometry, newfloat, caption, draftwatermark, seqsplit
% cleveref: load \crefname definitions after \begin{document}


%-----------------------------------------------------------------
% Tikz

\usepackage{tikz}

\tikzstyle{dot} = [circle, fill=black, inner sep=0pt, minimum width=4pt]
\tikzstyle{arrow} = [shorten <=1mm, shorten >=1mm,thick=2pt]

\newenvironment{diagram}
  {\begin{center}\begin{tikzpicture}}
  {\end{tikzpicture}\end{center}}


%-----------------------------------------------------------------
% Custom commands/definitions

\definecolor{faded}{HTML}{AAAAAA}
\definecolor{selected}{HTML}{DDBB88}
\definecolor{wrong}{HTML}{CC3445}
\definecolor{wire1}{HTML}{ABABAB}
\definecolor{wire2}{HTML}{AB56BC}
\definecolor{wire3}{HTML}{348967}


\mathchardef\mhyphen="2D % math hyphen
\def\EmptySet/{\varnothing}
\def\Nat/{\mathbb{N}}
\def\bottom/{\perp}
\def\meet/{\wedge}
\def\bigmeet/{\bigwedge}
\def\join/{\vee}
\def\bigjoin/{\bigvee}
\def\compose/{\circ}
\def\childOf/{\preccurlyeq}

\def\openTuple/{\langle}
\def\closeTuple/{\rangle}
\newcommand\tuple[1]{\openTuple/ #1 \closeTuple/}
\newcommand\preimage[1]{#1^{-1}}

\newcommand\ident[1]{id_{#1}}
\newcommand\category[1]{\mathbb{#1}}
\newcommand\oppCategory[1]{\mathbb{#1}^{op}}
\def\objects/{Objs}
\def\morphisms/{Morphs}
\newcommand\functor[1]{#1}
\newcommand\natTrans[2]{#1_{#2}}
\newcommand\characteristic[1]{\chi_{#1}}

\newcommand\atomsOf[1]{Atoms(#1)}
\newcommand\restrict[2]{\rho^{#1}_{#2}}
\def\Index/{\mathbb{A}}
\def\support/{I}
\newcommand\glues[1]{\mathcal{G}_{#1}}
\def\Gsheaf/{$\glues{}$-sheaf}
\def\Gsheaves/{$\glues{}$-sheaves}

\newcommand\jop[1]{j_{#1}}


%=================================================================
% Please use the following mathematics environments: Theorem, Lemma, Corollary, Proposition, Characterization, Property, Problem, Example, ExamplesandDefinitions, Hypothesis, Remark, Definition, Notation, Assumption
%% For proofs, please use the proof environment (the amsthm package is loaded by the MDPI class).

%=================================================================
% Full title of the paper (Capitalized)
\Title{Sheaf Mereology: Parts and Wholes in a Topos-Theoretic Setting}

% MDPI internal command: Title for citation in the left column
\TitleCitation{Title}

% Author Orchid ID: enter ID or remove command
\newcommand{\orcidauthorA}{0000-0000-0000-000X} % Add \orcidA{} behind the author's name
%\newcommand{\orcidauthorB}{0000-0000-0000-000X} % Add \orcidB{} behind the author's name

% Authors, for the paper (add full first names)
\Author{Firstname Lastname $^{1}$\orcidA{}, Firstname Lastname $^{2}$ and Firstname Lastname $^{2,}$*}

%\longauthorlist{yes}

% MDPI internal command: Authors, for metadata in PDF
\AuthorNames{Firstname Lastname, Firstname Lastname and Firstname Lastname}

% Author citation:  
\AuthorCitation{Lastname, F.; Lastname, F.; Lastname, F.}

% Affiliations / Addresses (Add [1] after \address if there is only one affiliation.)
\address{%
$^{1}$ \quad Affiliation 1; e-mail@e-mail.com\\
$^{2}$ \quad Affiliation 2; e-mail@e-mail.com}

% Contact information of the corresponding author
\corres{Correspondence: e-mail@e-mail.com; Tel.: (optional; include country code; if there are multiple corresponding authors, add author initials) +xx-xxxx-xxx-xxxx (F.L.)}

% Current address and/or shared authorship
%\firstnote{Current address: Affiliation.}  
% Current address should not be the same as any items in the Affiliation section.

%\secondnote{These authors contributed equally to this work.}
% The commands \thirdnote{} till \eighthnote{} are available for further notes.

%\simplesumm{} % Simple summary

%\conference{} % An extended version of a conference paper

% Abstract (Do not insert blank lines, i.e. \\) 
\abstract{A single paragraph of about 200 words maximum. For research articles, abstracts should give a pertinent overview of the work. We strongly encourage authors to use the following style of structured abstracts, but without headings: (1) Background: place the question addressed in a broad context and highlight the purpose of the study; (2) Methods: describe briefly the main methods or treatments applied; (3) Results: summarize the article's main findings; (4) Conclusions: indicate the main conclusions or interpretations. The abstract should be an objective representation of the article, it must not contain results which are not presented and substantiated in the main text and should not exaggerate the main conclusions.}

% Keywords
\keyword{mereology; fusions and integral wholes; sheaves; point-free topology; frames and locales; toposes; modality; merology logic; categorical logic} 

% The fields PACS, MSC, and JEL may be left empty or commented out if not applicable
%\PACS{J0101}
%\MSC{}
%\JEL{}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Different journals have different requirements. Please check the specific journal guidelines in the "Instructions for Authors" on the journal's official website.
%\addhighlights{yes}
%\renewcommand{\addhighlights}{%
%
%\noindent The goal is to increase the discoverability and readability of the article via search engines and other scholars. Highlights should not be a copy of the abstract, but a simple text allowing the reader to quickly and simplified find out what the article is about and what can be cited from it. Each of these parts should be devoted up to 2~bullet points.\vspace{3pt}\\
%\textbf{What are the main findings?}
% \begin{itemize}[labelsep=2.5mm,topsep=-3pt]
% \item First bullet.
% \item Second bullet.
% \end{itemize}\vspace{3pt}
%\textbf{What is the implication of the main finding?}
% \begin{itemize}[labelsep=2.5mm,topsep=-3pt]
% \item First bullet.
% \item Second bullet.
% \end{itemize}
%}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\setcounter{section}{-1} %% Remove this when starting to work on the template.
%\section{How to Use this Template}

% For any questions, please contact the editorial office of the journal or support@mdpi.com. For LaTeX-related questions please contact latex@mdpi.com.

%\endnote{This is an endnote.} % To use endnotes, please un-comment \printendnotes below (before References). Only journal Laws uses \footnote.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:introduction}

% The introduction should briefly place the study in a broad context and highlight why it is important. It should define the purpose of the work and its significance. The current state of the research field should be reviewed carefully and key publications cited. Please highlight controversial and diverging hypotheses when necessary. Finally, briefly mention the main aim of the work and highlight the principal conclusions. As far as possible, please keep the introduction comprehensible to scientists outside your particular field of research. 

Standard presentations of mereology tend to take what we might call a ``parts-first'' approach. You start by taking the parthood relation as primitive, and then you proceed by stipulating axioms that govern the relation. The goal is to choose your axioms well enough that the resulting models that satisfy your theory align nicely with the actual part-whole complexes that we encounter in the world around us. 

By most standard accounts (e.g., \cite{Simons:1987}, \cite{Varzi:2011}, or \cite{CotnoirAndVarzi:2021}), partisans of the parts-first approach have more or less agreed on a common (minimal) ``core'' known as ``classical mereology.'' First, classicists adopt the following principles that govern the ordering of the parts:

\begin{itemize}

\item Parthood is reflexive, antisymmetric, and transitive (i.e., it is a partial order).

\end{itemize}

\noindent
Second, classicists adopt the following decomposition principle that governs how wholes decompose:

\begin{itemize}

\item Wholes decompose into more than one proper part (i.e., parthood obeys some form of so-called ``supplementation,'' ``remainder,'' or ``complementation'' principle which says that no whole consists of only a single proper part --- there must be some remainder or relative complement).

\end{itemize}

\noindent
Third, classicists adopt the following principle that governs how parts fuse into wholes:

\begin{itemize}

\item Any collection of parts whatever forms a fusion (i.e. unrestricted fusion).

\end{itemize}

Classicists also require (either as an explicit axiom or as a consequence of the other axioms) some version of extensionality (TODO: consult Contoir's article on this and maybe cite it):

\begin{itemize}

\item If wholes have the same parts, then they're the same wholes.

\end{itemize}

With the above axioms fixed, the classicist can then define a number of other useful notions in the obvious ways, e.g.:

\begin{itemize}

\item Overlap and underlap
\item Complement/difference
\item Etc.

\end{itemize}

At first site, most of the classicist's principles can feel deeply intuitive. However, philosophers have objected to virtually all of them. Take for instance that parthood is transitive: if $x$ is a part of $y$ and $y$ is a part of $z$, then surely $x$ is a part of $z$. But there appear to be counter-examples. For example, my appendix is a part of me, and I am a member of the orchestra, but my appendix is not a member of the orchestra.

A standard response is to point out that this sort of objection exploits an ambiguity: we utilize different, more specialized notions of ``parthood'' when we talk about the integration of the parts of biological organisms vs. those of orchestras. My appendix is a part of me under one description (as a part of a biological organism), while I am a part of the orchestra under another (as a member of a musical ensemble). 

Defenders of the classical axioms have said that the fact that we can partition the general notion of parthood into more specialized versions only shows that the above axioms do in fact characterize a general notion of parthood, characterized precisely by the above classical notions (TODO: cite Simons, Varzi, etc).

However, one can't help but feel that there is something circular about this response, since it turns on the assumption that the different notions of functional unity are species (or determinations, or partitions, or what have you) of a more generic relation. But the existence of that generic relation hasn't been established, and there is no reason to think that mereological pluralism isn't correct --- namely, that there are many parthood relations, not one (TODO: cite Fine, etc.).

Another common objection to the classical approach revolves around composition principles. In particular, if we adopt unrestricted fusion, as the classical mereologist does, then we seem to get too many fusions. For instance, take the pencil on the table in front of me and your left knee. Are we really to believe that there is a fusion of that pencil and your left knee? Such a fusion would have two parts that live quite far apart (possibly even on different sides of the globe). 

Defenders of the classical approach do have a response though: just because we may not have a word or concept that names the pencil+knee fusion, that doesn't mean it doesn't exist. (TODO: cite Varzi, etc.) Indeed, just as Moore attempt to show that extramental things exist by holding up his two hands and saying, ``Here is one hand, here is the other,'' so too might one try to show that the pencil+knee fusion exists by saying, ``there is the pencil, there is the knee.''

Again though, one can't help but feel that there is something circular about this response. To appeal to the pencil+knee's fusion after its fused-ness has been questioned just brings the principle under scrutiny back into the mix. A better response would provide an independent reason to think that pencil+knee qualifies as more than a ``mere Cambridge'' fusion.

Whether these objections/responses constitute any real conceptual clarification or are inexorably stuck in semantic circularities is not something we want to decide here. We mention these points only because they illustrate something else: they illustrate that we seem to have intuitions not just about parts, but also about fusions. In the two objections just mentioned, we seem to have certain conceptions of integrated fusions somewhere in the back of our minds, and those seem to be driving the objections. 

For example, the reason it seems wrong to say my appendix is not part of the orchestra is because we seem to think that biological organisms are integrated in a different way than orchestras. Similarly, the reason we can so easily think that a pencil and a hand don't fuse is because they don't integrate in one of the ways that we ambiently accept as legitimate.

That leads to the following question: if we have ambient intuitions about which collections count as fusions and which ones don't, then why not take a ``fusions-first'' approach to mereology? Instead of taking parthood as the primitive relation, and then try to work up to a notion of fusions, why not take fusions as the primitive relation, and then work backwards to parts?

Such an approach is far less common in the technical mereological literature. That raises yet another question: why has the ``fusions-first'' approach been so neglected? One proposal is that it might seem to be too unwieldy. One might say that there are just too many different ways that things can integrate into wholes/fusions, and so it is a hopeless task to try and enumerate them and offer any sort of a unifying taxonomy. (TODO: Cite Simons.)

Another reason might be that such a view would be inelegant and perhaps would even fail to qualify as an ``explanation'' of the part-whole phenomenon altogether. If you ask me to explain why various $X$s seem to exhibit the same (or sufficiently similar) properties, it would be quite dissatisfying if I said, ``that's easy, there is no unifying explanation.'' 

TODO: remove/rewrite these last two paragraphs. The ``fusions-first'' approach is not so uncommon in the literature as I just made it out to be. Mereotopology exists as a branch of hereology, for all intensive purposes, precisely because it is the fusions-first response to the classical parts-first approach. Cite Casati and Varzi, chapter 3 and others.

Fortunately, a ``fusions-first'' approach need not be as doomed as it may seem. In this paper, we claim that there is a satisfying ``fusions-first'' approach to mereology, and we present it in what follows. To accomplish this, we will build a bridge between category theory and philosophy. In particular, we will take well-known techniques used to manage the gluing-together of parts in algebraic geometry and topos theory, and we will apply those techniques to the realm of mereology.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{From Parts to Sheaves}

To begin, we want to suggest that it is useful to draw a distinction between what one might call the algebra of parts on the one hand, and the integrity or gluing-together of the parts on the other. To get a sense of what this distinction means, and why it is useful, fix a part-whole complex to analyze (a statue of Dion, let's say), and let an enumeration of its parts be given. The classical principle of unrestricted fusion says that any combination of those parts glues into a fusion. In essence, this generates all possible combinations of parts. As such, it nearly yields a complete lattice, with overlap and underlap serving as the meet and join operators. 

However, it only \emph{nearly} yields a complete lattice because mereologists have been relunctant to allow a bottom element. Since mereologists are ontologists, they find a null element to be ontologically suspect. And indeed, what could an empty thing that is part of all other things possibly \emph{be}? So, instead of admitting it into their mereological systems, classical mereologists have simply omitted it altogether. David Lewis (\cite{Lewis:1991}) even went so far as to formulate a version of set theory that had no empty set. 

Yet despite their suspicion of a null element, classical mereologists have not shied away from allowing all possible fusions to exist, as noted already. Since the bottom element of a lattice is the empty join, we can put the point like this: classical mereologists are ontologically conservative about empty joins, and ontologically permissive about non-empty joins. As Tarski pointed out long ago, the principles of classical mereology thus yield a boolean algebra, with the bottom element removed (TODO: cite).

But it is difficult to see the motivation here. On the one hand, if you want to be ontologically conservative, then why allow so many fusions? If we are going to be suspicious of an empty join, then wouldn't we also be suspicious of the fusion of (say) Dion's left hand and right knee? Conversely, if we are happy to admit the existence of entities like the fusion of Dion's left hand and right knee, then why not an empty join? 

One way to diagnose the problem is to say that we, as classical mereologists, have confused the algebra of parts with the integrity of the wholes. We have defined the algebra of parts in a combinatorial way, but then at the same time, we tried to make that algebra do ontological work. But this inevitably pulls us in two directions. So, we end up letting the algebraic aspects of our parthood relation do ontological work (creating any fusion whatever), until it goes too far (e.g. the null element), at which point we try to pull back on the ontological reigns.

For another point of tension, consider extensionality. The classicist's axiom says if $x$ and $y$ have the same parts, then $x$ = $y$. This is ontologically conservative: ``no difference without a difference maker'' (TODO cite Lewis). However, this flattens all structure, and so it judges that ``tip'' and ``pit'' cannot be different words, since they have the same parts, after flattening. But that of course feels wrong. These two words have a different ordering of letters, so why would we neglect that in determining their identity? Here too we don't want the combinatorics to do any ontological work, even though we're happy to let the join operation freely generate entities.

We can free ourselves from these sorts of tensions if we separate the algebra of parts from the integrity or gluing of the parts. Let us think of the lattice of parts merely as the abstract ``parts space,'' i.e., as the set of all \emph{possible} combinations of the given parts into larger pieces. Moreover, let us be clear that this does not do any ontological work. A ``parts space'' is just an abstract description of the various combinations of parts that could be. Think of it as a kind of mold that has slots that could be filled in with actual pieces. To specify an \emph{actual} part-whole complex that occupies that parts space, we need to take a second step and fill in certain of those slots with actual stuff, and specify which of those pieces glue together into bigger pieces. 

Once we have made this distinction, we can let the algebra of parts be an algebra, and we can even allow a bottom element without worry. As a component of the abstract parts space, the bottom element is no more a real thing than the join of any other arbitrary regions of the parts space. At the same time, when we specify which pieces really occupy the parts space, we can be as ontologically conservative or as permissive as we like. We have the freedom to provide gluing conditions that are as fine-grained as we need. For instance, we can say that certain pieces glue together, while others do not (e.g., Dion's right knee glues directly to his right femur, but not directly to his left hand). Moreover, we can let the identity conditions be determined by the gluing conditions, and so maintain structured extensionality (a difference in fusions comes from different parts, or different gluings).

Once we make the distinction between the background algebra of parts and the foreground integrity of the fusion, our task takes on a distinctive shape: now we find ourselves trying to coherently glue pieces together over an ambient space. And that is something known well to algebraic geometers and topos theorists: it is the task of constructing a sheaf over a space. For the algebraic geometer and topos theorist, sheaf theory provides a systematic framework for gluing together pieces over a space in such a way that the gluing is done coherently and consistently against the ambient structure of the underlying space. It stands to reason, then, that the mathematician's sheaf-theoretic techniques can be used profitably in mereology.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The Central Thesis}

In this paper, we want to build a bridge between sheaf theory and mereology by importing some of those sheaf-theoretic techniques into the mereological setting. The central claim of this paper is thus: part-whole complexes can be usefully modeled as sheaves over locales. The key ideas are as follows:

\begin{itemize}

\item An algebra of parts tells us all the ways that parts can combine to form bigger wholes. In this sense, an algebra of parts generates the ambient ``parts space'' of an object, i.e. the abstract lattice-theoretic structure of \emph{possible} combinations. But not all possible combinations actually glue together to form \emph{actual} fusions. In many cases, we want to allow that only some of the parts glue together into an integrated whole/fusion. 

\item So, we then require a separate step where we, the mereologists, have to ``fill in'' the abstract parts space with actual parts: we have to specify which bits of stuff fill in or occupy which slots in that ambient parts space, and we have to specify how those various bits of stuff glue together to form integrated fusions.

\item It is tempting to try to model the ambient parts space as a topology. However, topologies have points, and it is not clear that all of the part-whole complexes that we might wish to consider are usefully modeled with points. This limitation is easy to overcome if we generalize and move to the point-free setting: instead of a topology, we choose to model the ambient parts space as a locale (a point-free generalization of a topology). 

\item We use a sheaf to specify which bits of stuff inhabit an ambient locale and also to stipulate how those bits glue together. A sheaf is precisely an assignment of data to a topology or locale that coherently glues that data together. So, we choose to model the actual part-whole complex as a sheaf over the ambient locale. 

\item To specify a part-whole complex, then, we (the mereologists) simply need to define a sheaf over the given locale. The ``data'' that we assign to the ambient locale are the bits of actual stuff that inhabit that parts space, and the gluing condition specifies how those pieces glue together.

\item This yields a straightforward procedure that can be used to model any part-whole complex: first, specify the ambient locale, i.e., the abstract space of parts that the part-whole complex in question inhabits; second, fill in that ambient space with actual pieces and say how they glue together; third, let the sheaf framework do the rest of the work. Then the glued sections of the sheaf turn out to be the fusions, whose parts are the smaller sections each fusion is glued from. This is an honest ``fusions-first'' approach. 

\end{itemize}

\noindent
There are two important benefits that come along for free when we take this approach.

\begin{itemize}

\item The sheaves over a locale form a topos. A topos is a special kind of category that you can do ``parts''-like logic in. Indeed, every topos comes equipped with just such an internal logic. It turns out that this internal logic corresponds exactly to the correct mereological logic that governs the part-whole complexes that can be formed over that locale. So, there is no need to manually create a mereological logic to reason about the part-whole complexes that occupy the ambient locale. We get that for free. 

\item Modalities are natural operators that occur in sheaves, where they are easily defined and managed. These modalities interact correctly with the internal logic of the topos (and in fact are part of that internal logic). So we get mereological modalities for free too.

\end{itemize}

To our mind, the fact that these benefits come for free offers a compelling reason to adopt a sheaf-theoretic approach to part-whole complexes.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Literature}

The literature on mereology is vast. What we might think of as formal mereology (axiomatized systems) goes back at least to Le\'{s}niewski's system called ``Mereology'' [cite] and Leonard and Goodman's ``Calculus of Individuals'' [cite], along with other contributions by Whitehead [cite], Tarski [cite], and others. Surveys of the resulting literature and ideas can be found in the now standard works by Simons and others (e.g. \cite{Simons:1987}, \cite{Varzi:2011}, or \cite{CotnoirAndVarzi:2021}).

Topological concepts have been used in mereology for a long time (see the historical coverage and discussion in \cite{Simons:1987}). So-called ``mereotopology'' explicitly aims to characterize mereological questions in topological ways, especially using notions like boundaries, interiors, and connectedness. A standard introduction to modern mereotopology is \cite{CasatiAndVarzi:1999}.

However, despite its heavy reliance on topology, mereotopology has not (to our knowledge) utilized sheaf-theory in any significant way (nor has classical mereology). TODO: discuss Spivak's behavioral mereology/seven-sketches/temporal type theory (\cite{ShultzAndSpivak:2019}, Moltmann's trope sheaves, Moltmann's mereology.

For sheaves, see \cite{Tennison:1975}, \cite{MacLaneAndMoerdijk:1994}, \cite{Rosiak:2022}, or \cite{Wedhorn:2016}.

For toposes, see \cite{Goldblatt:1984}, \cite{McLarty:1992}, \cite{Borceux:1994}, \cite{MacLaneAndMoerdijk:1994}, \cite{LawvereAndSchanuel:1997}. TODO: discuss the idea of ``deriving'' the logic from the underlying structure, rather than ``inventing'' it axiomatically. Perhaps Moltmann's mereology is to be cited here.

TODO: discuss how mereological concepts are used in certain ``fusion-first'' approaches, e.g., Peter Simons and using ``connectedness.'' Discuss Van Inwagen's special composition question (\cite{VanInwagen:1990}). 

TODO: discuss non-boolean approaches. Discuss boolean algebra stuff from Protow, the survey ``Logic in Heyting Algebras,''  Moltmann's Heyting mereology.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Contributions}

The contributions of this paper are as follows:

\begin{itemize}

\item We demonstrate a viable ``fusions-first'' approach to mereology.
\item We separate the algebra of parts from the integrity of fusions.
\item We build a bridge between mereological techniques of mathematics and philosophy. In particular:

\begin{itemize}

\item We utilize sheaves to systematically manage coherence and gluing over parts spaces.
\item We acquire the correct mereological logics for free from the internal language of the underlying topos.

\end{itemize}

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Plan of the Paper}

The plan of this paper is as follows. 

\begin{itemize}

\item Part 1: Sheaves

\begin{itemize}

\item In \cref{sec:sheaf-theory}, we introduce the relevant parts of sheaf theory that will be used in the rest of the paper.

\item In \cref{sec:sheaf-mereology}, we define part and whole in sheaf-theoretic terms, and we show how to model different kinds of part-whole complexes as sheaves. 

\item In \cref{sec:modalities}, we show how mereological modalities arise naturally in sheaves.

\item In \cref{sec:classical-mereology-in-sheaves}, we discuss what classical mereological notions look like in the sheaf-theoretic setting.

\end{itemize}

\item Part 2: Toposes

\begin{itemize}

\item In \cref{sec:category-theory}, we introduce the relevant parts of category theory that are needed for topos theory.

\item In \cref{sec:topos-theory}, we introduce topos theory and topos logic.

\item in \cref{sec:logic-in-toposes}, we show how to do mereological logic with topos logic. 

\item In \cref{sec:mereology-logics}, we show how the mereological logic of any given setting arises (for free) from the internal logic of the underlying topos.

\end{itemize}

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Sheaf-Theory}
\label{sec:sheaf-theory}

In this section, we cover the parts of sheaf theory that we will utilize in the rest of the paper. Readers familiar with sheaf theory can skip this section.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Fibers}

\noindent
Suppose we have a map (function) $f: E \to B$ that looks something like this:

\begin{diagram}

\node at (-5, 0) {$E$};
\draw (-3, -0.15) ellipse (1.5cm and 1.85cm);
\node[dot, label=left:$1$] (1) at (-3.25, 1.25) {};
\node[dot, label=left:$2$] (2) at (-2.5, 0.75) {};
\node[dot, label=left:$3$] (3) at (-3, 0.25) {};
\node[dot, label=left:$4$] (4) at (-3.5, -0.25) {};
\node[dot, label=left:$5$] (5) at (-2.5, -0.5) {};
\node[dot, label=left:$6$] (6) at (-3.0, -1) {};
\node[dot, label=left:$7$] (7) at (-2.75, -1.5) {};

\node at (4.375, 0) {$B$};
\draw (3.15, 0) ellipse (0.75cm and 1.75cm);
\node[dot, label=right:$a$] (a) at (3, 1) {};
\node[dot, label=right:$b$] (b) at (3, 0) {};
\node[dot, label=right:$c$] (c) at (3, -1) {};

\node at (0, -1.625) {$f$};
\draw[arrow,->] (1) to (a);
\draw[arrow,->] (2) to (b);
\draw[arrow,->] (3) to (a);
\draw[arrow,->] (4) to (b);
\draw[arrow,->] (5) to (c);
\draw[arrow,->] (6) to (b);
\draw[arrow,->] (7) to (c);

\end{diagram}

It is sometimes convenient to turn the diagram sideways and group together points in the domain that get sent to the same target, like so:

\begin{diagram}

\node at (3, 1.85) {$E$};
\draw (0, 1.85) ellipse (2.5cm and 1cm);
\node[dot, label=above:$1$] (1) at (-2, 1.75) {};
\node[dot, label=above:$3$] (3) at (-1.5, 1.5) {};
\node[dot, label=above:$2$] (2) at (-0.5, 1.75) {};
\node[dot, label=above:$4$] (4) at (0, 2) {};
\node[dot, label=above:$6$] (6) at (0.5, 1.55) {};
\node[dot, label=above:$5$] (5) at (2, 1.75) {};
\node[dot, label=above:$7$] (7) at (1.5, 1.5) {};

\node at (3, 0) {$B$};
\draw (0, -0.15) ellipse (2.5cm and 0.75cm);
\node[dot, label=below:$a$] (a) at (-1.75, 0) {};
\node[dot, label=below:$b$] (b) at (0, 0) {};
\node[dot, label=below:$c$] (c) at (1.75, 0) {};

\node at (2.5, 0.875) {$f$};
\draw[arrow,->] (1) to (a);
\draw[arrow,->] (2) to (b);
\draw[arrow,->] (3) to (a);
\draw[arrow,->] (4) to (b);
\draw[arrow,->] (5) to (c);
\draw[arrow,->] (6) to (b);
\draw[arrow,->] (7) to (c);

\end{diagram}

That makes the pre-images very easy to see. For any point in $B$, its pre-image is just the group of points sitting ``over'' it: 

\begin{diagram}

\node at (3, 1.85) {$E$};

\draw (-1.75, 1.85) ellipse (0.7cm and 0.75cm);
\node[dot, label=above:$1$] (1) at (-2, 1.75) {};
\node[dot, label=above:$3$] (3) at (-1.5, 1.5) {};

\draw (0, 1.95) ellipse (0.85cm and 0.85cm);
\node[dot, label=above:$2$] (2) at (-0.5, 1.75) {};
\node[dot, label=above:$4$] (4) at (0, 2) {};
\node[dot, label=above:$6$] (6) at (0.5, 1.55) {};

\draw (1.75, 1.85) ellipse (0.7cm and 0.75cm);
\node[dot, label=above:$5$] (5) at (2, 1.75) {};
\node[dot, label=above:$7$] (7) at (1.5, 1.5) {};

\node at (3, 0) {$B$};
\draw (0, -0.15) ellipse (2.5cm and 0.75cm);
\node[dot, label=below:$a$] (a) at (-1.75, 0) {};
\node[dot, label=below:$b$] (b) at (0, 0) {};
\node[dot, label=below:$c$] (c) at (1.75, 0) {};

\node at (2.5, 0.875) {$f$};
\draw[arrow,->] (1) to (a);
\draw[arrow,->] (2) to (b);
\draw[arrow,->] (3) to (a);
\draw[arrow,->] (4) to (b);
\draw[arrow,->] (5) to (c);
\draw[arrow,->] (6) to (b);
\draw[arrow,->] (7) to (c);

\end{diagram}

If we stack the points in each pre-image vertically, one on top of the other, we can then think of each pre-image as a kind of ``stalk'' growing over its base point:

\begin{diagram}

\node at (2.825, 1.5) {$E$};
\draw (-1.75, 1.75) ellipse (0.5cm and 1cm);
\node[dot, label=above:$3$] (3) at (-1.75, 2) {};
\node[dot, label=above:$1$] (1) at (-1.75, 1.25) {};

\draw (0, 2.15) ellipse (0.5cm and 1.375cm);
\node[dot, label=above:$6$] (6) at (0, 2.75) {};
\node[dot, label=above:$4$] (4) at (0, 2) {};
\node[dot, label=above:$2$] (2) at (0, 1.25) {};

\draw (1.75, 1.75) ellipse (0.5cm and 1cm);
\node[dot, label=above:$7$] (7) at (1.75, 2) {};
\node[dot, label=above:$5$] (5) at (1.75, 1.25) {};

\node at (2.825, -0.15) {$B$};
\draw (0, -0.15) ellipse (2.5cm and 0.75cm);
\node[dot, label=below:$a$] (a) at (-1.75, 0) {};
\node[dot, label=below:$b$] (b) at (0, 0) {};
\node[dot, label=below:$c$] (c) at (1.75, 0) {};

\node at (2.825, 0.625) {$f$};
\draw[arrow,->] (-1.75, 1) to (a);
\draw[arrow,->] (0, 1) to (b);
\draw[arrow,->] (1.75, 1) to (c);

\end{diagram}

This gives rise to the idea of the ``fibers'' of a map. The fibers of a map are just its pre-images. For instance, the fiber over $b$ is $\{ 2, 4, 6 \}$.

% ----------------------------------------
\begin{Definition}[Fibers]

Given a map $f : E \to B$ and a point $y \in B$, the fiber over $y$ is its pre-image $\preimage{f}(y)$ = $\{ x \mid f(x) = y \}$. $B$ is called the ``base space'' (or ``base'' for short) of $f$, while the point $y$ is called the ``base point'' (or ``base'' for short) of the fiber.

\end{Definition}

We can select a cross-section of one or more fibers by selecting a point from each of the fibers in question. For instance, we can take $3$, $4$, and $7$ as a cross-section of the fibers $\preimage{f}(a)$, $\preimage{f}(b)$, and $\preimage{f}(c)$:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.75, 2.15) rectangle (2.75, 1.875);

\node at (2.825, 1.5) {$E$};
\draw (-1.75, 1.75) ellipse (0.5cm and 1cm);
\node[dot, label=above:$3$] (3) at (-1.75, 2) {};
\node[dot, label=above:$1$] (1) at (-1.75, 1.25) {};

\draw (0, 2.15) ellipse (0.5cm and 1.375cm);
\node[dot, label=above:$6$] (6) at (0, 2.75) {};
\node[dot, label=above:$4$] (4) at (0, 2) {};
\node[dot, label=above:$2$] (2) at (0, 1.25) {};

\draw (1.75, 1.75) ellipse (0.5cm and 1cm);
\node[dot, label=above:$7$] (7) at (1.75, 2) {};
\node[dot, label=above:$5$] (5) at (1.75, 1.25) {};

\node at (2.825, -0.15) {$B$};
\draw (0, -0.15) ellipse (2.5cm and 0.75cm);
\node[dot, label=below:$a$] (a) at (-1.75, 0) {};
\node[dot, label=below:$b$] (b) at (0, 0) {};
\node[dot, label=below:$c$] (c) at (1.75, 0) {};

\node at (2.825, 0.625) {$f$};
\draw[arrow,->] (-1.75, 1) to (a);
\draw[arrow,->] (0, 1) to (b);
\draw[arrow,->] (1.75, 1) to (c);

\end{diagram}

We can also take cross-sections local to only some of the fibers. For instance, we can take $1$ as a cross-section just of $\preimage{f}(a)$:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.75, 1.4) rectangle (-0.75, 1.10);

\node at (2.825, 1.5) {$E$};
\draw (-1.75, 1.75) ellipse (0.5cm and 1cm);
\node[dot, label=above:$3$] (3) at (-1.75, 2) {};
\node[dot, label=above:$1$] (1) at (-1.75, 1.25) {};

\draw (0, 2.15) ellipse (0.5cm and 1.375cm);
\node[dot, label=above:$6$] (6) at (0, 2.75) {};
\node[dot, label=above:$4$] (4) at (0, 2) {};
\node[dot, label=above:$2$] (2) at (0, 1.25) {};

\draw (1.75, 1.75) ellipse (0.5cm and 1cm);
\node[dot, label=above:$7$] (7) at (1.75, 2) {};
\node[dot, label=above:$5$] (5) at (1.75, 1.25) {};

\node at (2.825, -0.15) {$B$};
\draw (0, -0.15) ellipse (2.5cm and 0.75cm);
\node[dot, label=below:$a$] (a) at (-1.75, 0) {};
\node[dot, label=below:$b$] (b) at (0, 0) {};
\node[dot, label=below:$c$] (c) at (1.75, 0) {};

\node at (2.825, 0.625) {$f$};
\draw[arrow,->] (-1.75, 1) to (a);
\draw[arrow,->] (0, 1) to (b);
\draw[arrow,->] (1.75, 1) to (c);

\end{diagram}

% ----------------------------------------
\begin{Definition}[Sections]

Given a map $f : E \to B$ and a subset $C \subseteq B$ (i.e., a selection of base points in $B$), a section of $f$ (over $C$) is a choice of one element from each fiber over each base $x \in C$.

\end{Definition}

% ----------------------------------------
\begin{Remark}
\label{remark:section-terminology}

Since each point in a fiber amounts to a section over the fiber's base, the elements of a fiber are often just called the ``sections'' of the fiber. 

\end{Remark}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Spaces}

\noindent
In the above examples, the base $B$ was a set. We often want to consider bases that have more structure, e.g., bases that have spatial structure.

In traditional topology, spaces are built out of the points of the space. Given a set of points, a topology on that set specifies which points belong in which regions of the space.

% ----------------------------------------
\begin{Definition}[Topology]

Let $X$ be a non-empty set, thought of as the ``points'' of the space. A topology on X is a collection $T$ of subsets of $X$, thought of as the ``regions'' of the space (called the ``open sets'' or just the ``opens'' of $T$), that satisfy the following conditions:

\begin{enumerate}

\item [(T1)] The empty set and the whole set are open: 

$$\EmptySet/ \in T, X \in T.$$

\item [(T2)] Arbitrary unions of opens are open:

$$\text{if } \{ U_{i} \}_{i \in I} \subseteq T, \text{ then } \bigcup\limits_{i \in I} U_{i} \in T.$$

\item [(T3)] Finite intersections of opens are open: 

$$\text{if } U_{1}, \ldots, U_{n} \in T, \text{ then } \bigcap\limits_{i=1}^{n} U_{i} \in T.$$

\end{enumerate} 

\end{Definition}

These conditions encode the way that spatial regions are put together. For instance, it ensures that if two regions overlap, then their overlapping area is a region too (and indeed, that's what it means for regions to \emph{overlap}: there's a region of space they have in common).

\begin{Remark}

The regions of a topology form a complete lattice. T1 says that the lattice has a top ($\top$) and bottom ($\bottom/$), T2 says that for any selection of opens there is a join, and T3 says that for any finite selection of opens there is a meet.

\end{Remark}

% ----------------------------------------
\begin{Example}
\label{ex:topology}

Let $X = \{ a, b, c \}$. One possible topology is: $T = \{ \EmptySet/, \{ b \}, \{ a, b \}, \{ b, c \}, \{a, b, c \} \}$. If we draw dashed circles around each of the opens (regions), ignoring the empty set, we get:

\begin{diagram}

\node[dot, label=below:$a$] (a) at (-1.75, 0) {};
\node[dot, label=below:$b$] (b) at (0, 0) {};
\node[dot, label=below:$c$] (c) at (1.75, 0) {};

\draw[dashed] (0, 0) ellipse (2.5cm and 1.55cm);
\draw[dashed] (0, -0.1) ellipse (0.5cm and 0.5cm);
\draw[dashed] (-0.75, -0.1) ellipse (1.55cm and 1cm);
\draw[dashed] (0.75, -0.1) ellipse (1.55cm and 1cm);

\end{diagram}

There are two regions $\{ a, b \}$ and $\{ b, c \}$ that overlap at $b$ (so $\{ b \}$ is a region in $T$ too). There is also the full region $\{ a, b, c \}$, which is the union of the smaller regions.

We can draw $T$ as a Hasse diagram, which shows that the regions form a lattice:

\begin{diagram}

\node (abc) at (0, 3) {$\{ a, b, c \}$};
\node (ab) at (-1, 2) {$\{ a, b \}$};
\node (bc) at (1, 2) {$\{ b, c \}$};
\node (b) at (0, 1) {$\{ b \}$};
\node (emptyset) at (0, 0) {$\EmptySet/$};

\draw (emptyset) to (b);
\draw (b) to (ab);
\draw (b) to (bc);
\draw (ab) to (abc);
\draw (bc) to (abc);

\end{diagram}

\end{Example}

The lattice structure suggests that much of what is important about a space is not so much its points, but rather its opens/regions. This leads to the idea that topology-like reasoning can be done without the points. So, we can generalize: take a topology, and drop the points. That leaves just the opens/regions, which we call a frame (or locale).


% ----------------------------------------
\begin{Definition}[Frames/locales]

A frame (synonymously, a locale) $\category{L}$ is a partially ordered set $L$ (we call its elements ``opens'' or ``regions'') that satisfies the following conditions:

\begin{enumerate}

\item [(L1)] $L$ is a complete lattice:

  \begin{itemize}
  \item Every subset $S \subseteq L$ has a join, denoted $\bigjoin/ S.$
  \item Every finite subset $F \subseteq L$ has a meet, denoted $\bigmeet/ F.$
  \end{itemize}

\item [(L2)] Finite meets distribute over arbitrary joins:
$$
  a \meet/ \bigmeet/\limits_{i \in I} b_{i} = \bigmeet/\limits_{i \in I} (a \meet/ b_{i}),
  \text{ for all } a \in L \text{ and all families } \{ b_{i} \}_{i \in I} \subseteq L.
$$

\end{enumerate}

Define $V \childOf/ U$ (read ``$V$ is included in $U$'') by $a = a \meet/ b$.

\end{Definition}


% ----------------------------------------
\begin{Remark}

The fact that $V \childOf/ U$ is equivalent to $a = a \meet/ b$ means we can deal with the opens of a frame algebraically (via $\meet/$ and $\join/$ operations), or order-theoretically (via the $\childOf/$ relation), whichever is more convenient. 

\end{Remark}

\begin{Remark}

The category of locales is defined as the dual/opposite of the category of frames (see \cref{def:opposite-category} below), and so frames and locales are quite literally the very same objects. In practice, frames are often used for algebraic purposes, and locales are used for (generalized) spatial purposes. Here, we will have no reason to distinguish these two roles, and so we will use the names ``frame'' and ``locale'' interchangeably. 

\end{Remark}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Presentations of locales}

\noindent
Locales have presentations much like groups and other algebraic structures. To give the presentation of a locale, specify a set of generators and relations. 


% ----------------------------------------
\begin{Definition}[Presentations]

A presentation $\tuple{G, R}$ of a locale $\category{L}$ is comprised of: 

\begin{enumerate}

\item [(P1)] A set of generators $G = \{ U_{k}, U_{m}, \ldots \}$.
\item [(P2)] A set of relations $R \subseteq G \times G$ on those generators.

\end{enumerate}

\noindent
The locale $\category{L}$ presented by $\tuple{G, R}$ is the smallest one freely generated from $G$ which satisfies $R$.

\end{Definition}

To calculate the locale that corresponds to a presentation, start with the generators, then take all finite meets and all arbitrary joins that satisfy $R$ (and of course L1 and L2).


% ----------------------------------------
\begin{Example}
\label{ex:locale-with-overlap-and-bottom}

Let a locale $\category{L}$ be given by the presentation $\tuple{G, R}$ where:

\begin{itemize}

\item $G = \{ \bottom/, U_{1}, U_{2}, U_{3} \}$.
\item $R = \{ \bottom/ \childOf/ U_{1}, U_{1} \childOf/ U_{2}, U_{1} \childOf/ U_{3} \}$.

\end{itemize}

There are four generators ($\bottom/$, $U_{1}$, $U_{2}$, and $U_{3}$), and $\bottom/$ is below $U_{1}$ while $U_{1}$ is a sub-region of $U_{2}$ and $U_{3}$. Since $U_{1}$ is a sub-region of both $U_{2}$ and $U_{3}$, $U_{1}$ is their meet:

\begin{itemize}

\item $U_{1} = U_{2} \meet/ U_{3}$.

\end{itemize}

At this point, we have generated this much of the locale:

\begin{diagram}

\node (U2) at (-2, 1.5) {$U_{2}$};
\node (U3) at (2, 1.5) {$U_{3}$};
\node (U1) at (0, 0) {$U_{1}$};
\node (bottom) at (0, -1) {$\bottom/$};

\draw (bottom) to (U1);
\draw (U1) to (U2);
\draw (U1) to (U3);

\end{diagram}

$R$ says nothing to constrain joins, so we need to join everything we can. In this case, we need to join $U_{2}$ and $U_{3}$:

\begin{diagram}

\node (U2_v_U3) at (0, 3) {$U_{2} \join/ U_{3}$};
\node (U2) at (-2, 1.5) {$U_{2}$};
\node (U3) at (2, 1.5) {$U_{3}$};
\node (U1) at (0, 0) {$U_{1}$};
\node (bottom) at (0, -1) {$\bottom/$};

\draw (bottom) to (U1);
\draw (U1) to (U2);
\draw (U1) to (U3);
\draw (U2) to (U2_v_U3);
\draw (U3) to (U2_v_U3);

\end{diagram}

There are no further joins or meets that aren't already represented in the picture. For instance, all further non-trivial meets are already accounted for:

\begin{itemize}

\item $U_{1} \meet/ \bottom/ = \bottom/$.
\item $U_{2} \meet/ U_{1} = U_{1}$ and $U_{3} \meet/ U_{1} = U_{1}$.
\item $U_{2} \meet/ \bottom/ = \bottom/$ and $U_{3} \meet/ \bottom/ = \bottom/$.
\item $(U_{2} \join/ U_{3}) \meet/ U_{2} = U_{2}$ and $(U_{2} \join/ U_{3}) \meet/ U_{3} = U_{3}$.
\item $(U_{2} \join/ U_{3}) \meet/ U_{1} = U_{1}$.
\item $(U_{2} \join/ U_{3}) \meet/ \bottom/ = \bottom/$.

\end{itemize}

Similarly, all other non-trivial joins are also already accounted for:

\begin{itemize}

\item $\bottom/ \join/ U_{1} = U_{1}$.
\item $\bottom/ \join/ U_{2} = U_{2}$ and $\bottom/ \join/ U_{3} = U_{3}$.
\item $\bottom/ \join/ (U_{2} \join/ U_{3}) = U_{2} \join/ U_{3}$.
\item $U_{1} \join/ U_{2} = U_{2}$ and $U_{1} \join/ U_{3} = U_{3}$.
\item $U_{2} \join/ (U_{2} \join/ U_{3}) = U_{2} \join/ U_{3}$ and $U_{2} \join/ (U_{3} \join/ U_{3}) = U_{2} \join/ U_{3}$.

\end{itemize}

\end{Example}


% ----------------------------------------
\begin{Example}
\label{ex:three-element-discrete-frame}

Let $\category{L} = \tuple{G, R}$ be given by:

\begin{itemize}

\item $G = \{ U_{1}, U_{2}, U_{3} \}$.
\item $R = \EmptySet/$.

\end{itemize}

We have three generators ($U_{1}$, $U_{2}$, and $U_{3}$), and there are no relations restricting how those generators are related. Thus, the locale that is freely generated from this presentation is isomorphic to the power set of three elements:

\begin{diagram}

\node (123) at (0, 4.5) {$\top = U_{1} \join/ U_{2} \join/ U_{3}$};
\node (12) at (-2, 3) {$U_{1} \join/ U_{2}$};
\node (13) at (0, 3) {$U_{1} \join/ U_{3}$};
\node (23) at (2, 3) {$U_{2} \join/ U_{3}$};
\node (1) at (-2, 1.5) {$U_{1}$};
\node (2) at (0, 1.5) {$U_{2}$};
\node (3) at (2, 1.5) {$U_{3}$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw (bottom) to (1);
\draw (bottom) to (2);
\draw (bottom) to (3);
\draw (1) to (12);
\draw (1) to (13);
\draw (2) to (12);
\draw (2) to (23);
\draw (3) to (13);
\draw (3) to (23);
\draw (12) to (123);
\draw (13) to (123);
\draw (23) to (123);

\end{diagram}

\end{Example}

A presentation provides the most ``minimal'' information from which the rest of the locale is generated. It might be tempting to think that each generator is an atomic region, but that is not quite right. Some generators are reducible to others.

% ----------------------------------------
\begin{Definition}[Meet-irreducibility]

Given a presentation $\category{L} = \tuple{G, R}$, a region $U \in G$ is meet-reducible (``reducible'' for short) if it is the non-trivial meet of other regions:
\[ 
U = W \meet/ V \implies (V = U \text{ or } W = U).
\]

\noindent
$U$ is meet-irreducible (``irreducible'' for short) if it is not meet-reducible.

\end{Definition}

Intuitively, a generator is reducible if it can be expressed as the meet of strictly larger regions, which occurs exactly when it is their overlap.

\begin{Example}

Take the locale from \cref{ex:locale-with-overlap-and-bottom}. $U_{1}$ is the overlap of $U_{2}$ and $U_{3}$, and $U_{2}$ and $U_{3}$ are strictly larger regions than $U_{1}$, so $U_{1}$ is reducible.

By contrast, $U_{2}$ and $U_{3}$ are irreducible, because they cannot be expressed as the meet of two strictly larger regions. Similarly, $\bottom/$ is irreducible, because it is not the meet of two strictly larger regions either (it is the meet of only one strictly larger region, namely $U_{1}$). 

\end{Example}

We can see the minimal irreducible generators of a locale as its atomic regions.

% ----------------------------------------
\begin{Definition}[Atomic regions]

Given a presentation $\category{L} = \tuple{G, R}$, define the atomic regions of $\category{L}$, denoted $\atomsOf{\category{L}}$, as the minimal irreducible generators, i.e. those generators $g \in G$ that satisfy the following two conditions:

\begin{enumerate}

\item [(A1)] \emph{Meet-irreducibility}. $g$ is meet-irreducible.

\item [(A2)] \emph{Minimality}. There is no strictly smaller meet-irreducible $h$ with $h \childOf/ g$.

\end{enumerate}

\end{Definition} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Presheaves}

\noindent
Above we considered the fibers of a map $f : E \to B$, where $E$ and $B$ were sets. We can also consider fibers over locales, where the fibers respect the locale's structure. This is called a presheaf. A presheaf is an assignment of data to each of a locale's regions that is ``stable under restriction,'' i.e., that respects zooming in and out.

% ----------------------------------------
\begin{Definition}[Presheaf]

Let $\category{L}$ be a locale, and let $\morphisms/(\category{L})$ be $\{ \tuple{A, B} \mid A \childOf/ B \in \category{L} \}$. A presheaf on $\category{L}$ is a pair $\tuple{F, \{ \restrict{B}{A} \}_{\tuple{A, B} \in \morphisms/(\category{L})}}$, where:

\begin{itemize}

\item $F$ assigns to each region $U \in L$ some data $F(U)$.

\item $\{ \restrict{B}{A} \}_{\tuple{A, B} \in \morphisms/(\category{L})}$ is a family of maps $\restrict{B}{A} : F(B) \to F(A)$ (called ``restriction maps''), each of which specifies how to restrict the data over $F(B)$ down to the data over $F(A)$.

\end{itemize}

\noindent
All together, $\tuple{F, \{ \restrict{B}{A} \}_{\tuple{A, B} \in \morphisms/(\category{L})}}$ must satisfy the following conditions:

\begin{enumerate}

\item [(R1)] Restrictions preserve identity:
$$\restrict{U}{U} = \ident{U} \text{ (the identity on $U$), for every } U \in \category{L}.$$

\item [(R2)] Restrictions compose:
$$\text{If } A \childOf/ B \text{ and } B \childOf/ C, \text{ then } \restrict{C}{A} = \restrict{B}{A} \compose/ \restrict{C}{B}.$$

\end{enumerate}

\end{Definition}

Since $F$ assigns data $F(U)$ to each region $U \in \category{L}$, we can think of the $F(U)$s as the ``fibers'' over $\category{L}$, and the restriction maps as ``zoom in'' maps that go from bigger fibers down to smaller fibers.


% ----------------------------------------
\begin{Example}
\label{ex:presheaf}

Let $\category{L}$ be a locale $\{ \bottom/, W, V, U \}$ with the following structure:

\begin{diagram}

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw (bottom) to (V);
\draw (bottom) to (W);
\draw (V) to (U);
\draw (W) to (U);

\end{diagram}

Next, let's define a presheaf $F$ as follows:

\begin{itemize}

\item $F(U) = \{ a, b, c, d \}$, $F(V) = \{ a, b \}$, $F(W) = \{ c, d \}$, $F(\bottom/) = \{ \ast \}$.

\item Define $\restrict{U}{V}$ as the projection (send $a$ to $a$, $b$ to $b$, and the rest can go anywhere), and similarly for $\restrict{U}{W}$. Let $\restrict{U}{\bottom/}$, $\restrict{V}{\bottom/}$, and $\restrict{W}{\bottom/}$ send their data to $\{ \ast \}$, and let the rest be identities.

\end{itemize}

We can see $F$'s assignments as fibers over $\category{L}$ by drawing them over the regions they are assigned to. For instance, over $U$ we have $F(U)$, i.e., $\{ a, b, c, d \}$:

\begin{diagram}

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed] (bottom) to (V);
\draw[dashed] (bottom) to (W);
\draw[dashed] (V) to (U);
\draw[dashed] (W) to (U);

\draw (0, 3.25) to (0, 3.775);
\draw (0, 4.625) ellipse (1.1cm and 1.1cm);
\node[dot, label=above:{$a$}] at (-0.375, 4.1) {};
\node[dot, label=above:{$b$}] at (-0.375, 4.85) {};
\node[dot, label=above:{$c$}] at (0.375, 4.1) {};
\node[dot, label=above:{$d$}] at (0.375, 4.85) {};

\end{diagram}

Similarly, over $V$ and $W$, we have $F(V) = \{ a, b \}$ and $F(W) = \{ c, d \}$:

\begin{diagram}

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed] (bottom) to (V);
\draw[dashed] (bottom) to (W);
\draw[dashed] (V) to (U);
\draw[dashed] (W) to (U);

\draw (0, 3.25) to (0, 3.775);
\draw (0, 4.625) ellipse (1.1cm and 1.1cm);
\node[dot, label=above:{$a$}] at (-0.375, 4.1) {};
\node[dot, label=above:{$b$}] at (-0.375, 4.85) {};
\node[dot, label=above:{$c$}] at (0.375, 4.1) {};
\node[dot, label=above:{$d$}] at (0.375, 4.85) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] at (-2, 2.5) {};
\node[dot, label=above:{$b$}] at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$c$}] at (2, 2.5) {};
\node[dot, label=above:{$d$}] at (2, 3.25) {};

\end{diagram}

Finally, over $\bottom/$, we have a singleton set:

\begin{diagram}

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed] (bottom) to (V);
\draw[dashed] (bottom) to (W);
\draw[dashed] (V) to (U);
\draw[dashed] (W) to (U);

\draw (0, 3.25) to (0, 3.775);
\draw (0, 4.625) ellipse (1.1cm and 1.1cm);
\node[dot, label=above:{$a$}] at (-0.375, 4.1) {};
\node[dot, label=above:{$b$}] at (-0.375, 4.85) {};
\node[dot, label=above:{$c$}] at (0.375, 4.1) {};
\node[dot, label=above:{$d$}] at (0.375, 4.85) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] at (-2, 2.5) {};
\node[dot, label=above:{$b$}] at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$c$}] at (2, 2.5) {};
\node[dot, label=above:{$d$}] at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.25) ellipse (0.375cm and 0.575cm);
\node[dot, label=above:{$\ast$}] at (0, 1) {};

\end{diagram}

The restriction maps show how to ``zoom in'' on the parts (sub-fibers) of any given fiber. For instance, we can see that the fiber over $V$ is contained in the fiber over $U$. The restriction map just projects that sub-fiber out, thereby showing us how to ``zoom in'' on that sub-fiber:

\begin{diagram}

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed] (bottom) to (V);
\draw[dashed] (bottom) to (W);
\draw[dashed] (V) to (U);
\draw[dashed] (W) to (U);

\draw (0, 3.25) to (0, 3.775);
\draw (0, 4.625) ellipse (1.1cm and 1.1cm);
\node[dot, label=above:{$a$}] (Ua) at (-0.375, 4.1) {};
\node[dot, label=above:{$b$}] (Ub) at (-0.375, 4.85) {};
\node[dot, label=above:{$c$}] (Uc) at (0.375, 4.1) {};
\node[dot, label=above:{$d$}] (Ud) at (0.375, 4.85) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$c$}] (Wc) at (2, 2.5) {};
\node[dot, label=above:{$d$}] (Wd) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.25) ellipse (0.375cm and 0.575cm);
\node[dot, label=above:{$\ast$}] (bottom) at (0, 1) {};

\draw[dashed] (-0.375, 4.625) ellipse (0.375cm and 0.875cm);
\draw[dashed] (-0.375, 3.25) to (-0.375, 3.85);
\draw[arrow, ->] (Ub) to (Vb);
\draw[arrow, ->] (Ua) to (Va);
\node at (-1.675, 4.5) {$\restrict{U}{V}$};

\end{diagram}

It's similar for the fiber over $W$:

\begin{diagram}

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed] (bottom) to (V);
\draw[dashed] (bottom) to (W);
\draw[dashed] (V) to (U);
\draw[dashed] (W) to (U);

\draw (0, 3.25) to (0, 3.775);
\draw (0, 4.625) ellipse (1.1cm and 1.1cm);
\node[dot, label=above:{$a$}] (Ua) at (-0.375, 4.1) {};
\node[dot, label=above:{$b$}] (Ub) at (-0.375, 4.85) {};
\node[dot, label=above:{$c$}] (Uc) at (0.375, 4.1) {};
\node[dot, label=above:{$d$}] (Ud) at (0.375, 4.85) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$c$}] (Wc) at (2, 2.5) {};
\node[dot, label=above:{$d$}] (Wd) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.25) ellipse (0.375cm and 0.575cm);
\node[dot, label=above:{$\ast$}] (bottom) at (0, 1) {};

\draw[dashed] (0.375, 4.625) ellipse (0.375cm and 0.875cm);
\draw[dashed] (0.375, 3.25) to (0.375, 3.85);
\draw[arrow, ->] (Ud) to (Wd);
\draw[arrow, ->] (Uc) to (Wc);
\node at (1.675, 4.5) {$\restrict{U}{W}$};

\end{diagram}

Restricting a fiber to itself is just the identity on the fiber:

\begin{diagram}

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed] (bottom) to (V);
\draw[dashed] (bottom) to (W);
\draw[dashed] (V) to (U);
\draw[dashed] (W) to (U);

\draw (0, 3.25) to (0, 3.775);
\draw (0, 4.625) ellipse (1.1cm and 1.1cm);
\node[dot, label=above:{$a$}] (Ua) at (-0.375, 4.1) {};
\node[dot, label=above:{$b$}] (Ub) at (-0.375, 4.85) {};
\node[dot, label=above:{$c$}] (Uc) at (0.375, 4.1) {};
\node[dot, label=above:{$d$}] (Ud) at (0.375, 4.85) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$c$}] (Wc) at (2, 2.5) {};
\node[dot, label=above:{$d$}] (Wd) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.25) ellipse (0.375cm and 0.575cm);
\node[dot, label=above:{$\ast$}] (bottom) at (0, 1) {};

\draw[arrow, ->] (Vb) to[out=215,in=155,looseness=35] (Vb);
\draw[arrow, ->] (Va) to[out=215,in=155,looseness=35] (Va);
\node at (-3.175, 2.875) {$\restrict{V}{V}$};

\end{diagram}

The other restriction maps restrict down to the singleton set. For instance:

\begin{diagram}

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed] (bottom) to (V);
\draw[dashed] (bottom) to (W);
\draw[dashed] (V) to (U);
\draw[dashed] (W) to (U);

\draw (0, 3.25) to (0, 3.775);
\draw (0, 4.625) ellipse (1.1cm and 1.1cm);
\node[dot, label=above:{$a$}] (Ua) at (-0.375, 4.1) {};
\node[dot, label=above:{$b$}] (Ub) at (-0.375, 4.85) {};
\node[dot, label=above:{$c$}] (Uc) at (0.375, 4.1) {};
\node[dot, label=above:{$d$}] (Ud) at (0.375, 4.85) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$c$}] (Wc) at (2, 2.5) {};
\node[dot, label=above:{$d$}] (Wd) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.25) ellipse (0.375cm and 0.575cm);
\node[dot, label=above:{$\ast$}] (bottom) at (0, 1) {};

\draw[arrow, ->] (Vb) to (bottom);
\draw[arrow, ->] (Va) to (bottom);
\node at (-0.45, 2.15) {$\restrict{V}{\bottom/}$};

\end{diagram}

All of this makes it clear that the structure of the presheaf data that sits in the fibers over $\category{L}$ mimics (respects) the structure of the base locale:

\begin{diagram}

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed] (bottom) to (V);
\draw[dashed] (bottom) to (W);
\draw[dashed] (V) to (U);
\draw[dashed] (W) to (U);

\draw (0, 3.25) to (0, 3.775);
\draw (0, 4.625) ellipse (1.1cm and 1.1cm);
\node[dot, label=above:{$a$}] (Ua) at (-0.375, 4.1) {};
\node[dot, label=above:{$b$}] (Ub) at (-0.375, 4.85) {};
\node[dot, label=above:{$c$}] (Uc) at (0.375, 4.1) {};
\node[dot, label=above:{$d$}] (Ud) at (0.375, 4.85) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$c$}] (Wc) at (2, 2.5) {};
\node[dot, label=above:{$d$}] (Wd) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.25) ellipse (0.375cm and 0.575cm);
\node[dot, label=above:{$\ast$}] (bottom) at (0, 1) {};

\draw[arrow, ->] (Ub) to (Vb);
\draw[arrow, ->] (Ua) to (Va);
\node at (-1.675, 4.5) {$\restrict{U}{V}$};

\draw[arrow, ->] (Ud) to (Wd);
\draw[arrow, ->] (Uc) to (Wc);
\node at (1.675, 4.5) {$\restrict{U}{W}$};

\draw[arrow, ->] (Vb) to (bottom);
\draw[arrow, ->] (Va) to (bottom);
\node at (-0.45, 2.15) {$\restrict{V}{\bottom/}$};

\draw[arrow, ->] (Wd) to (bottom);
\draw[arrow, ->] (Wc) to (bottom);
\node at (0.45, 2.15) {$\restrict{W}{\bottom/}$};

\end{diagram}

\end{Example}

% ----------------------------------------
\begin{Remark}

In line with \cref{remark:section-terminology}, the elements of each fiber $F(U)$ are usually just called the ``sections'' of $F(U)$. For instance, $c$ is a section of $F(W)$, as is $d$.

\end{Remark}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Sheaves}

\noindent
The definition of a presheaf requires only that the data be stable under restriction (zooming in on a region). It does not require that the data fit together across different regions (fibers).

A sheaf is a presheaf with an added gluing condition: whenever you have compatible data on overlapping fibers, there must be a unique way to glue it together into data over the union. In other words, the data in the fibers must agree on overlap and combine coherently.

To get at this idea, let's first define a cover. A cover of a region $U$ is a selection of sub-regions that covers $U$ in its entirety. The chosen sub-regions don't leave any part of $U$ exposed.

% ----------------------------------------
\begin{Definition}[Cover]

Let $\category{L}$ be a topology or a locale, and let $U$ be a region of $\category{L}$. A cover of $U$ is a family $\{ U_{i} \}_{i \in I} \subseteq \category{L}$ such that:

$$U = \bigjoin/\limits_{i \in I} \{ U_{i} \}.$$

\noindent
In other words, a cover of $U$ is a family of regions that join together to form $U$.

\end{Definition}


% ----------------------------------------
\begin{Example}

Take the topology from \cref{ex:topology}: $T = \{ \EmptySet/$, $\{ b \}$, $\{ a, b \}$, $\{ b, c \}$, $\{a, b, c \} \}$. A cover of $\{ a, b, c \}$ is $\{ a, b \}$ and $\{ b, c \}$, because altogether, $\{ a, b \}$ and $\{ b, c \}$ cover all of the points in $\{ a, b, c \}$.

Another cover of $\{ a, b, c \}$ is $\{ \{ a, b \}, \{ b, c \}, \{ b \} \}$. Although $\{ b \}$ is redundant here, this choice of sub-regions still entirely covers $\{ a, b, c \}$ as required.

\end{Example}


% ----------------------------------------
\begin{Example}

In the context of frames, where there are no points, a cover of $U$ is just a selection of sub-regions of $U$ that together join together to form $U$. Take the locale from \cref{ex:presheaf}:

\begin{diagram}

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw (bottom) to (V);
\draw (bottom) to (W);
\draw (V) to (U);
\draw (W) to (U);

\end{diagram}

\noindent
A cover of $U$ is $\{ V, W \}$, since $U = \bigjoin/ \{ V, W \}$:

\begin{diagram}

\draw[fill=selected] (-2, 1.5) ellipse (0.5cm and 0.5cm);
\draw[fill=selected] (2, 1.5) ellipse (0.5cm and 0.5cm);

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {\textcolor{faded}{$\bottom/$}};

\draw[faded] (bottom) to (V);
\draw[faded] (bottom) to (W);
\draw (V) to (U);
\draw (W) to (U);

\end{diagram}

A cover of $V$ is just $\{ V \}$:

\begin{diagram}

\draw[fill=selected] (-2, 1.5) ellipse (0.5cm and 0.5cm);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {\textcolor{faded}{$W$}};
\node (bottom) at (0, 0) {\textcolor{faded}{$\bottom/$}};

\draw[faded] (bottom) to (V);
\draw[faded] (bottom) to (W);
\draw[faded] (V) to (U);
\draw[faded] (W) to (U);

\end{diagram}
 
\end{Example}


% ----------------------------------------
\begin{Remark}

A cover over the least element of a locale (or a topology) is empty (the empty set), because there are no regions (or points) to cover. 

\end{Remark}


Given a presheaf $F$ over a locale $\category{L}$, if we have a cover $\{ U_{i} \}_{i \in I}$ of some portion of $\category{L}$, there is a corresponding family of fibers $\{ F(U_{i}) \}_{i \in I}$ over that cover.  We can pick one section (i.e., one element) from each such fiber to get a slice of elements that spans all of the fibers over that cover. Let us call such a choice a selection of patch candidates.


% ----------------------------------------
\begin{Definition}[Patch candidates]

Given a presheaf $F$ and a cover $\{ U_{i} \}_{i \in I}$ with a corresponding family of fibers $\{ F(U_{i}) \}_{i \in I}$, a selection of patch candidates $\{ s_{i} \}_{i \in I}$ is a choice of one section $s_{i}$ from each $F(U_{i})$:

$$\{ s_{i} \}_{i \in I} = \{ s_{i} \mid s_{i} \in F(U_{i}) \text{ for each } F(U_{i}) \in \{ F(U_{i}) \}_{i \in I} \}.$$

\end{Definition}


% ----------------------------------------
\begin{Example}

Take the presheaf from \cref{ex:presheaf}:

\begin{diagram}

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed] (bottom) to (V);
\draw[dashed] (bottom) to (W);
\draw[dashed] (V) to (U);
\draw[dashed] (W) to (U);

\draw (0, 3.25) to (0, 3.775);
\draw (0, 4.625) ellipse (1.1cm and 1.1cm);
\node[dot, label=above:{$a$}] at (-0.375, 4.1) {};
\node[dot, label=above:{$b$}] at (-0.375, 4.85) {};
\node[dot, label=above:{$c$}] at (0.375, 4.1) {};
\node[dot, label=above:{$d$}] at (0.375, 4.85) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] at (-2, 2.5) {};
\node[dot, label=above:{$b$}] at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$c$}] at (2, 2.5) {};
\node[dot, label=above:{$d$}] at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.25) ellipse (0.375cm and 0.575cm);
\node[dot, label=above:{$\ast$}] at (0, 1) {};

\end{diagram}

Let $\{ V, W \}$ be the cover of interest:

\begin{diagram}

\draw[fill=selected] (-2, 1.5) ellipse (0.5cm and 0.5cm);
\draw[fill=selected] (2, 1.5) ellipse (0.5cm and 0.5cm);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {\textcolor{faded}{$\bottom/$}};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw[faded] (0, 3.25) to (0, 3.775);
\draw[faded] (0, 4.625) ellipse (1.1cm and 1.1cm);
\node[dot, label=above:{\textcolor{faded}{$a$}}, faded] at (-0.375, 4.1) {};
\node[dot, label=above:{\textcolor{faded}{$b$}}, faded] at (-0.375, 4.85) {};
\node[dot, label=above:{\textcolor{faded}{$c$}}, faded] at (0.375, 4.1) {};
\node[dot, label=above:{\textcolor{faded}{$d$}}, faded] at (0.375, 4.85) {};

\draw[faded] (-2, 1.75) to (-2, 2.275);
\draw[faded] (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{\textcolor{faded}{$a$}}, faded] at (-2, 2.5) {};
\node[dot, label=above:{\textcolor{faded}{$b$}}, faded] at (-2, 3.25) {};

\draw[faded] (2, 1.75) to (2, 2.275);
\draw[faded] (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{\textcolor{faded}{$c$}}, faded] at (2, 2.5) {};
\node[dot, label=above:{\textcolor{faded}{$d$}}, faded] at (2, 3.25) {};

\draw[faded] (0, 0.25) to (0, 0.75);
\draw[faded] (0, 1.25) ellipse (0.375cm and 0.575cm);
\node[dot, label=above:{\textcolor{faded}{$\ast$}}, faded] at (0, 1) {};

\end{diagram}

Over this cover, we have a corresponding family of fibers:

\begin{diagram}

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {\textcolor{faded}{$\bottom/$}};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw[faded] (0, 3.25) to (0, 3.775);
\draw[faded] (0, 4.625) ellipse (1.1cm and 1.1cm);
\node[dot, label=above:{\textcolor{faded}{$a$}}, faded] at (-0.375, 4.1) {};
\node[dot, label=above:{\textcolor{faded}{$b$}}, faded] at (-0.375, 4.85) {};
\node[dot, label=above:{\textcolor{faded}{$c$}}, faded] at (0.375, 4.1) {};
\node[dot, label=above:{\textcolor{faded}{$d$}}, faded] at (0.375, 4.85) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] at (-2, 2.5) {};
\node[dot, label=above:{$b$}] at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$c$}] at (2, 2.5) {};
\node[dot, label=above:{$d$}] at (2, 3.25) {};

\draw[faded] (0, 0.25) to (0, 0.75);
\draw[faded] (0, 1.25) ellipse (0.375cm and 0.575cm);
\node[dot, label=above:{\textcolor{faded}{$\ast$}}, faded] at (0, 1) {};

\end{diagram}

A selection of patch candidates is a choice of one section (element) from each fiber. For instance, we might pick $b$ from $F(V)$ and $c$ from $F(W)$:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.5, 3.4) rectangle (-1.5, 3.1);
\draw[rounded corners=4pt,fill=selected] (1.5, 2.65) rectangle (2.5, 2.35);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {\textcolor{faded}{$\bottom/$}};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw[faded] (0, 3.25) to (0, 3.775);
\draw[faded] (0, 4.625) ellipse (1.1cm and 1.1cm);
\node[dot, label=above:{\textcolor{faded}{$a$}}, faded] at (-0.375, 4.1) {};
\node[dot, label=above:{\textcolor{faded}{$b$}}, faded] at (-0.375, 4.85) {};
\node[dot, label=above:{\textcolor{faded}{$c$}}, faded] at (0.375, 4.1) {};
\node[dot, label=above:{\textcolor{faded}{$d$}}, faded] at (0.375, 4.85) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] at (-2, 2.5) {};
\node[dot, label=above:{$b$}] at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$c$}] at (2, 2.5) {};
\node[dot, label=above:{$d$}] at (2, 3.25) {};

\draw[faded] (0, 0.25) to (0, 0.75);
\draw[faded] (0, 1.25) ellipse (0.375cm and 0.575cm);
\node[dot, label=above:{\textcolor{faded}{$\ast$}}, faded] at (0, 1) {};

\end{diagram}

Similarly, we might pick $\{ a, d \}$, $\{ b, d \}$, or $\{a, c \}$, each of which is a valid selection of patching candidates.

\end{Example}

% ----------------------------------------
\begin{Remark}

Consider the empty cover. Since there are no sub-regions below the least element of a locale, there are no patch candidates we could choose for the empty cover either. Hence, any selection of patch candidates for the empty cover is $\EmptySet/$.

\end{Remark}


A selection of patch candidates might fit together, or they might not. We say they are compatible if they fit together, i.e., if they agree on overlaps. To check this, take any pair of patch candidates, and check if they restrict to the same data on their overlap.

% ----------------------------------------
\begin{Definition}[Compatible patch candidates]

Given two fibers $F(U_{i})$ and $F(U_{j})$ and a patch candidate from each, $s_{i} \in F(U_{i})$ and $s_{j} \in F(U_{j})$, $s_{i}$ and $s_{j}$ are compatible if they restrict to the same data on their overlap $U_{i} \meet/ U_{j}$:
$$\restrict{U_{i}}{U_{i} \meet/ U_{j}}(s_{i}) 
    = 
    \restrict{U_{j}}{U_{i} \meet/ U_{j}}(s_{j}).$$

\noindent
A selection of patch candidates $\{ s_{i} \}_{i \in I}$ is compatible if all of its members are pair-wise compatible.

\end{Definition}


% ----------------------------------------
\begin{Example}
\label{ex:compatible-patch-candidates}

Consider the following presheaf $F$:

\begin{diagram}

\node (U) at (0, 3) {$U$};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed] (bottom) to (V);
\draw[dashed] (bottom) to (W);
\draw[dashed] (V) to (U);
\draw[dashed] (W) to (U);

\draw (0, 3.25) to (0, 3.75);
\draw (0, 4.925) ellipse (0.425cm and 1.325cm);
\node[dot, label=above:{$a$}] (Ua) at (0, 4) {};
\node[dot, label=above:{$b$}] (Ub) at (0, 4.75) {};
\node[dot, label=above:{$c$}] (Uc) at (0, 5.5) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.5) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$p$}] (bottomp) at (0, 1) {};
\node[dot, label=above:{$q$}] (bottomq) at (0, 1.75) {};

\draw[arrow, ->] (Uc) to (Vb);
\draw[arrow, ->] (Ub) to (Vb);
\draw[arrow, ->] (Ua) to (Va);
\node at (-1.25, 4.5) {$\restrict{U}{V}$};

\draw[arrow, ->] (Ua) to (Wb);
\draw[arrow, ->] (Ub) to (Wb);
\draw[arrow, ->] (Uc) to (Wc);
\node at (1.675, 4.5) {$\restrict{U}{W}$};

\draw[arrow, ->] (Vb) to (bottomq);
\draw[arrow, ->] (Va) to (bottomp);
\node at (-1.25, 1.5) {$\restrict{V}{\bottom/}$};

\draw[arrow, ->] (Wb) to (bottomq);
\draw[arrow, ->] (Wc) to (bottomp);
\node at (1, 1.5) {$\restrict{W}{\bottom/}$};

\end{diagram}

Take the cover $\{ V, W \}$ and its corresponding fibers:

\begin{diagram}

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {\textcolor{faded}{$\bottom/$}};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\end{diagram}

Suppose we pick $\{ a, c \}$ for patch candidates:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.5, 2.65) rectangle (-1.5, 2.35);
\draw[rounded corners=4pt,fill=selected] (1.5, 3.4) rectangle (2.5, 3.1);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {\textcolor{faded}{$\bottom/$}};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\end{diagram}

Is this selection compatible? We have to check if they agree on their overlap. The overlap $V \meet/ W$ is $\bottom/$. Where does $\restrict{V}{\bottom/}$ send our chosen patch candidate $a$? It sends it to $p$, since $\restrict{V}{\bottom/}(a) = p$. Where does $\restrict{W}{\bottom/}$ send our other chosen patch candidate $b$? It also sends it to $p$, since $\restrict{W}{\bottom/}(c) = p$. On the overlap $\bottom/$ then, $\restrict{V}{\bottom/}(a) = \restrict{W}{\bottom/}(c)$, so $a$ and $c$ are compatible. This is easy to see in the diagram, since $a$ and $b$ both get sent to the same place:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.5, 2.65) rectangle (-1.5, 2.35);
\draw[rounded corners=4pt,fill=selected] (1.5, 3.4) rectangle (2.5, 3.1);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.5) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$p$}] (bottomp) at (0, 1) {};
\node[dot, label=above:{\textcolor{faded}{$q$}}, faded] (bottomq) at (0, 1.75) {};

\draw[arrow, ->, faded] (Vb) to (bottomq);
\draw[arrow, ->] (Va) to (bottomp);
\node at (-1.25, 1.5) {$\restrict{V}{\bottom/}$};

\draw[arrow, ->, faded] (Wb) to (bottomq);
\draw[arrow, ->] (Wc) to (bottomp);
\node at (1, 1.5) {$\restrict{W}{\bottom/}$};

\end{diagram}

Now suppose we pick $\{ b, b \}$ for patch candidates:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.5, 3.4) rectangle (-1.5, 3.1);
\draw[rounded corners=4pt,fill=selected] (1.5, 2.65) rectangle (2.5, 2.35);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {\textcolor{faded}{$\bottom/$}};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\end{diagram}

These are also compatible. They agree on their overlap (both restrict to $q$):

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.5, 3.4) rectangle (-1.5, 3.1);
\draw[rounded corners=4pt,fill=selected] (1.5, 2.65) rectangle (2.5, 2.35);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.5) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{\textcolor{faded}{$p$}}, faded] (bottomp) at (0, 1) {};
\node[dot, label=above:{$q$}] (bottomq) at (0, 1.75) {};

\draw[arrow, ->] (Vb) to (bottomq);
\draw[arrow, ->, faded] (Va) to (bottomp);
\node at (-1.25, 1.5) {$\restrict{V}{\bottom/}$};

\draw[arrow, ->, faded] (Wc) to (bottomp);
\draw[arrow, ->] (Wb) to (bottomq);
\node at (1, 1.5) {$\restrict{W}{\bottom/}$};

\end{diagram}

Finally, suppose we pick $\{ a, b \}$ for patch candidates:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.5, 2.65) rectangle (-1.5, 2.35);
\draw[rounded corners=4pt,fill=selected] (1.5, 2.65) rectangle (2.5, 2.35);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {\textcolor{faded}{$\bottom/$}};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\end{diagram}

These are not compatible. They do not agree on their overlap:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.5, 2.65) rectangle (-1.5, 2.35);
\draw[rounded corners=4pt,fill=selected] (1.5, 2.65) rectangle (2.5, 2.35);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.5) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$p$}] (bottomp) at (0, 1) {};
\node[dot, label=above:{$q$}] (bottomq) at (0, 1.75) {};

\draw[arrow, ->, faded] (Vb) to (bottomq);
\draw[arrow, ->] (Va) to (bottomp);
\node at (-1.25, 1.5) {$\restrict{V}{\bottom/}$};

\draw[arrow, ->, faded] (Wc) to (bottomp);
\draw[arrow, ->] (Wb) to (bottomq);
\node at (1, 1.5) {$\restrict{W}{\bottom/}$};

\end{diagram}

\end{Example}

% ----------------------------------------
\begin{Remark}

Consider the empty cover. Since any selection of patch candidates for the empty cover is empty, compatibility is satisfied vacuously. 

As an analogy, if you ask your class to turn off all cell phones but nobody brought a cell phone to glass, then your request is satisfied vacuously: there is simply nothing that needs to be done to make it happen. It's similar with the empty cover: since there are patch candidates to check, compatibility is achieved vacuously.

\end{Remark}


If a selection of patch candidates $s_{i}$, \ldots, $s_{k}$ across a cover of $U$ is compatible, we say those patches glue together if if there's a section $s$ in $F(U)$ that restricts down to exactly those patches.

% ----------------------------------------
 \begin{Definition}[Gluing]

Given a presheaf $F$ and a selection of compatible patch candidates $\{ s_{i} \}_{i \in I}$ for a cover $\{ U_{i} \}_{i \in I}$, $\{ s_{i} \}_{i \in I}$ glue together only if there is a section $s \in F(U)$ that restricts down to $s_{i}$ on each fiber $F(U_{i})$ of the cover, i.e., only if $s$ is such that:
\[
\restrict{U}{U_{i}}(s) = s_{i}, \text{ for each } i \in I.
\]

\noindent
As a matter of terminology, if a section $s \in F(U)$ is glued from patches $\{ s_{i} \}_{i \in I}$, we say that $s$ is a global section of the cover, and each $s_{i}$ is a local section of the cover. We may also say variously that $s$ is \emph{glued from} those patches, that $s$ is \emph{composed} of those pathes, that those patches \emph{compose} $s$, or that gluing those patches \emph{yields} $s$.

A selection of patches $\{ s_{i} \}_{i \in I}$ glues uniquely if there is one and only one such section $s \in F(U)$ that is glued from them.
 
\end{Definition}


% ----------------------------------------
\begin{Example}
\label{ex:gluing}
 
Take the presheaf from \cref{ex:compatible-patch-candidates}, and consider the cover $\{ V, W \}$ again. Take the the selection of patches $\{ a, c \}$, which are compatible because they agree on overlap:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.5, 2.65) rectangle (-1.5, 2.35);
\draw[rounded corners=4pt,fill=selected] (1.5, 3.4) rectangle (2.5, 3.1);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw[faded] (0, 3.25) to (0, 3.75);
\draw[faded] (0, 4.925) ellipse (0.425cm and 1.325cm);
\node[dot, label=above:{\textcolor{faded}{$a$}}, faded] (Ua) at (0, 4) {};
\node[dot, label=above:{\textcolor{faded}{$b$}}, faded] (Ub) at (0, 4.75) {};
\node[dot, label=above:{\textcolor{faded}{$c$}}, faded] (Uc) at (0, 5.5) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.5) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$p$}] (bottomp) at (0, 1) {};
\node[dot, label=above:{\textcolor{faded}{$q$}}, faded] (bottomq) at (0, 1.75) {};

(\draw[arrow,->, faded] (Uc) to (Vb);
\draw[arrow, ->, faded] (Ub) to (Vb);
\draw[arrow, ->, faded] (Ua) to (Va);
\node at (-1.25, 4.5) {\textcolor{faded}{$\restrict{U}{V}$}};

\draw[arrow, ->, faded] (Ua) to (Wb);
\draw[arrow, ->, faded] (Ub) to (Wb);
\draw[arrow, ->, faded] (Uc) to (Wc);
\node at (1.675, 4.5) {\textcolor{faded}{$\restrict{U}{W}$}};

\draw[arrow, ->, faded] (Vb) to (bottomq);
\draw[arrow, ->] (Va) to (bottomp);
\node at (-1.25, 1.5) {$\restrict{V}{\bottom/}$};

\draw[arrow, ->, faded] (Wb) to (bottomq);
\draw[arrow, ->] (Wc) to (bottomp);
\node at (1, 1.5) {$\restrict{W}{\bottom/}$};

\end{diagram}

Even though $a$ and $c$ are compatible, they do not glue together, because there is no section in $F(U)$ that restricts down to them. Consider $a \in F(U)$ first. It restricts to $a \in F(V)$ on the left, but it does not restrict to $c \in F(W)$ on the right:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.5, 2.65) rectangle (-1.5, 2.35);
\draw[rounded corners=4pt,fill=selected] (1.5, 3.4) rectangle (2.5, 3.1);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw[faded] (0, 3.25) to (0, 3.75);
\draw[faded] (0, 4.925) ellipse (0.425cm and 1.325cm);
\node[dot, label=above:{$a$}] (Ua) at (0, 4) {};
\node[dot, label=above:{\textcolor{faded}{$b$}}, faded] (Ub) at (0, 4.75) {};
\node[dot, label=above:{\textcolor{faded}{$c$}}, faded] (Uc) at (0, 5.5) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.5) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$p$}] (bottomp) at (0, 1) {};
\node[dot, label=above:{\textcolor{faded}{$q$}}, faded] (bottomq) at (0, 1.75) {};

\draw[arrow, ->, faded] (Vb) to (bottomq);
\draw[arrow, ->] (Va) to (bottomp);
\node at (-1.25, 1.5) {$\restrict{V}{\bottom/}$};

\draw[arrow, ->, faded] (Wb) to (bottomq);
\draw[arrow, ->] (Wc) to (bottomp);
\node at (1, 1.5) {$\restrict{W}{\bottom/}$};

(\draw[arrow,->, faded] (Uc) to (Vb);
\draw[arrow, ->, faded] (Ub) to (Vb);
\draw[arrow, ->] (Ua) to (Va);
\node at (-1.25, 4.5) {\textcolor{faded}{$\restrict{U}{V}$}};

\draw[arrow, ->] (Ua) to (Wb);
\draw[arrow, ->, faded] (Ub) to (Wb);
\draw[arrow, ->, faded] (Uc) to (Wc);
\node at (1.675, 4.5) {\textcolor{faded}{$\restrict{U}{W}$}};

\draw[ultra thick, wrong] (-0.3, 4.3) to (0.3, 3.6);
\draw[ultra thick, wrong] (0.3, 4.3) to (-0.3, 3.6);

\end{diagram}

As for $b \in F(U)$, it restricts to neither $a \in F(V)$  on the left nor $c \in F(W)$ on the right:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.5, 2.65) rectangle (-1.5, 2.35);
\draw[rounded corners=4pt,fill=selected] (1.5, 3.4) rectangle (2.5, 3.1);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw[faded] (0, 3.25) to (0, 3.75);
\draw[faded] (0, 4.925) ellipse (0.425cm and 1.325cm);
\node[dot, label=above:{\textcolor{faded}{$a$}}, faded] (Ua) at (0, 4) {};
\node[dot, label=above:{$b$}] (Ub) at (0, 4.75) {};
\node[dot, label=above:{\textcolor{faded}{$c$}}, faded] (Uc) at (0, 5.5) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.5) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$p$}] (bottomp) at (0, 1) {};
\node[dot, label=above:{\textcolor{faded}{$q$}}, faded] (bottomq) at (0, 1.75) {};

\draw[arrow, ->, faded] (Vb) to (bottomq);
\draw[arrow, ->] (Va) to (bottomp);
\node at (-1.25, 1.5) {$\restrict{V}{\bottom/}$};

\draw[arrow, ->, faded] (Wb) to (bottomq);
\draw[arrow, ->] (Wc) to (bottomp);
\node at (1, 1.5) {$\restrict{W}{\bottom/}$};

(\draw[arrow,->, faded] (Uc) to (Vb);
\draw[arrow, ->] (Ub) to (Vb);
\draw[arrow, ->, faded] (Ua) to (Va);
\node at (-1.25, 4.5) {\textcolor{faded}{$\restrict{U}{V}$}};

\draw[arrow, ->, faded] (Ua) to (Wb);
\draw[arrow, ->] (Ub) to (Wb);
\draw[arrow, ->, faded] (Uc) to (Wc);
\node at (1.675, 4.5) {\textcolor{faded}{$\restrict{U}{W}$}};

\draw[ultra thick, wrong] (-0.3, 5.2) to (0.3, 4.6);
\draw[ultra thick, wrong] (0.3, 5.2) to (-0.3, 4.6);

\end{diagram}

Finally, $c \in F(U)$ restricts to $c \in F(W)$ on the right, but not to $a \in F(V)$ on the left:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.5, 2.65) rectangle (-1.5, 2.35);
\draw[rounded corners=4pt,fill=selected] (1.5, 3.4) rectangle (2.5, 3.1);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw[faded] (0, 3.25) to (0, 3.75);
\draw[faded] (0, 4.925) ellipse (0.425cm and 1.325cm);
\node[dot, label=above:{\textcolor{faded}{$a$}}, faded] (Ua) at (0, 4) {};
\node[dot, label=above:{\textcolor{faded}{$b$}}, faded] (Ub) at (0, 4.75) {};
\node[dot, label=above:{$c$}] (Uc) at (0, 5.5) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.5) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$p$}] (bottomp) at (0, 1) {};
\node[dot, label=above:{\textcolor{faded}{$q$}}, faded] (bottomq) at (0, 1.75) {};

\draw[arrow, ->, faded] (Vb) to (bottomq);
\draw[arrow, ->] (Va) to (bottomp);
\node at (-1.25, 1.5) {$\restrict{V}{\bottom/}$};

\draw[arrow, ->, faded] (Wb) to (bottomq);
\draw[arrow, ->] (Wc) to (bottomp);
\node at (1, 1.5) {$\restrict{W}{\bottom/}$};

(\draw[arrow,->] (Uc) to (Vb);
\draw[arrow, ->, faded] (Ub) to (Vb);
\draw[arrow, ->, faded] (Ua) to (Va);
\node at (-1.25, 4.5) {\textcolor{faded}{$\restrict{U}{V}$}};

\draw[arrow, ->, faded] (Ua) to (Wb);
\draw[arrow, ->, faded] (Ub) to (Wb);
\draw[arrow, ->] (Uc) to (Wc);
\node at (1.675, 4.5) {\textcolor{faded}{$\restrict{U}{W}$}};

\draw[ultra thick, wrong] (-0.3, 5.9) to (0.3, 5.3);
\draw[ultra thick, wrong] (0.3, 5.9) to (-0.3, 5.3);

\end{diagram}

Thus, none of $a$, $b$, or $c$ in $F(U)$ are glued from $\{ a, c \}$, because none of them decompose into $a$ on the left and $c$ on the right.

Now suppose we pick $\{ b, b \}$ for patch candidates. These do glue together (trivially), because there is a section in $F(U)$ (namely $b \in F(U)$) that restricts down to $b \in F(V)$ on the left and $b \in F(W)$ on the right:

\begin{diagram}

\draw[rounded corners=4pt,fill=selected] (-2.5, 3.4) rectangle (-1.5, 3.1);
\draw[rounded corners=4pt,fill=selected] (1.5, 2.65) rectangle (2.5, 2.35);

\node (U) at (0, 3) {\textcolor{faded}{$U$}};
\node (V) at (-2, 1.5) {$V$};
\node (W) at (2, 1.5) {$W$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw[dashed,faded] (bottom) to (V);
\draw[dashed,faded] (bottom) to (W);
\draw[dashed,faded] (V) to (U);
\draw[dashed,faded] (W) to (U);

\draw[faded] (0, 3.25) to (0, 3.75);
\draw[faded] (0, 4.925) ellipse (0.425cm and 1.325cm);
\node[dot, label=above:{\textcolor{faded}{$a$}}, faded] (Ua) at (0, 4) {};
\node[dot, label=above:{$b$}] (Ub) at (0, 4.75) {};
\node[dot, label=above:{\textcolor{faded}{$c$}}, faded] (Uc) at (0, 5.5) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$a$}] (Va) at (-2, 2.5) {};
\node[dot, label=above:{$b$}] (Vb) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2, 3.1) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{$b$}] (Wb) at (2, 2.5) {};
\node[dot, label=above:{$c$}] (Wc) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.75);
\draw (0, 1.5) ellipse (0.375cm and 0.875cm);
\node[dot, label=above:{\textcolor{faded}{$p$}}, faded] (bottomp) at (0, 1) {};
\node[dot, label=above:{$q$}] (bottomq) at (0, 1.75) {};

\draw[arrow, ->, faded] (Uc) to (Vb);
\draw[arrow, ->] (Ub) to (Vb);
\draw[arrow, ->, faded] (Ua) to (Va);
\node at (-1.25, 4.5) {\textcolor{faded}{$\restrict{U}{V}$}};

\draw[arrow, ->, faded] (Ua) to (Wb);
\draw[arrow, ->] (Ub) to (Wb);
\draw[arrow, ->, faded] (Uc) to (Wc);
\node at (1.675, 4.5) {\textcolor{faded}{$\restrict{U}{W}$}};

\draw[arrow, ->] (Vb) to (bottomq);
\draw[arrow, ->, faded] (Va) to (bottomp);
\node at (-1.25, 1.5) {$\restrict{V}{\bottom/}$};

\draw[arrow, ->, faded] (Wc) to (bottomp);
\draw[arrow, ->] (Wb) to (bottomq);
\node at (1, 1.5) {$\restrict{W}{\bottom/}$};

\end{diagram}
 
\end{Example}

% ----------------------------------------
\begin{Example}
\label{ex:robot}

Consider an example that glues together behaviors. Imagine a toy robot that looks something like a small tank: it has tracks on the left and right sides, and the two tracks are connected by a single drive controller. The controller either drives at a constant speed, or it sits idle. When it drives, it turns both tracks at the same speed.

Let's represent the robot as a locale. Let $LT$ and $RT$ be the left and right track assemblies respectively, let $D$ be the drive controller that is shared by $LT$ and $RT$, and let $R$ be the whole robot (the join of $LT$ and $RT$). As a picture:

\begin{diagram}

\node (R) at (0, 3) {$R$};
\node (LT) at (-2, 1.5) {$LT$};
\node (RT) at (2, 1.5) {$RT$};
\node (D) at (0, 0) {$D$};

\draw[] (D) to (LT);
\draw[] (D) to (RT);
\draw[] (LT) to (R);
\draw[] (RT) to (R);

\end{diagram}

For a presheaf, let's assign to each region the behaviors that are locally observable at that region:

\begin{itemize}

\item The drive controller $D$ can either $drive$ (turn) or sit $idle$. 
\item The left track assembly can each either $rotate_{L}$ or $stand_{L}$ still.
\item The right track assembly can also either $rotate_{R}$ or $stand_{R}$ still.
\item The entire robot can either $move$ (forward) or $sit$ stationary.

\end{itemize}

\noindent
In a picture:

\begin{diagram}

\node (R) at (0, 3) {$R$};
\node (LT) at (-2, 1.5) {$LT$};
\node (RT) at (2, 1.5) {$RT$};
\node (D) at (0, 0) {$D$};

\draw[dashed] (D) to (LT);
\draw[dashed] (D) to (RT);
\draw[dashed] (LT) to (R);
\draw[dashed] (RT) to (R);

\draw (0, 3.25) to (0, 3.75);
\draw (0, 4.5) ellipse (0.75cm and 1cm);
\node[dot, label=above:{\small{$sit$}}] (sit) at (0, 4.75) {};
\node[dot, label=above:{\small{$move$}}] (move) at (0, 4) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2.5, 2.9) ellipse (1cm and 0.8cm);
\node[dot, label=left:{\small{$rotate_{L}$}}] (left-turn) at (-2, 2.6) {};
\node[dot, label=left:{\small{$stand_{L}$}}] (left-stand) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2.5, 2.9) ellipse (1cm and 0.8cm);
\node[dot, label=right:{\small{$rotate_{R}$}}] (right-turn) at (2, 2.6) {};
\node[dot, label=right:{\small{$stand_{R}$}}] (right-stand) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.5);
\draw (0, 1.5) ellipse (0.75cm and 1cm);
\node[dot, label=below:{\small{$drive$}}] (drive) at (0, 1.25) {};
\node[dot, label=below:{\small{$idle$}}] (idle) at (0, 2) {};

\end{diagram}

For the restriction maps, let's say that they restrict the observable behavior of a larger region to the observable behavior of the smaller region. For instance, if you are observing the whole robot moving forward ($move$), and you then ``zoom in'' on the left track assembly, you'll see those tracks rotating ($rotate_{L}$).

\begin{itemize}

\item $\restrict{R}{LT}(sit) = stand_{L}$, $\restrict{R}{LT}(move) = rotate_{L}$.
\item $\restrict{R}{RT}(sit) = stand_{R}$, $\restrict{R}{RT}(move) = rotate_{R}$.
\item $\restrict{LT}{D}(stand_{L}) = idle$, $\restrict{LT}{D}(rotate_{L}) = drive$.
\item $\restrict{RT}{D}(stand_{R}) = idle$, $\restrict{RT}{D}(rotate_{R}) = drive$.

\end{itemize}

In a picture:

\begin{diagram}

\node (R) at (0, 3) {$R$};
\node (LT) at (-2, 1.5) {$LT$};
\node (RT) at (2, 1.5) {$RT$};
\node (D) at (0, 0) {$D$};

\draw[dashed] (D) to (LT);
\draw[dashed] (D) to (RT);
\draw[dashed] (LT) to (R);
\draw[dashed] (RT) to (R);

\draw (0, 3.25) to (0, 3.75);
\draw (0, 4.5) ellipse (0.75cm and 1cm);
\node[dot, label=above:{\small{$sit$}}] (sit) at (0, 4.75) {};
\node[dot, label=above:{\small{$move$}}] (move) at (0, 4) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2.5, 2.9) ellipse (1cm and 0.8cm);
\node[dot, label=left:{\small{$rotate_{L}$}}] (left-turn) at (-2, 2.6) {};
\node[dot, label=left:{\small{$stand_{L}$}}] (left-stand) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2.5, 2.9) ellipse (1cm and 0.8cm);
\node[dot, label=right:{\small{$rotate_{R}$}}] (right-turn) at (2, 2.6) {};
\node[dot, label=right:{\small{$stand_{R}$}}] (right-stand) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.5);
\draw (0, 1.5) ellipse (0.75cm and 1cm);
\node[dot, label=below:{\small{$drive$}}] (drive) at (0, 1.25) {};
\node[dot, label=below:{\small{$idle$}}] (idle) at (0, 2) {};

\draw[arrow, ->] (move) to (left-turn);
\draw[arrow, ->] (sit) to (left-stand);
\node at (-1.65, 4.375) {$\restrict{R}{LT}$};

\draw[arrow, ->] (move) to (right-turn);
\draw[arrow, ->] (sit) to (right-stand);
\node at (1.65, 4.375) {$\restrict{R}{RT}$};

\draw[arrow, ->] (left-turn) to (drive);
\draw[arrow, ->] (left-stand) to (idle);
\node at (-1.25, 1.5) {$\restrict{LT}{D}$};

\draw[arrow, ->] (right-turn) to (drive);
\draw[arrow, ->] (right-stand) to (idle);
\node at (1.25, 1.5) {$\restrict{RT}{D}$};

\end{diagram}

Now take the cover $\{ LT, RT \}$ of $R$. The patch candidates $\{ rotate_{L}, rotate_{R} \}$ are compatible, because they agree on overlap (they both restrict down to $drive$). But they also glue uniquely, yielding $move$. In other words, the robot's forward motion is patched together precisely from the two pieces of its cover, namely the left tracks rotating ($rotate_{L}$) and the right tracks rotating ($rotate_{R}$).

Similarly, the Robot's $sit$ behavior is also glued from the two pieces of its cover, namely the left track assembly standing still ($stand_{L}$) and the right track assembly standing still ($stand_{R}$).

Thus, there are two global sections of $R$'s behavior: moving forwards (patched together from its left and right motions), or standing still (patched together from its left and right lack of motion). 

\end{Example}
 
We can now state what it is to be a sheaf. A sheaf is a presheaf that satisfies a special gluing condition: namely, that for every cover, every compatible selection of patch candidates glues together uniquely.
 
% ----------------------------------------
\begin{Definition}[Sheaf]
 
A presheaf $F$ is a sheaf iff it satisfies the following condition (called ``the gluing condition''):

\begin{enumerate}

\item [(G0)] For every cover $\{ U_{i} \}_{i \in I}$ of a region $U$ and every selection of patch candidates $\{ s_{i} \}_{i \in I}$ for that cover, if $\{ s_{i} \}_{i \in I}$ can glue, then $\{ s_{i} \}_{i \in I}$ glue to yield a unique $s \in F(U)$.

\end{enumerate}
 
\end{Definition}

% ----------------------------------------
\begin{Remark}

There is a subtlety regarding what sheaves look like over the least element of a locale. Note that the gluing condition is formulated as an implication. That is to say, it says that, for every cross-section of patch candidates, \emph{if} that cross-section can glue, \emph{then} it glues in exactly one way. 

Next, consider the fact that the cover over the least region of a locale is an empty cover. Since there are no patch candidates that need to be checked for compatibility, there is nothing that needs to be done to get a ``selection of gluable patch candidates.'' Hence, the antecedent of the gluing condition is satisfied vacuously over the least element of the locale.

But since the empty cover satisfies the antecedent of the gluing condition vacuously, it follows that if a presheaf is to qualify as a sheaf, it must ensure that the consequent is satisfied over the empty cover as well. In other words, it must assign a unique glued section (a singleton set) to the least region of the locale. So, even though a \emph{presheaf} may assign a larger set of data to the least element of a locale, a \emph{sheaf} always assigns a singleton to that region.

\end{Remark}


% ----------------------------------------
\begin{Example}

The presheaf from \cref{ex:compatible-patch-candidates} fails to be sheaf, because as we saw in \cref{ex:gluing}, there is a compatible selection of patch candidates (namely, $\{ a, c \}$) which fails to glue. To be a sheaf, every compatible selection of patch candidates must glue.

\end{Example}

% ----------------------------------------
\begin{Example}
\label{ex:robot-sheaf}

The presheaf from \cref{ex:robot} fails to be a sheaf, because it does not assign a singleton to the lowest region of the underlying locale. In that example $D$ is the lowest region of the locale, and $F(D) = \{ p, q \}$, a set containing two elements. Hence, $F$ fails to be a sheaf.

However, suppose we add a distinct bottom element to the locale:

\begin{diagram}

\node (R) at (0, 3) {$R$};
\node (LT) at (-2, 1.5) {$LT$};
\node (RT) at (2, 1.5) {$RT$};
\node (D) at (0, 0) {$D$};
\node (bottom) at (0, -1) {$\bottom/$};

\draw[] (D) to (bottom);
\draw[] (D) to (LT);
\draw[] (D) to (RT);
\draw[] (LT) to (R);
\draw[] (RT) to (R);

\end{diagram}

If we assign a singleton set to $\bottom/$ (so that $F(\bottom/) = \{ \ast \}$, say), then $F$ looks like this:

\begin{diagram}

\node (R) at (0, 3) {$R$};
\node (LT) at (-2, 1.5) {$LT$};
\node (RT) at (2, 1.5) {$RT$};
\node (D) at (0, 0) {$D$};
\node (bottom) at (0, -1.5) {$\bottom/$};

\draw[dashed] (D) to (bottom);
\draw[dashed] (D) to (LT);
\draw[dashed] (D) to (RT);
\draw[dashed] (LT) to (R);
\draw[dashed] (RT) to (R);

\draw (0, 3.25) to (0, 3.75);
\draw (0, 4.5) ellipse (0.75cm and 1cm);
\node[dot, label=above:{\small{$sit$}}] (sit) at (0, 4.75) {};
\node[dot, label=above:{\small{$move$}}] (move) at (0, 4) {};

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2.5, 2.9) ellipse (1cm and 0.8cm);
\node[dot, label=left:{\small{$rotate_{L}$}}] (left-turn) at (-2, 2.6) {};
\node[dot, label=left:{\small{$stand_{L}$}}] (left-stand) at (-2, 3.25) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2.5, 2.9) ellipse (1cm and 0.8cm);
\node[dot, label=right:{\small{$rotate_{R}$}}] (right-turn) at (2, 2.6) {};
\node[dot, label=right:{\small{$stand_{R}$}}] (right-stand) at (2, 3.25) {};

\draw (0, 0.25) to (0, 0.5);
\draw (0, 1.5) ellipse (0.75cm and 1cm);
\node[dot, label=below:{\small{$drive$}}] (drive) at (0, 1.25) {};
\node[dot, label=below:{\small{$idle$}}] (idle) at (0, 2) {};

\draw (0.25, -1.5) to (0.75, -1);
\draw (0.75, -0.65) ellipse (0.35cm and 0.5cm);
\node[dot, label=below:{\small{$\ast $}}] (asterisk) at (0.75, -0.575) {};

\draw[arrow, ->] (move) to (left-turn);
\draw[arrow, ->] (sit) to (left-stand);
\node at (-1.65, 4.375) {$\restrict{R}{LT}$};

\draw[arrow, ->] (move) to (right-turn);
\draw[arrow, ->] (sit) to (right-stand);
\node at (1.65, 4.375) {$\restrict{R}{RT}$};

\draw[arrow, ->] (left-turn) to (drive);
\draw[arrow, ->] (left-stand) to (idle);
\node at (-1.25, 1.5) {$\restrict{LT}{D}$};

\draw[arrow, ->] (right-turn) to (drive);
\draw[arrow, ->] (right-stand) to (idle);
\node at (1.25, 1.5) {$\restrict{RT}{D}$};

\draw[arrow, ->] (idle) to[out=325, in=80] (asterisk);
\draw[arrow, ->] (drive) to[out=335, in=85] (asterisk);
\node at (1.275, 0.25) {$\restrict{D}{\bottom/}$};

\end{diagram}

\noindent
This modification ensures that $F$ qualifies as a sheaf, since it ensures that \emph{all} gluable selections of patch candidates (including the empty one) glue uniquely.

\end{Example}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{A Canonical Sheaf Construction}

\noindent
Not every presheaf is a sheaf, since some presheaves fail the gluing condition. However, there is a canonical procedure called ``sheafification'' that turns any presheaf into a sheaf. To sheafify a presheaf, add any missing sections that glue, then quotient sections that are locally indistinguishable. The result is guaranteed to be a sheaf, by construction. 

For our purposes, there is a simplified version of sheafification that we can use to construct sheaves that model part-whole complexes in a natural way. Given a presentation of a locale, the recipe to build such a sheaf over it goes like this:

\begin{enumerate}

\item Assign local data to atomic regions.
\item Specify a gluing condition.
\item Recursively glue more and more pieces together until you can't glue any more.

\end{enumerate}

Let's make this more precise. Given a presented locale, we can uniquely write each region as the join of its atomic regions.


% ----------------------------------------
\begin{Definition}[Atomic indices]

Let $\category{L} = \tuple{G, R}$ be a presented locale with $G = \{ U_{1}, \ldots, U_{n} \}$. Let $\Index/ \subseteq \{ 0, \ldots, n \}$ be the indices of the atomic regions of $G$. 

For any $U \in \category{L}$, define its atomic support (denoted $\support/(U)$, or just $\support/$ for short) as:

\begin{equation*}
  \support/(U) = \{ i \in \Index/ \mid U_{i} \childOf/ U \}
\end{equation*}

\noindent
Then $U$ can be written canonically as $U_{\support/(U)}$, the join of its atomic supports:

\begin{equation*}
  U_{\support/(U)} = \bigjoin/\limits_{i \in \support/(U)} U_{i}.
\end{equation*}

\end{Definition}

A gluing condition is a family of predicates that say when a selection of patch candidates glue.

% ----------------------------------------
\begin{Definition}[Gluing condition]

A gluing condition $\glues{}$ is a family of predicates

\[
  \glues{U}: \prod_{i \in \support/(U)} F(U_{i}) \to \{ \mathrm{true}, \mathrm{false} \},
\]

\noindent
one for each region $U \in \category{L}$, that collectively satisfy the following coherence conditions:

\begin{enumerate}

\item [(G1)] \emph{Local data is glued}. If $U_{k} \in \atomsOf{\category{L}}$ and $F(U_{k}) = \{ \tuple{b_{k}} \}$, then

\[
  \glues{U_{k}}(\tuple{b_{k}}) = \mathrm{true}.
\]

\item [(G2)] \emph{Downward stability}. If $\glues{U}(\tuple{b_{i}}_{i \in \support/(U)}) = \mathrm{true}$, then for each $V \childOf/ U$, we must have:

\[
  \glues{V}(\restrict{U}{V}(\tuple{b_{i}}_{i \in \support/(U)})) = \mathrm{true}.
\]

\item [(G3)] \emph{Upward stability}. Given a selection of patch candidates $\tuple{b_{i}}_{i \in \support/(U)}$, if $\glues{U_{i} \join/ U_{j}}(\tuple{b_{i}, b_{j}}) = \mathrm{true}$ for each $i, j \in \support/(U)$, then we must have:

\[
  \glues{U}(\tuple{b_{i}}_{i \in \support/(U)}) = \mathrm{true}.
\]

\end{enumerate}

\end{Definition}

A sheaf can be generated from a gluing condition by starting with some local data on the atomic regions and then gluing all pieces together that satisfy the gluing condition.

% ----------------------------------------
\begin{Definition}[\Gsheaves/]
\label{def:g-sheaves}

Given a gluing condition $\glues{}$ and local data $F(U_{k}) = \{ \tuple{b_{k}} \}$ for each atomic region $U_{k}$, define for each region $U$:

\[
  F(U) = \{ \tuple{b_{i}}_{i \in \support/(U)} \in \prod_{i \in \support/(U)} F(U_{i}) 
    \mid \glues{U}(\tuple{b_{i}}_{i \in \support/(U)}) = \mathrm{true} \}.
\]

\noindent
For $V \childOf/ U$, define the restriction map

\[
  \restrict{U}{V}: F(U) \to F(V) 
    \quad\text{ as }\quad
    \restrict{U}{V}(\tuple{b_{i}}_{i \in \support/(U)}) = \tuple{b_{i}}_{i \in \support/(V)}.
\]

\noindent
Set $F(\bottom/) = \{ \tuple{} \}$, the empty tuple.

\end{Definition}

\begin{Remark}

Alternatively, given some local data and a gluing condition, define a presheaf over the given locale, call it $F_{\wp}$, that assigns all combinations of local data to each region:

\[
F_{\wp}(U) = \prod_{i \in \support/(U)} F(U_{i}).
\]

\noindent
Then filter by the gluing condition. That produces the same sheaf.

\end{Remark}

We must check that \cref{def:g-sheaves} really defines a sheaf. 

% ----------------------------------------
\begin{Theorem}[\Gsheaves/ are presheaves]

Given a gluing condition $\glues{}$ and an assignment of local data to the atomic regions of the underlying locale, the corresponding \Gsheaf/ is a presheaf.

\end{Theorem}

\begin{proof}

We must show that restrictions preserve identities and composition.

\begin{itemize}

\item \emph{Identities}. $\restrict{U}{U}$ projects to the same index set, so $\restrict{U}{U} = \ident{F(U)}$.

\item \emph{Composition}. $\restrict{U}{V}$ restricts to the fiber over $V$, and $\restrict{V}{W}$ restricts to the fiber over $W$, so $\restrict{V}{W} \compose/ \restrict{U}{V}$ = $\restrict{U}{W}$.

\end{itemize}

\noindent
We must also show that the restrictions are well defined. 

\begin{itemize}

\item For $V \childOf/ U$, if $\tuple{b_{i}}_{i \in \support/(U)} \in F(U)$, then by (G2) $\tuple{b_{i}}_{i \in \support/(V)}$ satisfies $\glues{V}$, so $\restrict{U}{V}$ is well-defined. \qedhere

\end{itemize}

\end{proof}

% ----------------------------------------
\begin{Theorem}[\Gsheaves/ are sheaves]

Given a gluing condition $\glues{}$ and an assignment of local data to the atomic regions of the underlying locale, the corresponding \Gsheaf/ satisfies the gluing condition G0.

\end{Theorem}

\begin{proof}

We must show that every gluable selection of patch candidates $\tuple{b_{i}}_{i \in \support/(U)}$ glues to yield a unique section in $F(U)$. Assume that we have a compatible selection of patch candidates $\tuple{b_{i}}_{i \in \support/(U)}$. Then:

\begin{itemize}

\item Existence: we assumed the patch candidates are compatible. By (G3) then, $\tuple{b_{i}}_{i \in \support/(U)} \in F(U)$.

\item Uniqueness: let $s = \tuple{b_{i}}_{i \in \support/(U)} \in F(U)$. If another section $t = \tuple{b_{i}}_{i \in \support/(U)} \in F(U)$ were glued from the same components, then $s = t$, since both restrict to the same supports. \qedhere

\end{itemize}

\end{proof}

Throughout the rest of this paper, we will use \Gsheaves/ to model part-whole complexes, but that is only for simplicity of exposition. Any sheaf over a locale would do just as well.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Modeling Part-Whole Complexes as Sheaves}
\label{sec:sheaf-mereology}

\noindent
As noted in \cref{sec:introduction}, the central claim of this paper is that we can model part-whole complexes as sheaves over locales. In particular, the locale provides the abstract parts space of ``regions'' the pieces can occupy, the sheaf assigns actual pieces to those regions, and the gluing condition determines when pieces fuse.

We can thus define the core mereological concepts of part and whole in sheaf-theoretic terms. Regarding wholes, we can identify fusion with gluing: to say that some pieces fuse or form a ``fusion'' is just to say that they are glued together. Regarding parts, to say that a piece is a ``part'' is just to say that it is a part of a fusion. In other words, the parts of a fusion are just the pieces from which it is glued together.

\def\partOf/{\sqsubseteq}

\begin{Definition}[Fusions and parts]

We say that a section $s \in F(U)$ is a fusion iff 

\[
\glues{U}(s) = \mathrm{true}.
\]

\noindent
Given $t \in F(V)$ and $s \in F(U)$ with $V \childOf/ U$ and $V \not = \bottom/$, we say $t$ is a part of $s$, denoted $t \partOf/ s$, iff

\[
\glues{U}(s) \quad\text{ and }\quad \restrict{U}{V}(s) = t.
\]

\end{Definition}

\begin{Remark}

$V \not = \bottom/$ because no parts can occupy $\bottom/$. The least region of the locale represents the combinatorial idea of no regions at all, and so it cannot be populated by any parts (hence in a \Gsheaf/ the sole section over $\bottom/$ is the singleton $\tuple{}$).

\end{Remark}

Sheaf theory thus provides a systematic framework with which to model a large variety of part-whole complexes in a ``fusions-first'' manner. In the rest of this section, we illustrate with examples.

% ----------------------------------------
\begin{Example}
\label{ex:wr-h-er}

Consider a building with a west room, an east room, and a hallway between them. For simplicity, let us consider only the floors of the building (ignore walls, ceilings, and so on). The ambient locale is given by the presentation

\begin{itemize}

\item $\category{L} = \tuple{G, R} = \tuple{\{ WR, H, ER \}, \EmptySet/}$

\end{itemize}

\noindent
where

\begin{itemize}

\item $WR$ = west room
\item $H$ = hallway
\item $ER$ = east room

\end{itemize}

\noindent
As a Hasse diagram:

\begin{diagram}

\node (WR_v_H_v_ER) at (0, 3) {$WR \join/ H \join/ ER$};
\node (WR_v_H) at (-2, 2) {$WR \join/ H$};
\node (WR_v_ER) at (0, 2) {$WR \join/ ER$};
\node (H_v_ER) at (2, 2) {$H \join/ ER$};
\node (WR) at (-2, 1) {$WR$};
\node (H) at (0, 1) {$H$};
\node (ER) at (2, 1) {$ER$};
\node (bottom) at (0, 0) {$\bottom/$};

\draw (bottom) to (WR);
\draw (bottom) to (H);
\draw (bottom) to (ER);
\draw (WR) to (WR_v_H);
\draw (WR) to (WR_v_ER);
\draw (H) to (WR_v_H);
\draw (H) to (H_v_ER);
\draw (ER) to (WR_v_ER);
\draw (ER) to (H_v_ER);
\draw (WR_v_H) to (WR_v_H_v_ER);
\draw (WR_v_ER) to (WR_v_H_v_ER);
\draw (H_v_ER) to (WR_v_H_v_ER);

\end{diagram}

\noindent
All of the generators are atomic, since none overlap (there are no meets among the generators):

\begin{itemize}

\item $\atomsOf{\category{L}} = \{ WR, H, ER \}$

\end{itemize}

\noindent
Let us define a \Gsheaf/ $F$ that models the flooring of this building. For data, let there be the following available flooring materials:

\begin{itemize}

\item $M = \{ \text{wood}, \text{tile}, \ldots \}$

\end{itemize}

\noindent
For a gluing condition, let us say that sections glue if they contain the same materials:

\begin{itemize}

\item $\glues{U}(\tuple{b_{i}}_{i \in \support/(U)}) = \mathrm{true}$ 
  iff $b_{i} = b_{j}$ for every $i, j \in \support/(U)$.
\item $\mathrm{false}$ otherwise

\end{itemize}

\noindent
We must check that this is a legitimate gluing condition.

\begin{proof}

We must show that $\glues{}$ satisfies the coherence conditions (G1)--(G3).

\begin{itemize}

\item [G1] \emph{Local atomic data}. Trivial.

\item [G2] \emph{Downward stability}. We must show that if $\glues{U}(\tuple{b_{i}}_{i \in \support/(U)})$ = $\mathrm{true}$, then $\glues{V}(\restrict{U}{V}(\tuple{b_{i}}_{i \in \support/(U)}))$ = $\mathrm{true}$ for every $V \childOf/ U$.  Assume the antecedent. Then $\restrict{U}{V}(\tuple{b_{i}}_{i \in \support/(U)})$ = $\tuple{b_{i}}_{i \in \support/(V)}$.
  \begin{itemize}
      \item \emph{Case 1}: if the length of $\tuple{b_{i}}_{i \in \support/(V)} = 1$, it glues by (G1).
      \item \emph{Case 2}: if the length of $\tuple{b_{i}}_{i \in \support/(V)} \geqslant 2$, then by the assumption, $b_{i}$ = $b_{j}$ for every $i, j \in \support/(V)$, so they glue.
  \end{itemize}

\item [G3] \emph{Upward stability}. Given a selection of compatible patch candidates $\tuple{b_{i}}_{i \in \support/(U)}$, we must show that if $\glues{U_{i}}(\tuple{b_{i}, b_{j}})$ = $\mathrm{true}$ for each $i, j \in \support/(U)$, then $\glues{U}(\tuple{b_{i}}_{i \in \support/(U)})$ = $\mathrm{true}$. Assume the antecedent. Since for every $i, j \in \support/(U)$, $b_{i} = b_{j}$ by the assumption, $\tuple{b_{i}}_{i \in \support/(U)}$ glues. \qedhere

\end{itemize}

\end{proof}

\noindent
For the atomic regions, fix a choice of local data:

\begin{itemize}

\item $F(WR) = \{ \tuple{wood} \}$
\item $F(H) = \{ \tuple{wood} \}$
\item $F(ER) = \{ \tuple{tile} \}$

\end{itemize}

\noindent
Extend compatible data to meets, of which there is only $\bottom/$, so:

\begin{itemize}

\item $F(\bottom/) = \{ \tuple{} \}$

\end{itemize}

\noindent
Recursively extend data to joins via gluing:

\begin{itemize}

\item $F(WR \join/ H)$ = $\{ \tuple{wood, wood} \}$, since $F(WR)$ = $F(H)$ = $\{ \tuple{wood} \}$,
and $wood$ = $wood$.

\item $F(WR \join/ ER) = \EmptySet/$, since $F(WR)$ = $\{ \tuple{wood} \}$, $F(ER) = \{ \tuple{tile} \}$, and $wood \not = tile$.

\item $F(H \join/ ER)$ = $\EmptySet/$, since $F(H)$ = $\{ \tuple{wood} \}$, $F(ER)$ = $\{ \tuple{tile} \}$, $wood \not = tile$.

\item $F(WR \join/ H \join/ ER)$ = $\EmptySet/$, since $F(WR \join/ H)$ = $\{ \tuple{wood, wood} \}$, $F(H \join/ ER)$ = $F(WR \join/ ER)$ = $\EmptySet/$, and $wood \not = \EmptySet/$.

\end{itemize}

\noindent
In this building, there are two maximal fusions:

\begin{itemize}

\item The flooring of the west room and the hallway glue into one piece that covers both.
\item The flooring that covers the east room is (trivially) glued into a single piece, namely itself.

\end{itemize}

\noindent
Thus, the flooring of this building is really a collection of two independent fusions: the wooden floor that covers the east room and hallway, and the tiled floor that covers the east room. That implies: 

\begin{itemize}

\item To separate the floors of the east room and hallway, you would have to use a saw to cut them, since they are fused. They are not merely sitting next to each other. Rather, they make up a single (fused) piece.

\item By contrast, to separate the hallway and the east room, you would not need to cut them, since they are not fused. They simply happen to be sitting next to each other.

\end{itemize}

\noindent
The parts of the fusions are clear:

\begin{itemize}

\item The wooden floor that covers the west room and the hallway has two parts: the wooden floor that covers the west room, and the wooden floor that covers the hallway.

\item The tiled floor of the east room has no parts (in this locale), since it is not the fusion of other fusions.

\end{itemize}

\end{Example}

In the previous example, none of the atomic regions overlapped. The locale was discrete, and thus the sheaf was free to glue or not glue pieces as it saw fit. The story is different if there are overlaps in the locale itself. Overlaps in the locale require overlaps in the sheaf.

% ----------------------------------------
\begin{Example}
\label{ex:wh-o-eh}

Consider the floor of a single room. Let us say that the regions of interest are its west half, its east half, and a six inch span where they overlap.

The ambient locale of this kind of space can be given by the presentation

\begin{itemize}

\item $L = \tuple{G, R} = 
  \tuple{\{ \bottom/, WH, O, EH \}, \{\bottom/ \childOf/ O, O \childOf/ WH, O \childOf/ EH\}}$

\end{itemize}

\noindent
where

\begin{itemize}

\item $WH$ = west half
\item $O$ = overlap
\item $EH$ = east half

\end{itemize}

\noindent
The atomic sections of this locale are:

\begin{itemize}

\item $WH$
\item $EH$
\item $\bottom/$

\end{itemize}

\noindent
In particular, $O$ is not an atomic region, because it is the non-trivial overlap of $WH$ and $EH$.

Here is the Hasse diagram:

\begin{diagram}

\node (WH_v_EH) at (0, 3) {$WH \join/ EH$};
\node (WH) at (-2, 1.5) {$WH$};
\node (EH) at (2, 1.5) {$EH$};
\node (O) at (0, 0) {$O$};
\node (bottom) at (0, -1) {$\bottom/$};

\draw (bottom) to (O);
\draw (O) to (WH);
\draw (O) to (EH);
\draw (WH) to (WH_v_EH);
\draw (EH) to (WH_v_EH);

\end{diagram}

Let us define a \Gsheaf/ $F$ that models the flooring of this room, using the same gluing condition from \cref{ex:wr-h-er}.

For the atomic regions, let us assign wood to both halves:

\begin{itemize}

\item $F(WH) = \{ \tuple{wood} \}$
\item $F(EH) = \{ \tuple{wood} \}$

\end{itemize}

\noindent
In a picture (omitting $\bottom/$ for simplicity):

\begin{diagram}

\node (WH_v_EH) at (0, 3) {$WH \join/ EH$};
\node (WH) at (-2, 1.5) {$WH$};
\node (EH) at (2, 1.5) {$EH$};
\node (O) at (0, 0) {$O$};

\draw[dashed] (O) to (WH);
\draw[dashed] (O) to (EH);
\draw[dashed] (WH) to (WH_v_EH);
\draw[dashed] (EH) to (WH_v_EH);

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2.55, 2.75) ellipse (1cm and 0.75cm);
\node[dot, label=left:{\small{$wood$}}] (wood_WH) at (-2, 2.75) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2.5, 2.75) ellipse (1cm and 0.75cm);
\node[dot, label=right:{\small{$wood$}}] (wood_EH) at (2, 2.75) {};

\end{diagram}

\noindent
For the meet (the overlap $O$), the two halves restrict to the same thing:

\begin{itemize}

\item $F(O) = \{ \tuple{wood} \}$
    
\end{itemize}

\noindent
Thus:

\begin{diagram}

\node (WH_v_EH) at (0, 3) {$WH \join/ EH$};
\node (WH) at (-2, 1.5) {$WH$};
\node (EH) at (2, 1.5) {$EH$};
\node (O) at (0, 0) {$O$};

\draw[dashed] (O) to (WH);
\draw[dashed] (O) to (EH);
\draw[dashed] (WH) to (WH_v_EH);
\draw[dashed] (EH) to (WH_v_EH);

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2.55, 2.75) ellipse (1cm and 0.75cm);
\node[dot, label=left:{\small{$wood$}}] (wood_WH) at (-2, 2.75) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2.5, 2.75) ellipse (1cm and 0.75cm);
\node[dot, label=right:{\small{$wood$}}] (wood_EH) at (2, 2.75) {};

\draw (0, 0.25) to (0, 0.5);
\draw (0, 1.5) ellipse (0.85cm and 0.75cm);
\node[dot, label=below:{\small{$wood$}}] (wood_O) at (0, 1.5) {};

\draw[arrow, ->] (wood_WH) to (wood_O);
\draw[arrow, ->] (wood_EH) to (wood_O);

\end{diagram}

\noindent
For the join, the west and east halves glue, since they're made from the same flooring materials and agree on their overlap:

\begin{itemize}

\item $F(WH \join/ EH) = \{ \tuple{wood} \}$

\end{itemize}

\noindent
Thus:

\begin{diagram}

\node (WH_v_EH) at (0, 3) {$WH \join/ EH$};
\node (WH) at (-2, 1.5) {$WH$};
\node (EH) at (2, 1.5) {$EH$};
\node (O) at (0, 0) {$O$};

\draw[dashed] (O) to (WH);
\draw[dashed] (O) to (EH);
\draw[dashed] (WH) to (WH_v_EH);
\draw[dashed] (EH) to (WH_v_EH);

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2.55, 2.75) ellipse (1cm and 0.75cm);
\node[dot, label=left:{\small{$wood$}}] (wood_WH) at (-2, 2.75) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2.5, 2.75) ellipse (1cm and 0.75cm);
\node[dot, label=right:{\small{$wood$}}] (wood_EH) at (2, 2.75) {};

\draw (0, 0.25) to (0, 0.5);
\draw (0, 1.5) ellipse (0.85cm and 0.75cm);
\node[dot, label=below:{\small{$wood$}}] (wood_O) at (0, 1.5) {};

\draw (0, 3.25) to (0, 3.75);
\draw (0, 4.25) ellipse (0.75cm and 0.75cm);
\node[dot, label=above:{\small{$wood$}}] (wood_WH_v_EH) at (0, 4) {};

\draw[arrow, ->] (wood_WH_v_EH) to (wood_WH);
\draw[arrow, ->] (wood_WH_v_EH) to (wood_EH);
\draw[arrow, ->] (wood_WH) to (wood_O);
\draw[arrow, ->] (wood_EH) to (wood_O);

\end{diagram}

The maximal fusion is a single piece of wooden flooring that covers the whole room. Its parts are the west and east halves, and (transitively) their overlap. The west and east halves themselves have a shared part, the strip of overlap.

\end{Example}


% ----------------------------------------
\begin{Example}
\label{ex:wh-o-eh-fail}

To illustrate a failed attempt to build a sheaf, let us take the locale and gluing condition from \cref{ex:wh-o-eh}, but let's assign different flooring materials to the atomic regions:

\begin{itemize}

\item $F(WH) = \{ \tuple{wood} \}$
\item $F(EH) = \{ \tuple{tile} \}$

\end{itemize}

\noindent
As a picture:

\begin{diagram}

\node (WH_v_EH) at (0, 3) {$WH \join/ EH$};
\node (WH) at (-2, 1.5) {$WH$};
\node (EH) at (2, 1.5) {$EH$};
\node (O) at (0, 0) {$O$};

\draw[dashed] (O) to (WH);
\draw[dashed] (O) to (EH);
\draw[dashed] (WH) to (WH_v_EH);
\draw[dashed] (EH) to (WH_v_EH);

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2.55, 2.75) ellipse (1cm and 0.75cm);
\node[dot, label=left:{\small{$wood$}}] (wood_WH) at (-2, 2.75) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2.5, 2.75) ellipse (1cm and 0.75cm);
\node[dot, label=right:{\small{$tile$}}] (tile_EH) at (2, 2.75) {};

\end{diagram}

Next, we attempt to extend this data to meets, which requires that we restrict to the overlap, and then filter out anything that can't glue. Here, $F(WH)$ restricts to $\{ \tuple{wood} \}$, and $F(EH)$ restricts to $\{ \tuple{tile} \}$:

\begin{itemize}

\item $\restrict{WH}{O}(\tuple{wood}) = \tuple{wood}$
\item $\restrict{EH}{O}(\tuple{tile}) = \tuple{tile}$

\end{itemize}

\noindent
Thus:

\begin{diagram}

\node (WH_v_EH) at (0, 3) {$WH \join/ EH$};
\node (WH) at (-2, 1.5) {$WH$};
\node (EH) at (2, 1.5) {$EH$};
\node (O) at (0, 0) {$O$};

\draw[dashed] (O) to (WH);
\draw[dashed] (O) to (EH);
\draw[dashed] (WH) to (WH_v_EH);
\draw[dashed] (EH) to (WH_v_EH);

\draw (-2, 1.75) to (-2, 2.275);
\draw (-2.55, 2.75) ellipse (1cm and 0.75cm);
\node[dot, label=left:{\small{$wood$}}] (wood_WH) at (-2, 2.75) {};

\draw (2, 1.75) to (2, 2.275);
\draw (2.5, 2.75) ellipse (1cm and 0.75cm);
\node[dot, label=right:{\small{$tile$}}] (tile_EH) at (2, 2.75) {};

\draw (0, 0.25) to (0, 0.5);
\draw (0, 1.5) ellipse (1cm and 1cm);
\node[dot, label=below:{\small{$wood$}}] (wood_O) at (0, 1.25) {};
\node[dot, label=below:{\small{$tile$}}] (tile_O) at (0, 2.1) {};

\draw[arrow, ->] (wood_WH) to (wood_O);
\draw[arrow, ->] (tile_EH) to (tile_O);

\end{diagram}

However, these cannot glue, because they are not the same. We see here that the data of WH and EH disagree on the overlap. Hence, we are unable to construct a coherent sheaf. This illustrates how sheaf theory requires and manages coherent gluing at all levels. Because it requires that pieces glue together coherently at every level of ``zoom,'' it prevents us from ever putting together an incoherent part-whole complex in the first place.

It is worth spelling the failure out explicitly. Since $WH$ and $EH$ disagree on their overlap, $F$ cannot assign anything to $O$, so:

\begin{itemize}

\item $F(O) = \EmptySet/$

\end{itemize}

\noindent
But that renders the restrictions $\restrict{WH}{O}$ and $\restrict{EH}{O}$ undefined, thereby severing our ability to zoom in and out. Thus, the system as a whole becomes incoherent.

Intuitively, this makes sense. If the western and eastern halves of a room were truly floored with different materials, then they would not overlap. There would be some sort of boundary between them where the one's materials end and the other's materials begin. But here, the ambient locale doesn't allow that possibility. In \emph{this} particular locale, the western and eastern halves \emph{do} overlap, so the sheaf must assign pieces to the different regions coherently, i.e., it must assign pieces that agree on their overlap.

\end{Example}

The previous two examples were spatial. But parts come in non-spatial guises too, and sheaves can model them just as well.

% ----------------------------------------
\begin{Example}
\label{ex:human-society}

Suppose we say that human society (under some description) consists of the mesh of a specified set of relationships between the people that participate in that society.

Let $P$ be the population in question (a finite set of individual people), and let the regions of our locale be subsets of such individuals. Then the ambient locale is given by the presentation:

\begin{itemize}

\item $\category{L} = \tuple{G, R} = \tuple{P, \EmptySet/}$

\end{itemize}

\noindent
For concreteness, suppose:

\begin{itemize}

\item $P = \{ A$ (Alice), $B$ (Bob), $C$ (Carol), $D$ (Denny) $\}$

\end{itemize}

\noindent
Then the Hasse diagram is isomorphic to the powerset of $P$:

\begin{diagram}

\node (ABCD) at (0, 6) {$A \join/ B \join/ C \join/ D$};
\node (ABC) at (-3, 4.5) {$A \join/ B \join/ C$};
\node (ABD) at (-1, 4.5) {$A \join/ B \join/ D$};
\node (ACD) at (1, 4.5) {$A \join/ C \join/ D$};
\node (BCD) at (3, 4.5) {$B \join/ C \join/ D$};
\node (AB) at (-5, 3) {$A \join/ B$};
\node (AC) at (-3, 3) {$A \join/ C$};
\node (AD) at (-1, 3) {$A \join/ D$};
\node (BC) at (1, 3) {$B \join/ C$};
\node (BD) at (3, 3) {$B \join/ D$};
\node (CD) at (5, 3) {$C \join/ D$};
\node (A) at (-3, 1.5) {$A$};
\node (B) at (-1, 1.5) {$B$};
\node (C) at (1, 1.5) {$C$};
\node (D) at (3, 1.5) {$D$}; 
\node (bottom) at (0, 0) {$\bottom/$};

\draw (bottom) to (A);
\draw (bottom) to (B);
\draw (bottom) to (C);
\draw (bottom) to (D);
\draw (A) to (AB);
\draw (A) to (AC);
\draw (A) to (AD);
\draw (B) to (AB);
\draw (B) to (BC);
\draw (B) to (BD);
\draw (C) to (AC);
\draw (C) to (BC);
\draw (C) to (CD);
\draw (D) to (AD);
\draw (D) to (BD);
\draw (D) to (CD);
\draw (AB) to (ABC);
\draw (AB) to (ABD);
\draw (AC) to (ABC);
\draw (AC) to (ACD);
\draw (AD) to (ABD);
\draw (AD) to (ACD);
\draw (BC) to (ABC);
\draw (BC) to (BCD);
\draw (BD) to (ABD);
\draw (BD) to (BCD);
\draw (CD) to (ACD);
\draw (CD) to (BCD);
\draw (ABC) to (ABCD);
\draw (ABD) to (ABCD);
\draw (ACD) to (ABCD);
\draw (BCD) to (ABCD);

\end{diagram}

\noindent
All of the generators are atomic, since there are no meets among the generators:

\begin{itemize}

\item $\atomsOf{\category{L}} = \{ A, B, C, D \}$

\end{itemize}

\noindent
Let us define a \Gsheaf/ $F$ that models the mesh of a selected set of relationships over $P$. To do that, let us first specify a set $R$ that picks out the (binary, symmetric) relationships of interest:

\begin{itemize}

\item $R = \{ f$ (friends), $m$ (married), $\ldots \}$

\end{itemize}

\noindent
For convenience, if $U, V \in P$, $r \in R$, and $U$ and $V$ stand in relationship $r$, we
will write $r(U, V)$.

For a gluing condition, let us say that sections glue if they are connected by the same relations:

\begin{itemize}

\item $\glues{U}(\tuple{b_{i}}_{i \in \support/(U)}) = \mathrm{true}$ iff for every $r \in R$, 
      $r(U_{i}, U_{j}) \in b_{i}$ iff $r(U_{j}, U_{i}) \in b_{j}$, for every $i, j \in \support/(U)$
\item $\mathrm{false}$ otherwise

\end{itemize}

\noindent
We must check that this is a legitimate gluing condition.

\begin{proof}

The proof is the same as before. \qedhere

\end{proof}

\noindent
For the atomic regions, let us fix a choice of local data by assigning to each person the relations they stand in, e.g.:

\begin{itemize}

\item $F(A) = \{\tuple{\{ f(A, B), f(A, C), m(A, B) \}} \}$
\item $F(B) = \{\tuple{\{ f(B, A), m(B, A), f(B, D) \}} \}$
\item $F(C) = \{\tuple{\{ f(C, A), m(C, D) \}} \}$
\item $F(D) = \{\tuple{\{ f(D, B), m(D, C) \}} \}$

\end{itemize}

\noindent
To visualize this data, we can picture each fiber as a mini-graph:

\begin{diagram}

\node[dot] (Cf_over_A) at (-4.25, 3.25) [label=right:{\small{$C$}}] {};
\node[dot] (Bm_over_A) at (-5, 3.75) [label=above:{\small{$B$}}] {};
\node[dot] (Bf_over_A) at (-5.75, 3.25) [label=left:{\small{$B$}}] {};
\node[dot] (anchor_over_A) at (-5, 3) [label=below:{\small{$A$}}] {};
\node (A) at (-5, 1.5) {$A$};
\draw (A) to (-5, 2.25);
\draw (anchor_over_A) to node[midway, below left] {\small{$f$}} (Bf_over_A);
\draw (anchor_over_A) to node[midway, left] {\small{$m$}} (Bm_over_A);
\draw (anchor_over_A) to node[midway, below right] {\small{$f$}} (Cf_over_A);

\node[dot] (Df_over_B) at (-1.25, 3.25) [label=right:{\small{$D$}}] {};
\node[dot] (Am_over_B) at (-2, 3.75) [label=above:{\small{$A$}}] {};
\node[dot] (Af_over_B) at (-2.75, 3.25) [label=left:{\small{$A$}}] {};
\node[dot] (anchor_over_B) at (-2, 3) [label=below:{\small{$B$}}] {};
\node (B) at (-2, 1.5) {$B$};
\draw (B) to (-2, 2.25);
\draw (anchor_over_B) to node[midway, below left] {\small{$f$}} (Af_over_B);
\draw (anchor_over_B) to node[midway, left] {\small{$m$}} (Am_over_B);
\draw (anchor_over_B) to node[midway, below right] {\small{$f$}} (Df_over_B);

\node[dot] (Af_over_C) at (0.5, 3.5) [label=left:{\small{$A$}}] {};
\node[dot] (Dm_over_C) at (1.5, 3.5) [label=right:{\small{$D$}}] {};
\node[dot] (anchor_over_C) at (1, 3) [label=below:{\small{$C$}}] {};
\node (C) at (1, 1.5) {$C$};
\draw (C) to (1, 2.25);
\draw (anchor_over_C) to node[midway, below left] {\small{$f$}} (Af_over_C);
\draw (anchor_over_C) to node[midway, below right] {\small{$m$}} (Dm_over_C);

\node[dot] (Bf_over_D) at (3.5, 3.5) [label=left:{\small{$B$}}] {};
\node[dot] (Cm_over_D) at (4.5, 3.5) [label=right:{\small{$C$}}] {};
\node[dot] (anchor_over_D) at (4, 3) [label=below:{\small{$D$}}] {};
\node (D) at (4, 1.5) {$D$};
\draw (D) to (4, 2.25);
\draw (anchor_over_D) to node[midway, below left] {\small{$f$}} (Bf_over_D);
\draw (anchor_over_D) to node[midway, below right] {\small{$m$}} (Cm_over_D);

\end{diagram}

\noindent
For example, in the fiber over $A$:

\begin{itemize}

\item The $f$-labeled edge from $A$ to $B$ represents $f(A, B)$: $A$ and $B$ are friends.
\item The $m$-labeled edge from $A$ to $B$ represents $m(A, B)$: $A$ and $B$ are married.
\item The $f$-labeled edge from $A$ to $C$ represents $f(A, C)$: $A$ and $C$ are friends.

\end{itemize}

\noindent
Next, we must extend compatible data to meets, of which there is only $\bottom/$, so:

\begin{itemize}

\item $F(\bottom/) = \{ \tuple{} \}$

\end{itemize}

\noindent
Finally, we must extend atomic data to binary joins via gluing. The gluing condition essentially says that mini-graphs can be glued along shared edges, provided that they share exactly the same edges. To see how this works, consider (for example) the mini-graphs over $A$ and $C$:

\begin{diagram}

\node[dot] (Cf_over_A) at (-1.25, 3.25) [label=right:{\small{$C$}}] {};
\node[dot] (Bm_over_A) at (-2, 3.75) [label=above:{\small{$B$}}] {};
\node[dot] (Bf_over_A) at (-2.75, 3.25) [label=left:{\small{$B$}}] {};
\node[dot] (anchor_over_A) at (-2, 3) [label=below:{\small{$A$}}] {};
\draw (anchor_over_A) to node[midway, below left] {\small{$f$}} (Bf_over_A);
\draw (anchor_over_A) to node[midway, left] {\small{$m$}} (Bm_over_A);
\draw (anchor_over_A) to node[midway, below right] {\small{$f$}} (Cf_over_A);

\node[dot] (Af_over_C) at (1.5, 3.5) [label=left:{\small{$A$}}] {};
\node[dot] (Dm_over_C) at (2.5, 3.5) [label=right:{\small{$D$}}] {};
\node[dot] (anchor_over_C) at (2, 3) [label=below:{\small{$C$}}] {};
\draw (anchor_over_C) to node[midway, below left] {\small{$f$}} (Af_over_C);
\draw (anchor_over_C) to node[midway, below right] {\small{$m$}} (Dm_over_C);

\end{diagram}

\noindent
Can these be glued? The answer is yes, because they share exactly one edge, namely the one labeled $f$. If you rotate the graphs sideways a bit, you can see how they can be merged along $f(A, C)$:

\begin{diagram}

\node[dot] (Cf_over_A) at (-1.15, 3) [label=below right:{\small{$C$}}] {};
\node[dot] (Bm_over_A) at (-1.65, 3.75) [label=above:{\small{$B$}}] {};
\node[dot] (Bf_over_A) at (-2.5, 3.5) [label=left:{\small{$B$}}] {};
\node[dot] (anchor_over_A) at (-2, 3) [label=below left:{\small{$A$}}] {};
\draw (anchor_over_A) to node[midway, below left] {\small{$f$}} (Bf_over_A);
\draw (anchor_over_A) to node[midway, above left] {\small{$m$}} (Bm_over_A);
\draw (anchor_over_A) to node[midway, below] {\small{$f$}} (Cf_over_A);

\node[dot] (Af_over_C) at (1.15, 3) [label=below left:{\small{$A$}}] {};
\node[dot] (Dm_over_C) at (2, 3.75) [label=right:{\small{$D$}}] {};
\node[dot] (anchor_over_C) at (2, 3) [label=below right:{\small{$C$}}] {};
\draw (anchor_over_C) to node[midway, below] {\small{$f$}} (Af_over_C);
\draw (anchor_over_C) to node[midway, right] {\small{$m$}} (Dm_over_C);

\draw[dashed] (-2, 2.5) -- (-2, 2.35) -- (-1.15, 2.35) -- (-1.14, 2.5);
\draw[dashed] (1.15, 2.5) -- (1.15, 2.35) -- (2, 2.35) -- (2, 2.5);
\draw[dashed] (-1.65, 2.35) -- (-1.65, 2) -- (1.65, 2) -- (1.65, 2.35);
\node at (0, 1.75) {\small{merge these edges}};

\end{diagram}
 
\noindent
Merging along $f(A, C)$ yields the following glued graph:

\begin{diagram}

\node[dot] (Cf_over_A) at (-1.15, 3) [label=below right:{\small{$C$}}] {};
\node[dot] (Bm_over_A) at (-2, 3.75) [label=above:{\small{$B$}}] {};
\node[dot] (Bf_over_A) at (-2.75, 3.25) [label=left:{\small{$B$}}] {};
\node[dot] (anchor_over_A) at (-2, 3) [label=below left:{\small{$A$}}] {};
\node[dot] (Dm_over_Cf) at (-0.75, 3.75) [label=right:{\small{$D$}}] {};
\draw (anchor_over_A) to node[midway, below left] {\small{$f$}} (Bf_over_A);
\draw (anchor_over_A) to node[midway, left] {\small{$m$}} (Bm_over_A);
\draw (anchor_over_A) to node[midway, below] {\small{$f$}} (Cf_over_A);
\draw (Cf_over_A) to node[midway, below right] {\small{$m$}} (Dm_over_Cf);

\end{diagram}

\noindent
By gluing binary joins in this fashion, we get:

\begin{itemize}

\item $F(A \join/ B) = \{\tuple{\{ f(A, B), m(A, B), f(A, C) \}, \{ f(B, A), m(B, A), f(B, D) \}} \}$
\item $F(A \join/ C) = \{\tuple{\{ f(B, A), m(B, A), f(B, D) \}}, \{ f(C, A), m(C, D) \} \}$
\item $F(A \join/ D) = \EmptySet/$
\item $F(B \join/ C) = \EmptySet/$
\item $F(B \join/ D) = \{\tuple{\{ f(B, A), m(B, A), f(B, D) \}, \{ f(D, B), m(D, C) \}} \}$
\item $F(C \join/ D) = \{\tuple{\{ f(C, A), m(C, D) \}, \{ f(D, B), m(D, C) \}} \}$

\end{itemize}

\noindent
As pictures:

\begin{diagram}

\node[dot] (A_over_A_v_B) at (-4.4, 1.5) [label=below left:{\small{$A$}}] {};
\node[dot] (B_over_A_v_B) at (-3.6, 1.5) [label=below right:{\small{$B$}}] {};
\node[dot] (Cf_over_A_v_B) at (-4.6, 2.1) [label=above:{\small{$C$}}] {};
\node[dot] (Df_over_A_v_B) at (-3.4, 2.1) [label=above:{\small{$D$}}] {};
\node (A_v_B) at (-4, 0) {$A \join/ B$};
\draw (A_v_B) to (-4, 0.75);
\draw (A_over_A_v_B) to node[midway, left] {\small{$f$}} (Cf_over_A_v_B);
\draw (B_over_A_v_B) to node[midway, right] {\small{$f$}} (Df_over_A_v_B);
\draw (A_over_A_v_B) to[out=30, in=150] node[midway, above] {\small{$f$}} (B_over_A_v_B);
\draw (A_over_A_v_B) to[out=330, in=210] node[midway, below] {\small{$m$}} (B_over_A_v_B);

\node[dot] (A_over_A_v_C) at (-1.4, 1.5) [label=below left:{\small{$A$}}] {};
\node[dot] (C_over_A_v_C) at (-0.6, 1.5) [label=below right:{\small{$C$}}] {};
\node[dot] (Bm_over_A_v_C) at (-1.4, 2.2) [label=above:{\small{$B$}}] {};
\node[dot] (Bf_over_A_v_C) at (-2.1, 1.7) [label=left:{\small{$B$}}] {};
\node[dot] (Dm_over_A_v_C) at (-0.4, 2.2) [label=right:{\small{$D$}}] {};
\node (A_v_C) at (-1, 0) {$A \join/ C$};
\draw (A_v_C) to (-1, 0.75);
\draw (A_over_A_v_C) to node[midway, below left] {\small{$f$}} (Bf_over_A_v_C);
\draw (A_over_A_v_C) to node[midway, left] {\small{$m$}} (Bm_over_A_v_C);
\draw (A_over_A_v_C) to node[midway, below] {\small{$f$}} (C_over_A_v_C);
\draw (C_over_A_v_C) to node[midway, below right] {\small{$m$}} (Dm_over_A_v_C);

\node (empty_over_A_v_D_and_B_v_C) at (1, 1.25) {$\EmptySet/$};
\node (A_v_D_and_B_v_C) at (1, 0) {$A \join/ D$/$B \join/ C$};
\draw (A_v_D_and_B_v_C) to (1, 0.75);

\node[dot] (B_over_B_v_D) at (3.1, 1.5) [label=below left:{\small{$B$}}] {};
\node[dot] (D_over_B_v_D) at (3.9, 1.5) [label=below right:{\small{$D$}}] {};
\node[dot] (Am_over_B_v_D) at (3.1, 2.2) [label=above:{\small{$A$}}] {};
\node[dot] (Af_over_B_v_D) at (2.4, 1.7) [label=left:{\small{$A$}}] {};
\node[dot] (Cm_over_B_v_D) at (4.1, 2.2) [label=right:{\small{$C$}}] {};
\node (B_v_D) at (3.5, 0) {$B \join/ D$};
\draw (B_v_D) to (3.5, 0.75);
\draw (B_over_B_v_D) to node[midway, below left] {\small{$f$}} (Af_over_B_v_D);
\draw (B_over_B_v_D) to node[midway, left] {\small{$m$}} (Am_over_B_v_D);
\draw (B_over_B_v_D) to node[midway, below] {\small{$f$}} (D_over_B_v_D);
\draw (D_over_B_v_D) to node[midway, below right] {\small{$m$}} (Cm_over_B_v_D);

\node[dot] (C_over_C_v_D) at (5.6, 1.5) [label=below left:{\small{$C$}}] {};
\node[dot] (D_over_C_v_D) at (6.4, 1.5) [label=below right:{\small{$D$}}] {};
\node[dot] (Af_over_C_v_D) at (5.4, 2.1) [label=above:{\small{$A$}}] {};
\node[dot] (Bf_over_C_v_D) at (6.6, 2.1) [label=above:{\small{$B$}}] {};
\node (C_v_D) at (6, 0) {$C \join/ D$};
\draw (C_v_D) to (6, 0.75);
\draw (C_over_C_v_D) to node[midway, below] {\small{$m$}} (D_over_C_v_D);
\draw (C_over_C_v_D) to node[midway, left] {\small{$f$}} (Af_over_C_v_D);
\draw (D_over_C_v_D) to node[midway, right] {\small{$f$}} (Bf_over_C_v_D);

\end{diagram}

Having glued joins of two regions, we must next glue joins of three atomic regions. For instance, take $B \join/ C \join/ D$. We can glue $B \join/ C$ trivially (because they share no edges), we can glue $C \join/ D$ along their shared $f$-edge, and we can glue $B \join/ D$ along their shared $f$-edge. That yields:

\begin{diagram}

\node[dot] (B_over_B_v_C_v_D) at (-0.5, 1.5) [label=below right:{\small{$B$}}] {};
\node[dot] (C_over_B_v_C_v_D) at (0.5, 1.5) [label=below:{\small{$C$}}] {};
\node[dot] (D_over_B_v_C_v_D) at (0, 2) [label=above:{\small{$D$}}] {};
\node[dot] (Af_from_B_over_B_v_C_v_D) at (-1.1, 2) [label=left:{\small{$A$}}] {};
\node[dot] (Am_from_B_over_B_v_C_v_D) at (-1.2, 1) [label=left:{\small{$A$}}] {};
\node[dot] (Af_from_C_over_B_v_C_v_D) at (1.1, 2) [label=right:{\small{$A$}}] {};
\node (B_v_C_v_D) at (0, 0) {$B \join/ C \join/ D$};
\draw (B_v_C_v_D) to (0, 0.75);
\draw (B_over_B_v_C_v_D) to node[midway, above left] {\small{$f$}} (D_over_B_v_C_v_D);
\draw (C_over_B_v_C_v_D) to node[midway, above right] {\small{$m$}} (D_over_B_v_C_v_D);
\draw 
  (C_over_B_v_C_v_D) 
  to 
  node[midway, below right] {\small{$f$}} 
  (Af_from_C_over_B_v_C_v_D);
\draw 
  (B_over_B_v_C_v_D) 
  to
  node[midway, below left] {\small{$f$}} 
  (Af_from_B_over_B_v_C_v_D);
\draw 
  (B_over_B_v_C_v_D) 
  to
  node[midway, below right] {\small{$m$}} 
  (Am_from_B_over_B_v_C_v_D);

\end{diagram}

\noindent
By gluing all joins of three atomic regions in this fashion, we get:

\begin{itemize}

\item
  $F(A \join/ B \join/ C) =$
    $\left\{
      \begin{array}{l l}
        \openTuple/ 
          & \{ f(A, B), f(A, C), m(A, B) \}, \\
          & \{ f(B, A), m(B, A), f(B, D) \}, \\
	  & \{ f(C, A), m(C, D) \} \quad \closeTuple/
      \end{array}
    \right\}$

\item 
  $F(A \join/ B \join/ D) =$
    $\left\{
      \begin{array}{l l}
        \openTuple/ 
          & \{ f(A, B), f(A, C), m(A, B) \}, \\
          & \{ f(B, A), m(B, A), f(B, D) \}, \\
          & \{ f(D, B), m(D, C) \} \quad \closeTuple/
      \end{array}
    \right\}$

\item
  $F(A \join/ C \join/ D) =$
    $\left\{
      \begin{array}{l l}
        \openTuple/
          & \{ f(A, B), f(A, C), m(A, B) \}, \\
	  & \{ f(C, A), m(C, D) \}, \\
          & \{ f(D, B), m(D, C) \} \quad \closeTuple/
      \end{array}
    \right\}$

\item $F(B \join/ C \join/ D) =$
    $\left\{
      \begin{array}{l l}
        \openTuple/
          & \{ f(B, A), m(B, A), f(B, D) \}, \\
          & \{ f(C, A), m(C, D) \}, \\
          & \{ f(D, B), m(D, C) \} \quad \closeTuple/
      \end{array}
    \right\}$

\end{itemize}

\noindent
At the top-most join, gluing four regions, we get:

\begin{itemize}

\item
  $F(A \join/ B \join/ C \join/ D) =$
    $\left\{
      \begin{array}{l l}
        \openTuple/ 
          & \{ f(A, B), f(A, C), m(A, B) \}, \\
          & \{ f(B, A), m(B, A), f(B, D) \}, \\
	  & \{ f(C, A), m(C, D) \}, \\
	  & \{ f(D, B), m(D, C) \} \quad \closeTuple/
      \end{array}
    \right\}$

\end{itemize}

\noindent
As a picture:

\begin{diagram}

\node[dot] (B_over_A_v_B_v_C_v_D) at (-0.5, 1.5) [label=left:{\small{$B$}}] {};
\node[dot] (C_over_A_v_B_v_C_v_D) at (0.5, 1.5) [label=right:{\small{$C$}}] {};
\node[dot] (D_over_A_v_B_v_C_v_D) at (0, 2) [label=above:{\small{$D$}}] {};
\node[dot] (A_over_A_v_B_v_C_v_D) at (0, 1) [label=below:{\small{$A$}}] {};
\node (A_v_B_v_C_v_D) at (0, -0.5) {$A \join/ B \join/ C \join/ D$};
\draw (A_v_B_v_C_v_D) to (0, 0.25);
\draw 
  (B_over_A_v_B_v_C_v_D) 
  to 
  node[midway, above left] {\small{$f$}} 
  (D_over_A_v_B_v_C_v_D);
\draw 
  (C_over_A_v_B_v_C_v_D) 
  to 
  node[midway, above right] {\small{$m$}} 
  (D_over_A_v_B_v_C_v_D);
\draw 
  (C_over_A_v_B_v_C_v_D) 
  to 
  node[midway, below right] {\small{$f$}} 
  (A_over_A_v_B_v_C_v_D);
\draw 
  (B_over_A_v_B_v_C_v_D) 
  to[out=280, in=170] 
  node[midway, below left] {\small{$f$}} 
  (A_over_A_v_B_v_C_v_D);
\draw 
  (B_over_A_v_B_v_C_v_D) 
  to[out=340, in=110] 
  node[midway, above right] {\small{$m$}} 
  (A_over_A_v_B_v_C_v_D);

\end{diagram}

\noindent
The resulting sheaf yields a fused mesh of relationships over the population, which is glued together from smaller meshes over smaller subsets of the population. 

\begin{itemize}

\item Each atomic fiber is a part of the whole (human society), and its data encodes the internal (relational) structure of that part.

\item Mereological overlap is then modeled by shared relationships: two parts overlap if their relational graphs intersect coherently.

\item Failure to glue (as in $F(A \join/ D) = \EmptySet/$ and $F(B \join/ C) = \EmptySet/$) reflects mereological separation: the atomic regions in question cannot be fused because they are not related in this mesh.

\end{itemize}

\end{Example}


For another example, consider processes. A process (or more generally any sequence of events, states, etc.) can be seen as a part-whole complex too. 


% ----------------------------------------
\begin{Example}
\label{ex:simple-processes}

Imagine a scenario where something can do one of two things repeatedly: at each step, it can do one thing (``option $a$'') or another thing (``option $b$''), and then repeat the choice again.

To model this, fix a finite alphabet $\Sigma = \{ a, b \}$, with ``$a$'' for ``option $a$'' and ``$b$'' for ``option $b$.'' Then let $\Sigma^{\ast}$ be the set of all finite sequences (words) over $\Sigma$, with $\epsilon$ denoting the empty sequence. For instance, the sequence $aab$ represents the sequence of length 3 that picks ``option $a$'' first, then ``option $a$'' again, and then finally ``option $b$.''

Let us say that $\Sigma^{\leqslant n}$ is the set of all finite sequences less than length $n$, and let us say that $\Sigma^{=n}$ is the set of finite sequences of exactly length $n$. Hence:

\begin{itemize}

\item $\Sigma^{=0} = \{ \epsilon \}$.
\item $\Sigma^{=1} = \Sigma^{\leqslant 1} = \{ \epsilon, a, b \}$.
\item $\Sigma^{\leqslant 2} = \{ \epsilon, a, b, aa, bb, ab, ba \}$.
\item $\Sigma^{=2} = \{ aa, bb, ab, ba \}$.
\item Etc.

\end{itemize}

\noindent
Given sequences $w, v \in \Sigma^{\leqslant n}$ with $length(w) \leqslant length(v)$, let us write $w \subseteq v$ to denote that $w$ is a prefix of $v$, as in $aab \subseteq aabc$.

Next, define a topology over $\Sigma^{\leqslant}$ by setting the open sets to be sequences that share a prefix:

\begin{itemize}

\item $U_{w} = \{ v \in \Sigma^{\leqslant} \mid w \subseteq v \}$.

\end{itemize}

\noindent
So $U_{w}$ consists of all sequences that continue $w$. For instance, if $w = aab$, then we might picture $U_{w}$ as a kind of bouquet or bundle of sequences that are all bound at their shared stem ($aab$) but then branch out in different directions:

\begin{diagram}

\node at (0.1, -0.75) {$U_{aab}$};
\draw (-0.4, -0.4) rectangle (0.6, -1.15);

\node (1) at (0, 0) {$a$};
\node (2) at (0, 0.5) {$a$};
\node (3) at (0, 1) {$b$};
\draw (1) to (2) to (3);

\node (4) at (-0.35, 1.65) {$a$};
\node (5) at (-0.75, 2.25) {$b$};
\node (6) at (-1.5, 2.75) {};
\draw (3) to (4) to (5) to (6);

\node (7) at (0, 1.5) {$b$};
\node (8) at (0, 2) {$a$};
\node (9) at (-0.1, 2.5) {$a$};
\node (10) at (-0.25, 3) {$b$};
\node (11) at (-0.35, 3.5) {};
\draw (3) to (7) to (8) to (9) to (10) to (11);

\node (12) at (0.2, 1.65) {$a$};
\node (13) at (0.4, 2.25) {$a$};
\node (14) at (0.75, 3) {};
\draw (3) to (12) to (13) to (14);

\node (15) at (0.5, 1.5) {$b$};
\node (16) at (1, 1.75) {$b$};
\node (17) at (1.5, 2) {};
\draw (3) to (15) to (16) to (17);

\draw (0.25, 0) -- (0.5, 0) -- (0.5, 1) -- (0.25, 1);
\draw (0.5, 0.5) -- (1.25, 0.5);
\node at (2.5, 0.5) {\small{shared prefix $aab$}};

\end{diagram}

\noindent
We can form a locale from this topology. Let $\category{L}$ be the locale given by the presentation $\tuple{G, R}$, where:

\begin{itemize}

\item $G = \{ U_{w} \mid w \in \Sigma^{n} \}$, i.e., each open is a generator.
\item $R = \{ U_{w} \childOf/ U_{v} \mid v \subseteq w \}$, i.e., bouquets with longer prefixes are lower.

\end{itemize}

\noindent
For example, given $\Sigma^{\leqslant 2}$, we have the following generators:

\begin{itemize}

\item $G = \{ U_{\epsilon}, U_{a}, U_{b}, U_{aa}, U_{bb}, U_{ab}, U_{ba} \}$.

\end{itemize}

\noindent
Here are some of the relations:

\begin{itemize}

\item $U_{aa} \childOf/ U_{a}$ and $U_{ab} \childOf/ U_{a}$, since ``$a$'' is a prefix of $aa$ and $ab$.
\item $U_{bb} \childOf/ U_{b}$ and $U_{ba} \childOf/ U_{b}$, since ``$b$'' is a prefix of $bb$ and $ba$.
\item Every generator is lower than $U_{\epsilon}$, since $\epsilon$ (the empty sequence) is a prefix of every sequence.

\end{itemize}

\noindent
The Hasse diagram looks like this:

\begin{diagram}

\node (e) at (0, 3) {$U_{\epsilon}$};

\node (a) at (-1.5, 2) {$U_{a}$};
\node (b) at (1.5, 2) {$U_{b}$};

\node (aa) at (-3, 1) {$U_{aa}$};
\node (ab) at (-1, 1) {$U_{ab}$};
\node (ba) at (1, 1) {$U_{ba}$};
\node (bb) at (3, 1) {$U_{bb}$};

\node (bottom) at (0, -0.5) {$\bottom/$};

\draw (bottom) to (aa);
\draw (bottom) to (ab);
\draw (bottom) to (ba);
\draw (bottom) to (bb);

\draw (aa) to (a);
\draw (ab) to (a);
\draw (ba) to (b);
\draw (bb) to (b);

\draw (a) to (e);
\draw (b) to (e);

\end{diagram}

Think of moving upwards in this locale as forgetting information about (or alternatively, as committing less to) the history of the sequence. For example, think of $U_{ab}$ as a region where we know that ``$a$'' happened first and then ``$b$'' happened, but think of $U_{a}$ as a region where we know only that ``$a$'' happened first and we don't know what happened after that. The top element is $U_{\epsilon}$, which means we don't know anything about the sequence of actions. The $\bottom/$ element indicates not that we know nothing, but that there is no sequence at all.

Notice that implication moves upwards: $U_{ab}$ implies $U_{a}$ because if I know (at $U_{ab}$) that ``$a$'' happened first and then ``$b$'' happened, then I certainly know that ``$a$'' happened first. 

Further, no generator is the non-trivial overlap of other generators, so every generator is an atomic region:

\begin{itemize}

\item $\atomsOf{\category{L}}$ = G

\end{itemize}

\noindent
As with any locale, we can write each region canonically as the join of its atomic regions:

\begin{itemize}

\item $U_{\support/(U)} = \bigjoin/\limits_{i \in \support/(U)} U_{i}$

\end{itemize}

\noindent
But here, what this means is that we can canonically write each region as the join of its ``most specified'' prefixes. For instance, $\support/(U_{a}) = \{ aa, ab \}$, so:

\begin{itemize}

\item $U_{a} = U_{\support/(U_{a})} = \bigjoin/ \{U_{aa}, U_{ab} \}$.

\end{itemize}

\noindent
This makes sense. Since $U_{a}$ is a region where we know only that ``$a$'' happened first, it is the join of all maximal continuations that begin with ``$a$.''

This particular locale is interesting because it models the ``process space'' of any 2-stage sequence that can make one of two choices at each stage. Let us now assign some actual processes to this ambient space, using a \Gsheaf/.

Imagine a machine $m$ that can run multiple concurrent processes, all of whom share the same memory. For simplicity, let us suppose that the machine has two registers ($R = \{ r_{1}, r_{2} \}$), each of which can hold one bit ($1$ or $0$). So, at any point in time the machine's memory state $S : \{ 0, 1 \} \times \{ 0, 1 \}$ can be one of the following:

\begin{itemize}

\item $S = \{ \tuple{0, 0}, \tuple{1, 0}, \tuple{0, 1}, \tuple{1, 1} \}$, with initial state $s_{0} = \tuple{0, 0}$.

\end{itemize}

We can think of the concurrent processes of interest as a selection of programs that we want to run on the machine all at the same time. In terms of behavior, let us say that each program-run reads a word from its input stream, one character at a time, and in response to each character, it takes one of the following actions $A$: it writes a value ($1$ or $0$) to one of the registers, it writes (possibly distinct) values to both registers, or it does nothing and leaves the registers as they are:

\begin{itemize}

\item $A = \{ \{ r1 \mapsto v \}, \{ r2 \mapsto v \}, \{ r1 \mapsto v, r2 \mapsto w \}, \EmptySet/ \}$, where $v, w \in \{ 0, 1 \}$.

\end{itemize}

We can define a process (program trace) as a map from $n$-length words to $n$-length sequences of write actions, where we require that such maps agree on prefixes (since a process responding to $ab$ and $aa$ would do the same thing on the first $a$). This way, a program trace records for each input stream the sequence of write actions that result. For concreteness, here are two such traces:

\begin{itemize}

\item $f : \Sigma^{=2} \to A \times A$

  \begin{itemize}
    \item $f(aa) = \tuple{\{ r1 \mapsto 1 \}, \{ r1 \mapsto 0 \} \}}$
    \item $f(ab) = \tuple{\{ r1 \mapsto 1 \}, \{ r2 \mapsto 0 \} \}}$
    \item $f(bb) = \tuple{\{ \{ r2 \mapsto 0 \}, \{ r2 \mapsto 1 \} \}}$
    \item $f(ba) = \tuple{\{ \{ r2 \mapsto 0 \}, \{ r1 \mapsto 1 \} \}}$
  \end{itemize}

\item $g : \Sigma^{=2} \to A \times A$

  \begin{itemize}
    \item $g(aa) = \tuple{\{ r2 \mapsto 0 \}, \{ r2 \mapsto 0 \} \}}$
    \item $g(ab) = \tuple{\{ r2 \mapsto 0 \}, \EmptySet/ \}}$
    \item $g(bb) = \tuple{\{ \{ r1 \mapsto 1 \}, \{ r1 \mapsto 0 \} \}}$
    \item $g(ba) = \tuple{\{ \{ r1 \mapsto 1 \}, \{ r1 \mapsto 1 \} \}}$
  \end{itemize}

\end{itemize}

\noindent
Let us now say that concurrent processes are compatible if they ``play well'' together, i.e., they share resources (memory) consistently. In particular, given two processes $f$ and $g$, let us say:

\begin{itemize}

\item $f$ and $g$ are compatible at stage $n$ if they write to different registers.
\item $f$ and $g$ are compatible at stage $n$ if they write the same value to the same register.
\item $f$ and $g$ conflict at stage $n$ if they write different values to the same register.

\end{itemize}

\noindent
We can formalize this notion as a gluing condition that says a selection of patch candidates glue at $U_{w}$ if they play well up to $w$. Fix a selection of programs $P = \{ f, g, \ldots \}$ to run on the machine, then:

\begin{itemize}

\item Given a selection of patch candidates $\tuple{(b_{i,p})_{p \in P}}_{i \in \support/(U_{w})}$ over a region $U_{w}$ with trace length $|w|$, $\glues{U_{w}}(\tuple{b_{i}}_{i \in \support/(U_{w})}) = \mathrm{true}$ iff the following condition holds. Write $b_{i,p}[m]$ to denote the write actions of process $p$ in region $i$ at stage $m$. Then, require that at each stage $m \leqslant |w|$ and every register $r \in R$, the set 

\[
\{ v \in \{ 0, 1 \} \mid \exists i \in \support/(U_{w}), p \in P \text{ where } r \mapsto v \in b_{i,p}[m] \}
\]

has cardinality at most 1. In other words, two values are not written to the same register.

\item $\glues{U_{w}}(\tuple{b_{i}}_{i \in \support/(U_{w})}) = \mathrm{false}$ otherwise.

\end{itemize}

\noindent
We must check that this is a legitimate gluing condition.

\begin{proof}

We must check that $\glues{U_{w}}$ is downwards and upwards stable. 

\begin{itemize}

\item \emph{Downwards stability}. Assume that $\glues{U_{w}}(\tuple{b_{i}}_{i \in \support/(U_{w})}) = \mathrm{true}$. Then $\glues{U_{i}}(\tuple{b_{i}}) = \mathrm{true}$ for each $i \in \support/(U_{w})$ since by $\glues{U_{w}}$, every $b_{i}, b_{j}$ play well on their prefixes.

\item \emph{Upwards stability}. Assume $\glues{U_{\{i, j\}}}(\tuple{b_{i}, b_{j}}) = \mathrm{true}$ for all $i, j \in \support/(U_{w})$. Then $\glues{U_{w}}(\tuple{b_{i}}_{i \in \support/(U_{w})}) = \mathrm{true}$ since no $i, j$ conflict on writes. \qedhere

\end{itemize}

\end{proof}

\noindent
With a gluing condition at hand, we can now define a \Gsheaf/ $F$. Let our selection of processes be $P = \{ f, g, \ldots \}$. Then, we can fix the atomic data (omitting outer brackets to avoid clutter):

\begin{itemize}

\item $F(U_{aa}) = (f(aa), g(aa))
  = 
  (
        \tuple{ \{ r1 \mapsto 1 \}, \{ r1 \mapsto 0 \} },
        \tuple{ \{ r2 \mapsto 0 \}, \{ r2 \mapsto 0 \} } 
  )
  .$
  
\item $F(U_{ab}) = (f(ab), g(ab))
  = 
  (
        \tuple{ \{ r1 \mapsto 1 \}, \{ r2 \mapsto 0 \} },
        \tuple{ \{ r2 \mapsto 0 \}, \EmptySet/ } 
  )
  .$

\item $F(U_{bb}) = (f(bb), g(bb))
  = 
  (
        \tuple{ \{ r2 \mapsto 0 \}, \{ r2 \mapsto 1 \} },
        \tuple{ \{ r1 \mapsto 1 \}, \{ r1 \mapsto 0 \} } 
  )
  .$

\item $F(U_{ba}) = (f(ba), g(ba))
  = 
  (
        \tuple{ \{ r2 \mapsto 0 \}, \{ r1 \mapsto 1 \} },
        \tuple{ \{ r1 \mapsto 1 \}, \{ r1 \mapsto 1 \} } 
  )
  .$

\end{itemize}

\noindent
There are no meets among the generators beyond $\bottom/$, so:

\begin{itemize}

\item $F(\bottom/) = \{ \tuple{} \}.$

\end{itemize}

\noindent
Next, we must extend $F$ to joins via gluing. So, for each $U_{w}$, we must assign:

\begin{itemize}

\item $F(U_{w}) = \{ \tuple{(b_{i,p})_{p \in P}}_{i \in \support/(U_{w})} \mid \glues{U_{w}}(\tuple{(b_{i,p})_{p \in P}}_{i \in \support/(U_{w})}) = \mathrm{true} \}.$

\end{itemize}

\noindent
Let's compute $F(U_{a})$ = $F(U_{aa} \join/ U_{ab})$. To determine if $(f(aa), g(aa))$ and $(f(ab), g(ab))$ glue, we need to check that they do not write conflicting values.

\begin{itemize}

\item Stage 1 (at the shared prefix ``$a$''): $f(aa)$ and $f(ab)$ write $1$ to $r1$, while $g(aa)$ and $g(ab)$ write $0$ to $r2$. Since $f$ and $g$ write to different registers, there is no conflict.

\item Stage 2: $f(ab)$ and $g(aa)$ write the same value (namely, $0$) to $r2$, $f(aa)$ writes $0$ to $r1$, and $g(ab)$ does nothing, so there are no conflicts. 

\end{itemize}

\noindent
Hence, $(f(aa), g(aa))$ and $(f(ab), g(ab))$ glue to form a unique section:

\begin{itemize}

\item $F(U_{a}) = (f(aa), g(aa)), (f(ab), g(ab))$

\end{itemize}

\noindent
Now let's compute $F(U_{b})$ = $F(U_{bb} \join/ U_{ba})$. To determine if $(f(bb), g(bb))$ and $(f(ba), g(ba))$ glue, we need to again check for conflicting writes:

\begin{itemize}

\item Stage 1 (at the shared prefix ``$b$''): $f(bb)$ and $f(ba)$ write $0$ to $r2$, while $g(bb)$ and $g(ba)$ write $1$ to $r1$, so there is no conflict.

\item Stage 2: $f(bb)$ and $f(ba)$ write $1$ to different registers, so they do not conflict with each other, while $f(ba)$ and $g(ba)$ write $1$ to $r1$, so they do not conflict either. However, $g(bb)$ writes $0$ to $r1$, which conflicts with $g(ba)$'s and $f(ba)$'s attempt to write $1$ to the same register.

\end{itemize}

\noindent
Since we have a conflict, $(f(bb), g(bb))$ and $(f(ba), g(ba))$ fail to glue over $U_{b}$. Notice:

\begin{itemize}

\item The processes $f$ and $g$ agree locally at $U_{a}$.
\item By contrast, they disagree locally at $U_{b}$.
\item There is no global section that glues together all of $f$ and $g$'s behavior at the top $U_{\epsilon}$, thus $f$ and $g$ are not globally compatible processes. 

\end{itemize}

This sort of example illustrates how sheaves can model processes, concurrency, and resource conflicts. Here the processes were programs running on a simple machine, but they could just as easily be biological processes competing for resources, etc.

Whatever the concrete details may be, this example captures how local behavior can be integrated and extended over larger regions of the process space. One might naively think that the ``parts'' of such systems are the processes. But there is a different way to slice it: if you want to talk about the integrity of the ``whole'' of a concurrent system, you need to talk about how that involves coherent, integrated behavior that is functionally united locally across the various ``regions'' and ``stages'' of the system's evolution.

\end{Example}


% ----------------------------------------
TODO:
\begin{itemize}

\item Add example: something over a continuous interval/timeline? E.g., maybe something over a timeline (the frame of opens taken from  the usual topology of R)? Maybe we can define a gluing condition for a mass of clay over time that says pieces glue if they agree on overlaps, so that the whole lump of clay can have parts replaced over time but as a whole it never breaks into fragments? Maybe the "closure" is even a modality.

\item Add example: Socrates and seated Socrates?

\item Note Spivak et al's behavioral mereology is an example of a \Gsheaf/ (and check the details to make sure that's really true).

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Modalities in the Sheaf-theoretic Setting}
\label{sec:modalities}

\noindent
In the context of sheaves, modalities manifest as $j$-operators (also called local operators). A $j$-operator is a closure operator on the underlying locale.

% ----------------------------------------
\begin{Definition}[$j$-operators]

Given a locale $\category{L}$, a $j$-operator on $\category{L}$ is a closure operator $\jop{} : \category{L} \to \category{L}$ satisfying the following conditions:

\begin{enumerate}

\item [(J1)] \emph{Inflation}. $U \childOf/ \jop{}(U)$.

\item [(J2)] \emph{Idempotence}. $\jop{}(\jop{}(U)) = \jop{}(U)$.

\item [(J3)] \emph{Meet-preservation}. $\jop{}(U \meet/ V) = \jop{}(U) \meet/ \jop{}(V)$.

\end{enumerate} 

\end{Definition}


A $j$-operator induces a $j$-sheaf.

% ----------------------------------------
\begin{Definition}[$j$-sheaves]

Given a sheaf $F$ over a locale $\category{L}$ and a $j$-operator $\jop{} : \category{L} \to \category{L}$, the corresponding $j$-sheaf, denoted $F_{\jop{}}$, is given by:
\[
  F_{\jop{}} = F(\jop{}(U)).
\]

\end{Definition}

\begin{Remark}

In a sheaf, there are a variety of other modalities beyond the traditional alethic ones (necessity and possibility). Any closure operator qualifies as a modality of some description.

\end{Remark}


% ----------------------------------------
\begin{Example}
\label{ex:reachability-modality-on-human-society}

From \cref{ex:human-society}, recall the mesh of human relationships modeled by a \Gsheaf/ $F$ defined over the presented locale $\category{L}$ = $\tuple{P := \{ A, B, C, D \}, \EmptySet/}$. Let us define a family of ``reachability'' modalities over this mesh.

For each $r \in R$, write $\rightsquigarrow_{r}$ for the reflexive and transitive closure of $r$ on the generators. Hence, $\rightsquigarrow_{f}$ is the transitive closure of friendship on the generators, and $\rightsquigarrow_{m}$ is the transitive closure on marriage. 

Then for each $r \in R$, define $\jop{r}$ inductively:

\begin{itemize}

\item \emph{Base case}. For each generator $U \in G$, set $\jop{r}$ to the join of all other generators reachable via $r$:

\[
  \jop{r}(U) := \bigjoin/ \{ V \mid U \rightsquigarrow_{r} V \}
\]

\item \emph{Inductive step}. Extend to arbitrary joins $U_{\support/(U)}$:

\[
  \jop{r}(U_{\support/(U)}) := \bigjoin/\limits_{i \in \support/(U)} \jop{r}(U_{i})
\]

\end{itemize}

\noindent
We need to check that this is a $j$-operator.

\begin{proof}

We check (J1)--(J3) from the definition.

TODO. Do the base case, then the inductive step. \qedhere

\end{proof}

Intuitively, this operator expands every region $U$ to the largest region that is reachable from $U$ by $r$. In other words, it expands each subset of society to the largest subset of society that is connected by $r$. Hence, $\jop{f}(U)$ yields all those who are connected to $U$ through a chain of friends, while $\jop{m}(U)$ yields all those who are connected to $U$ through a chain of marriage (which in a monogamous society will yield only married couples but in a polygamous society may be more revealing).

Applying $\jop{f}$ (for instance) to $\category{L}$ yields the following:

\begin{itemize}

\item $\jop{f}(A) = A \join/ B \join/ C \join/ D$, because $A \rightsquigarrow_{f} A$, $A \rightsquigarrow_{f} B$, $A \rightsquigarrow_{f} D$, and $A \rightsquigarrow_{f} C$.

\item $\jop{f}(B) = A \join/ B \join/ C \join/ D$, because $B \rightsquigarrow_{f} B$, $B \rightsquigarrow_{f} D$, $B \rightsquigarrow_{f} A$, and $B \rightsquigarrow_{f} C$.

\item Similar for $\jop{f}(C)$ ad $\jop{f}(D)$.

\item $\jop{f}(\bottom/) = \bottom/$.

\end{itemize}

\noindent
Hence, everyone in this mini-society is connected through friends (or friends-of-friends, etc.). Notice also that everyone is connected \emph{immediately}, i.e., at the first application of $\jop{f}$.

When it comes to marriage, the situation is different. Applying $\jop{m}$ yields:

\begin{itemize}

\item $\jop{m}(A) = A \join/ B$, because $A \rightsquigarrow_{m} A$ and $A \rightsquigarrow_{m} B$.

\item $\jop{m}(B) = A \join/ B$, because $B \rightsquigarrow_{m} B$ and $B \rightsquigarrow_{m} A$.

\item $\jop{m}(C) = C \join/ D$, because $C \rightsquigarrow_{m} C$ and $C \rightsquigarrow_{m} D$.

\item Similar for $\jop{m}(D)$.

\item $\jop{m}(A \join/ B) = A \join/ B$, since $A$ and $B$ are already connected.

\item $\jop{m}(C \join/ D) = C \join/ D$, since $C$ and $D$ are already connected.

\item $\jop{m}(A \join/ C) = A \join/ B \join/ C \join/ D$, since from $A$, $A$ can reach $B$ (i.e., $A \rightsquigarrow_{m} B$) and from $C$, $C$ can reach $D$ (i.e., $C \rightsquigarrow_{m} D$).

\item Similar for the rest.

\end{itemize}

\noindent
In contrast to the $\jop{f}$ modality, the $\jop{m}$ modality keeps the $A, B$ component separate from the $C, D$ component at all regions (sub-populations) that don't include a member of both couples, just as we would expect.

Now that we have defined $\jop{f}$ and $\jop{m}$, we can construct a modal overlay for each that we can use to filter the original mesh:

\begin{itemize}

\item Define the friendship mesh as $F_{f}$, filtered by $\jop{f}$, i.e., set $F_{f}(U) := F(\jop{f}(U))$.

\item Define the marriage mesh as $F_{m}$, filtered by $\jop{m}$, i.e., $F_{m}(U) := F(\jop{m}(U))$.

\end{itemize}

\end{Example}



% ----------------------------------------
\begin{Example}
\label{ex:already-happened-modality-on-simple-processes}

Recall the example of concurrent processes $f$ and $g$ from \cref{ex:simple-processes}. We can define an \emph{``already happened''} modality that captures what has definitely occurred so far. 

\begin{Definition}[Already-happened operator]

Let $\jop{H}$ be given by:

\[
  \jop{H}(U_{w}) := \bigjoin/ \{ U_{v} \mid v \subseteq w \},
\]

\noindent
i.e., the join of all opens corresponding to prefixes of $w$ (including $w$ itself).

\end{Definition}

Intuitively, $\jop{H}(U_{w})$ is the region that remembers everything that has already happened along $w$. It is a closure operator that closes upwards by collecting all shorter prefixes.

We must check that this is a legitimate $j$-operator.

\begin{proof}

We check (J1)--(J3).

\begin{itemize}

\item [J1] \emph{Inflation}. $U_{w} \childOf/ \jop{H}(U_{w})$ holds because $U_{w}$ is included among the prefixes being joined.  

\item [J2] \emph{Idempotence}. Applying $\jop{H}$ again adds no new prefixes, so $\jop{H}(\jop{H}(U_{w})) = \jop{H}(U_{w})$.

\item [J3] \emph{Meet-preservation}. The meet of two regions corresponds to their longest shared prefix, whose prefixes are all of the prefixes collected by $\jop{H}$. Hence, $\jop{H}(U_{w} \meet/ U_{v}) = \jop{H}(U_{w}) \meet/ \jop{H}(U_{v})$. \qedhere

\end{itemize}

\end{proof}

\noindent
Applying $\jop{H}$ to the generators of $\category{L}$:

\begin{itemize}

\item For $U_{aa}$: $\jop{H}(U_{aa}) = U_{\epsilon} \join/ U_{a} \join/ U_{aa}$.  
\item For $U_{ab}$: $\jop{H}(U_{ab}) = U_{\epsilon} \join/ U_{a} \join/ U_{ab}$.  
\item For $U_{ba}$: $\jop{H}(U_{ba}) = U_{\epsilon} \join/ U_{b} \join/ U_{ba}$.  
\item For $U_{bb}$: $\jop{H}(U_{bb}) = U_{\epsilon} \join/ U_{b} \join/ U_{bb}$.  
\item For $U_{a}$: $\jop{H}(U_{a}) = U_{\epsilon} \join/ U_{a}$.  
\item For $U_{b}$: $\jop{H}(U_{b}) = U_{\epsilon} \join/ U_{b}$.  
\item For $U_{\epsilon}$: $\jop{H}(U_{\epsilon}) = U_{\epsilon}$.  

\end{itemize}

\noindent
Since $\jop{H}$ filters each region to everything that is already determined in that region, we can use it to define an overlay of $F$

\[
  F_{H}(U_{w}) := F(\jop{H}(U_{w})),
\]

\noindent
so that sections at $U_{w}$ remember only what has happened along all prefixes of $w$.

\end{Example}


% ----------------------------------------
\begin{Example}
\label{ex:safety-modality-on-simple-processes}

Recall the example of concurrent processes $f$ and $g$ from \cref{ex:simple-processes}. We can define a safety (``nothing bad happens'') modality as a $j$-operator that identifies the largest safe extensions of a given region.

\begin{Definition}[Safety operator]

Let us say that a region $U$ is safe if all processes in $F(U)$ play well together, i.e., if there are no write conflicts. Then let $\jop{S} : \category{L} \to \category{L}$ be given by:

\[
  \jop{S}(U) := 
    \begin{cases}
      \bigjoin/ \{ V \mid U \childOf/ V \text{ and } V \text{ is safe} \} & \text{if this join is non-empty} \\
      U & \text{otherwise}.
    \end{cases}
\]

\end{Definition}

\noindent
Intuitively, $\jop{S}(U)$ inflates $U$ to the largest region that is guaranteed safe starting from $U$.

We must check that $\jop{S}(U)$ is a legitimate $j$-operator.

\begin{proof}

We check (J1)--(J3).

\begin{itemize}

\item [J1] \emph{Inflation}. By construction, $U \childOf/ \jop{S}(U)$ whenever $U$ has any safe parent regions, otherwise $\jop{S}(U) = U$.

\item [J2] \emph{Idempotence}. Applying $\jop{S}$ more than once does not change the result, since appyling it once takes the join of all safe parents. Hence, $\jop{S}(\jop{S}(U)) = \jop{S}(U)$.

\item [J3] \emph{Meet-preservation}. For any $U$ and $V$, since $U \meet/ V$ is $U$ or $V$, 
\[
  \jop{S}(U \meet/ V) = 
  \bigjoin/ \{ W \mid U \meet/ V \childOf/ W \text{ and } W \text{ safe} \} = 
  \jop{S}(U) \meet/ \jop{S}(V).  \qedhere
\]

\end{itemize}

\end{proof}

\noindent
Let's apply $\jop{S}$ to the generators of $\category{L}$:

\begin{itemize}

\item $\jop{S}(U_{aa}) = U_{a}$ since its safe parent regions are $U_{aa}$ and $U_{a}$.

\item Similarly, $\jop{S}(U_{ab}) = U_a$.

\item $\jop{S}(U_{ba}) = U_{ba}$ because the only safe parent of $U_{ba}$ is $U_{ba}$ itself.

\item Similarly, $\jop{S}(U_{bb}) = U_{bb}$.

\end{itemize}

\noindent
Now extend it to joins:

\begin{itemize}

\item $\jop{S}(U_{a}) = \jop{S}(U_{aa}) \join/ \jop{S}(U_{ab}) = U_{a} \join/ U_{a} = U_{a}$.

\item $\jop{S}(U_{b})= U_{b}$ since $U_{b}$ is unsafe (there are conflicts among its generators) and thus no further extension can be safe.

\item $\bottom/$ is trivially fixed: $\jop{S}(\bottom/) = \bottom/$.

\end{itemize}

\noindent
Notice:

\begin{itemize}

\item Each generator $U_{w}$ represents a part of a process's history.

\item The operator $\jop{S}$ identifies the largest safe fusion containing $U_{w}$, i.e., the maximal extension of the part where processes play well together.  

\item If no safe extensions exist (as in $U_{b}$), then $\jop{S}(U_b)$ doesn't get bigger, indicating that safety cannot be guaranteed any further beyond this part.

\item Hence, $\jop{S}$ captures a mereological notion of integrity, showing which combinations of parts form consistent wholes and which do not.

\end{itemize}

\end{Example}


% ----------------------------------------
\noindent
TODOs:

\begin{itemize}

\item Add example: A statue and the lump of clay?

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Classical Mereological Notions in the Sheaf-theoretic Setting}
\label{sec:classical-mereology-in-sheaves}

\noindent
In this section, we provide a discussion of what classical notions of mereology look like in the sheaf-theoretic setting.

\begin{itemize}

\item \emph{Cambridge fusions}. Sheaves handle Cambridge fusions correctly.

\item \emph{Mere collections}. The collection of all dogs. Is that a ``whole''? Well, we could build a sheaf whose atomic regions are filled with dogs, none of which glue. Then we have a collection of dogs, but no glued object. That matches exactly the intuition: yes, we have a ``collection'' (we built a sheaf for it, after all), but the internals of that sheaf reveal that it's \emph{merely} a collection, i.e., that its parts are not glued.

\item \emph{Co-habitating fusions}. Sheaves allow multiple fusions to occupy the same locale, without being glued. For instance, in the sheaf of real-valued functions over real number line, there are many functions that glue together, and occupy the same locale. 

\item \emph{Non-boolean algebra}. The parts space is Heyting, not Boolean. We're not saddled with such a strong complement operation. You can pick a locale that is Boolean if you need it, but this framework doesn't require it. In fact, the positive logic of a locale is ``geometric logic.''

\item \emph{Reflexivity, antisymmetry, and transitivity}. These are guaranteed. Locally, of course, you may not have transitivity. But globally, it's a theorem. [Check that.]

\item \emph{Distributivity}. TODO: do the glued sections of a sheaf have to be distrubitive? Only inside what glues (since we glue pairwise, so every $i \join/ j$ of the cover.

\item \emph{An empty element}. There is a need for a bottom element in the \emph{algebra} of parts, but a sheaf need not contain any such thing. There is no need here to try and construct awkward mathematical structures that do algebra on parts but yet don't have a bottom element because our ontological intuitions tell us there can be no such thing. That confuses two issues: algebra and integrity. So here we separate those cleanly, and the algebra can do algebra while the sheaf can do integrity. [In a sheaf you CAN'T assign an empty element to bottom, for coherence, so the bottom element is special...need to say more about that and figure it out.]

\item \emph{Supplementation principles}. Sheaves don't constrain one way or another. [Is that really true? Maybe it's better to say that it doesn't force any supplementation principles, which might provide a reason to call into question whether supplementation is another one of those ideas that is about integrity of parts but has been confused with the algebra of parts.]

\item \emph{Ordering of parts}. Consider that ``pit'' and ``tip'' have the same parts but are different words. These differences can be handled by different sheaves over a 3-stage prefix-ordered locale as in the example of concurrent processes. Note that we retain extensionality.

\item \emph{Extensionality}. Classical mereology's notion of extensionality essentially flattens any structure and is thus overly aggressive. This is why extensionality is so controversial. The sheaf-theoretic perspective retains extensionality, but is much more nuanced. [Here too, I suspect that mereological discussions of extensionality have confused the algebra of parts and the integrity of wholes.]

\item \emph{Gunk and atoms}. You can model continuity and gunky parts if you so desire. You just need a sober space to do it. TODO: check that we can model continuity in the locale in this way. TODO: can you do continuity only in the sheaf data, without an underlying continuous decompositon in the locale? I would think that if you can't infinitely decompose into smaller opens around a point in the locale, you couldn't do such a thing in the sheaf data?

\item \emph{Priority of wholes}. The framework is agnostic as to whether you take an  Aristotelian-Thomistic approach (TODO: cite Aquinas, Arlig, and that guy who wrote that recent book defending the Aristotelian view). 

\item \emph{The whole is greater than its parts}. The framework is agnostic as to whether you want to be a Scotist and say that the whole is something over and above its parts (cite Cross) or an Ockhamist who says it is not (TODO: cite Normore, Arlig). 

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Category Theory}
\label{sec:category-theory}

\noindent
In this section, we cover the parts of category theory that we will use in the remainder of the paper. Readers familiar with category theory can skip this section.

Since at least Aristotle's time, philosophers have been interested in placing objects of the same kind into categories. Modern category theorists do this too: a category is a collection of objects that are all the same in kind. But category theory has a further requirement: not only must you tell us what the objects are in your category, you must also tell us about the maps between them, so that we know how to relate/compare those objects. Further, those maps must compose in well-behaved ways.

% ----------------------------------------
\begin{Definition}[Categories]
 
A category $\category{C}$ consists of the following data:
 
\begin{enumerate}
 
\item A collection of objects $X$, $Y$, $Z$, and so on, denoted $\objects/(\category{C})$
\item A collection of morphisms $f : X \to Y$, $g : Y \to Z$, and so on, denoted $\morphisms/(\category{C})$, each with a designated domain (an object) and codomain (an object), such that:

  \begin{enumerate}
    \item There is an identity morphism $\ident{X} : X \to X$ for each object $X$.
    \item Morphisms compose, i.e., if $f : X \to Y$ and $g : Y \to Z$ are morphisms in $\category{C}$ such that $f$'s codomain matches $g$'s domain, then their composite $g \compose/ f : X \to Z$ (pronounced ``$g$ after $f$'') is a morphism in $\category{C}$ too.
  \end{enumerate}
 
\end{enumerate}
 
 \noindent
The objects and morphisms of $\category{C}$ must satisfy the following conditions: 

\begin{enumerate}

\item [(K1)] Composing with an identity has no effect, i.e. for any morphism $f : X \to Y$,
$$\ident{Y} \compose/ f = f \text{ and } f = f \compose/ \ident{X}.$$

\item [(K2)] Composition is associative, i.e., for any morphisms $f : X \to Y$, $g : Y \to Z$, and $h : Z \to W$,
$$(h \compose/ g) \compose/ f = h \compose/ (g \compose/ f).$$

\end{enumerate}
 
\end{Definition}

% ----------------------------------------
\begin{Example}

The category $\category{S}et$ of sets and total maps has all sets for its objects and all total function between them for its morphisms. To check that it is a category, we need to confirm that it satisfies all the requirements. 

First, does every object have an identity? Yes, because for every set $X$, there is an identity function $\ident{X} : X \to X$ given by $\ident{X}(x) = x$.  For instance, take the following set $X$:

\begin{diagram}

  \node at (-1, -0.75) {$X$};
  \draw (-0.15, 0) ellipse (0.5cm and 1cm);
  \node[dot, label=left:{$a$}] (a) at (0, 0.5) {};
  \node[dot, label=left:{$b$}] (b) at (0, -0.5) {};

\end{diagram}

There is an identity function that sends each point of $X$ to itself:

\begin{diagram}

  \node at (-1, -0.75) {$X$};
  \draw (-0.15, 0) ellipse (0.5cm and 1cm);
  \node[dot, label=left:{$a$}] (a) at (0, 0.5) {};
  \node[dot, label=left:{$b$}] (b) at (0, -0.5) {};
  
  \node at (1, 0) {$\ident{X}$};
  \draw[arrow, ->] (a) to[out=330, in=30, looseness=35] (a);
  \draw[arrow, ->] (b) to[out=330, in=30, looseness=35] (b);

\end{diagram}

Do morphisms compose? Yes: the morphisms of this category are functions, and functions compose. For instance, take the following $f : X \to Y$ and $g : Y \to Z$: 

\begin{diagram}

  \draw (0, 0.15) ellipse (0.5cm and 1cm);
  \node[dot, label=above:{$a$}] (a) at (0, 0.5) {};
  \node[dot, label=above:{$b$}] (b) at (0, -0.5) {};
  
  \draw (4, -0.85) ellipse (0.75cm and 1.25cm);
  \node[dot, label=above:{$1$}] (1) at (4, -0.25) {};
  \node[dot, label=above:{$2$}] (2) at (4, -1) {};
  \node[dot, label=above:{$3$}] (3) at (4, -1.75) {};

  \draw (8.25, 0.15) ellipse (0.5cm and 1cm);
  \node[dot, label=above:{$p$}] (p) at (8.25, 0.5) {};
  \node[dot, label=above:{$q$}] (q) at (8.25, -0.5) {};

  \node at (-0.925, -0.85) {$X$};
  \node at (3.25, -2) {$Y$};
  \node at (8.75, -0.85) {$Z$};

  \node at (1.75, -1.5) {$f$};
  \draw[arrow,->] (a) to (1);
  \draw[arrow,->] (b) to (3);
  
  \node at (6.25, -1.5) {$g$};
  \draw[arrow,->] (1) to (p);
  \draw[arrow,->] (2) to (p);
  \draw[arrow,->] (3) to (q);

\end{diagram}

Their composite $g \compose/ f : X \to Z$ is a function too:

\begin{diagram}

  \draw (0, 0.15) ellipse (0.5cm and 1cm);
  \node[dot, label=above:{$a$}] (a) at (0, 0.5) {};
  \node[dot, label=above:{$b$}] (b) at (0, -0.5) {};
  
  \draw (4, -0.85) ellipse (0.75cm and 1.25cm);
  \node[dot, label=above:{$1$}] (1) at (4, -0.25) {};
  \node[dot, label=above:{$2$}] (2) at (4, -1) {};
  \node[dot, label=above:{$3$}] (3) at (4, -1.75) {};

  \draw (8.25, 0.15) ellipse (0.5cm and 1cm);
  \node[dot, label=above:{$p$}] (p) at (8.25, 0.5) {};
  \node[dot, label=above:{$q$}] (q) at (8.25, -0.5) {};

  \node at (-0.925, -0.85) {$X$};
  \node at (3.25, -2) {$Y$};
  \node at (8.75, -0.85) {$Z$};

  \node at (1.75, -1.5) {$f$};
  \draw[arrow,->] (a) to (1);
  \draw[arrow,->] (b) to (3);
  
  \node at (6.25, -1.5) {$g$};
  \draw[arrow,->] (1) to (p);
  \draw[arrow,->] (2) to (p);
  \draw[arrow,->] (3) to (q);

  \node at (4, 1) {$g \compose/ f$};
  \draw[arrow,->] (a) to[out=30, in=150] (p);
  \draw[arrow,->] (b) to[out=45, in=135] (q);

\end{diagram}

Further, it is clear that composing with an identity has no effect, since identity functions do not shuffle around any points. It is also clear that function composition is associative: it does not matter if I take $f$ first and then $h \compose/ g$, or $g \compose/ f$ first and then $h$. I get to the same results either way. So $\category{S}et$ is a genuine category.

\end{Example}

% ----------------------------------------
\begin{Example}

The category $\category{T}op$ of topological spaces and continuous maps is the category whose objects are all topological spaces and whose morphisms are the continuous maps between them.

\end{Example}

% ----------------------------------------
\begin{Example}

The category $\category{F}rm$ of frames and frame homomorphisms is the category whose objects are frames and whose morphisms are frame homomorphisms, i.e., maps that preserve arbitrary joins and finite meets.

\end{Example}

% ----------------------------------------
\begin{Example}

A poset can be seen as a category. For example, consider the powerset of $\{ a, b \}$, ordered by inclusion. The Hasse Diagram looks like this:

\begin{diagram}

  \node (ab) at (0, 3) {$\{ a, b \}$};
  \node (a) at (-1.5, 1.5) {$\{ a \}$};
  \node (b) at (1.5, 1.5) {$\{ b \}$};
  \node (bottom) at (0, 0) {$\EmptySet/$};
  
  \draw (bottom) to (a);
  \draw (bottom) to (b);
  \draw (a) to (ab);
  \draw (b) to (ab);

\end{diagram}

The fact that the elements of this diagram are sets is inessential. We could relabel them with arbitrary names to make the structure of the underlying poset obvious:

\begin{diagram}

  \node[dot] (ab) at (0, 3) [label=above:$s$] {};
  \node[dot] (a) at (-1.5, 1.5) [label=left:$p$] {};
  \node[dot] (b) at (1.5, 1.5) [label=right:$q$] {};
  \node[dot] (bottom) at (0, 0) [label=below:$r$] {};
  
  \draw (bottom) to (a);
  \draw (bottom) to (b);
  \draw (a) to (ab);
  \draw (b) to (ab);

\end{diagram}

Hasse diagrams only show the minimal information needed to understand the poset. A poset is reflexive and transitive, but we don't draw lines for the reflexive and transitive steps, to avoid clutter. Thus, for instance, in this case, although $p \leqslant p$, we don't draw a line to represent it in the Hasse diagram. However, if we were to draw the full poset, we would get something that looks like this:

\begin{diagram}

  \node[dot, label=above:{$s$}] (ab) at (0, 3) {};
  \node[dot, label=left:{$p$}] (a) at (-1.5, 1.5) {};
  \node[dot, label=right:{$q$}] (b) at (1.5, 1.5) {};
  \node[dot, label=below:{$r$}] (bottom) at (0, 0) {};
  
  \draw[arrow, ->] (bottom) to (a);
  \draw[arrow, ->] (bottom) to (b);
  \draw[arrow, ->] (a) to (ab);
  \draw[arrow, ->] (b) to (ab);

  \draw[arrow, ->] (bottom) to[out=120, in=240, looseness=1.5] (ab);
  \draw[arrow, ->] (bottom) to[out=60, in=300, looseness=1.5] (ab);

  \draw[arrow, ->] (ab) to[out=40, in=140, looseness=30] (ab);
  \draw[arrow, ->] (a) to[out=230, in=120, looseness=30] (a);
  \draw[arrow, ->] (b) to[out=320, in=60, looseness=30] (b);
  \draw[arrow, ->] (bottom) to[out=320, in=220, looseness=30] (bottom);

\end{diagram}

\noindent
This is category. It's objects are the points ($r$, $p$, $q$, and $s$), and its morphisms are the arrows in the picture. It has identities (each reflexive loop), morphisms compose (because a poset is transitive), and so on.

This illustrates that the morphisms in a category need not be functions, nor do they need to be function-like. Here, we put a morphism between two objects just to state a fact about the poset: a morphism from $p$ to $s$ simply means $p \leqslant s$, i.e., that ''$p$ is lower than $s$ in the ordering.''

\end{Example}


% ----------------------------------------
\begin{Definition}[Opposite categories]

For any category $\category{C}$, define the opposite category $\oppCategory{C}$ as the category with the same objects as $\category{C}$, but whose morphisms and composition are turned around. That is:

\begin{enumerate}

\item For any morphism $f : X \to Y$ in $\category{C}$, the corresponding morphism in $\oppCategory{C}$ is $f^{op} : Y \to X$.

\item For any morphisms $f : X \to Y$, $g : Y \to Z$, and their composite $g \compose/ f : X \to Z$ in $\category{C}$, the correspond morphisms and composite in $\oppCategory{C}$ are $f^{op} : Y \to X$, $g^{op} : Z \to Y$, and $(g \compose/ f)^{op}$ = $f^{op} \compose/ g^{op} : Z \to X$.

\end{enumerate}

\end{Definition}

% ----------------------------------------
\begin{Example}

The category $\category{L}oc$ of locales is defined as the opposite category of $\category{F}rm$. Thus, the objects of $\category{L}oc$ are the same objects as $\category{F}rm$, which is why we can call a frame a locale or vice versa.

\end{Example}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Functors}

\noindent
Functors are maps between categories that preserve categorical structure. That is, a functor maps one category to another in such a way that it preserves the identities and composition of the original category, so that you end up picking out a kind of ``image'' of the first category in the second category.

% ----------------------------------------
\begin{Definition}[Functors]

A functor $\functor{F} : \category{J} \to \category{C}$ is comprised of the following data:

\begin{enumerate}

  \item A mapping of objects to objects, i.e., for each object $X \in \category{J}$, $\functor{F}(X)$ is an object in $\category{C}$.
  
  \item A mapping of morphisms to morphisms, i.e., for each morphism $f : X \to Y$ in $\category{J}$, $\functor{F}(f) : \functor{F}(X) \to \functor{F}(Y)$ is a morphism in $\category{C}$.

\end{enumerate}

\noindent
Further, these mappings must satisfy the following conditions:

\begin{enumerate}

\item [(F1)] $\functor{F}$ preserves identities, i.e.,
$$\functor{F}(\ident{X}) = \ident{\functor{F}(X)}.$$

\item [(F2)] $\functor{F}$ preserves composition, i.e. for any $f : X \to Y$ and $g : Y \to Z$ in $\category{C}$,
$$\functor{F}(g \compose/ f) = \functor{F}(f) \compose/ \functor{F}(g).$$

\end{enumerate}

\noindent
A functor $\functor{F} : \category{J} \to \category{C}$ is also called a diagram, because it picks out $\category{J}$-shaped figures of $\category{C}$. $\category{J}$ is then called the indexing category, because the objects and morphisms of $\functor{F}$'s image are indexed by the objects and morphisms of $\functor{J}$.

A functor to or from an opposite category (e.g., $\functor{F} : \oppCategory{J} \to \category{C}$ or $\functor{F} : \category{J} \to \oppCategory{C}$) is called a contravariant functor because the morphisms go in opposite directions on either side of the functor.

\end{Definition}


% ----------------------------------------
\begin{Example}

Suppose $\category{J}$ consists of two objects and one non-trival morphism, something like this (we do not draw identity morphisms):

\begin{diagram}
  \node at (-3, 0) {$\category{J}$};
  \node (A) at (0, 0) {$A$};
  \node (B) at (4, 0) {$B$};
  \draw[arrow,->] (A) to (B);
  \node at (2, -0.25) {$f$};
\end{diagram}

\noindent
Then a functor $\functor{F}$ from $\category{J}$ to $\category{S}et$ uses $\category{J}$ as a kind of template: it picks out a set $\functor{F}(A)$ for $A$, a set $\functor{F}(B)$ for $B$, and a function $\functor{F}(f) : \functor{F}(A) \to \functor{F}(B)$ for $f$. For instance, to build such an $\functor{F}$, for $A$ we might pick the set $\{ a, b \}$: 

\begin{diagram}

  \node (A) at (0, 2.5) {$A$};
  \node (B) at (4, 2.5) {$B$};
  \draw[arrow,->] (A) to (B);
  \node (f) at (2, 2.25) {$f$};

  \node at (-3, 2.5) {$\category{J}$};
  \draw[dotted] (-3, 1.5) to (8, 1.5);
  \node at (-3, 1) {$\category{S}et$};

  \draw (-0.15, 0) ellipse (0.5cm and 1cm);
  \node[dot, label=left:{$a$}] (a) at (0, 0.5) {};
  \node[dot, label=left:{$b$}] (b) at (0, -0.5) {};

  \node at (-1.5, 0) {$\functor{F}(A)$};

  \draw[arrow, ->, dashed] (A) to[out=240, in=100] (-0.25, 1);

\end{diagram}

\noindent
Then for $B$ we might pick the set $\{ 1, 2, 3 \}$:

\begin{diagram}

  \node (A) at (0, 2.5) {$A$};
  \node (B) at (4, 2.5) {$B$};
  \draw[arrow,->] (A) to (B);
  \node (f) at (2, 2.25) {$f$};

  \node at (-3, 2.5) {$\category{J}$};
  \draw[dotted] (-3, 1.5) to (8, 1.5);
  \node at (-3, 1) {$\category{S}et$};

  \draw (-0.15, 0) ellipse (0.5cm and 1cm);
  \node[dot, label=left:{$a$}] (a) at (0, 0.5) {};
  \node[dot, label=left:{$b$}] (b) at (0, -0.5) {};
  
  \draw (4.15, 0) ellipse (0.75cm and 1.25cm);
  \node[dot, label=right:{$1$}] (1) at (4, 0.75) {};
  \node[dot, label=right:{$2$}] (2) at (4, 0) {};
  \node[dot, label=right:{$3$}] (3) at (4, -0.75) {};

  \node at (-1.5, 0) {$\functor{F}(A)$};
  \node at (5.75, 0) {$\functor{F}(B)$};

  \draw[arrow, ->, dashed] (A) to[out=240, in=100] (-0.25, 1);
  \draw[arrow, ->, dashed] (B) to[out=300, in=80] (4.25, 1.25);

\end{diagram}

\noindent
Finally, for $f$ we might pick the function that sends $a$ to 2 and $b$ to $3$:

\begin{diagram}

  \node (A) at (0, 2.5) {$A$};
  \node (B) at (4, 2.5) {$B$};
  \draw[arrow,->] (A) to (B);
  \node (f) at (2, 2.25) {$f$};

  \node at (-3, 2.5) {$\category{J}$};
  \draw[dotted] (-3, 1.5) to (8, 1.5);
  \node at (-3, 1) {$\category{S}et$};

  \draw (-0.15, 0) ellipse (0.5cm and 1cm);
  \node[dot, label=left:{$a$}] (a) at (0, 0.5) {};
  \node[dot, label=left:{$b$}] (b) at (0, -0.5) {};
  
  \draw (4.15, 0) ellipse (0.75cm and 1.25cm);
  \node[dot, label=right:{$1$}] (1) at (4, 0.75) {};
  \node[dot, label=right:{$2$}] (2) at (4, 0) {};
  \node[dot, label=right:{$3$}] (3) at (4, -0.75) {};

  \draw[arrow, ->] (a) to (2);
  \draw[arrow, ->] (b) to (3);

  \node at (-1.5, 0) {$\functor{F}(A)$};
  \node at (5.75, 0) {$\functor{F}(B)$};
  \node at (2, -1) {$\functor{F}(f)$};

  \draw[arrow, ->, dashed] (A) to[out=240, in=100] (-0.25, 1);
  \draw[arrow, ->, dashed] (B) to[out=300, in=80] (4.25, 1.25);
  \draw[arrow, ->, dashed] (f) to[out=255, in=90] (1.75, 0.5);

\end{diagram}

\noindent
Or, to draw the same picture without the internal details:

\begin{diagram}

  \node (A) at (0, 2.5) {$A$};
  \node (B) at (4, 2.5) {$B$};
  \draw[arrow,->] (A) to (B);
  \node (f) at (2, 2.25) {$f$};

  \node at (-3, 2.5) {$\category{J}$};
  \draw[dotted] (-3, 1.5) to (8, 1.5);
  \node at (-3, 1) {$\category{S}et$};

  \node (FA) at (0, 0) {$\functor{F}(A)$};
  \node (FB) at (4, 0) {$\functor{F}(B)$};
  \node at (2, -0.25) {$\functor{F}(f)$};

  \draw[arrow, ->] (FA) to (FB);

  \draw[arrow, ->, dashed] (A) to[out=240, in=100] (-0.25, 0.25);
  \draw[arrow, ->, dashed] (B) to[out=300, in=80] (4.25, 0.25);
  \draw[arrow, ->, dashed] (f) to[out=255, in=100] (1.825, 0.25);
  \node at (5, 1.5) {$\functor{F}$};

\end{diagram}

\noindent
This makes it clear that $\functor{F}$ picks out a $\category{J}$-shaped piece of $\category{S}et$: namely, a piece of $\category{S}et$ that consists of two objects with one non-trivial morphism between them.

We could construct a different functor $\functor{G} : \category{J} \to \category{S}et$ by picking different sets with a different morphism between them, in which case we would thereby pick out a different $\category{J}$-shaped piece of $\category{S}et$.

\end{Example}

\begin{Remark}

Functors do not always pick out \emph{isomorphic} $\category{J}$-figures. A functor can collapse parts of $\category{J}$ and still preserve its identities and composition. For instance, a functor can send all objects of $\category{J}$ to the one-element set $\{ \ast \}$ in $\category{S}et$ and all morphisms of $\category{J}$ to its identity $\ast \mapsto \ast$.

\end{Remark}

\begin{Remark}

A contravariant functor from an indexing category $\category{J}$ to $\category{S}et$ is a presheaf. The signature of such a functor is $F: \oppCategory{J} \to \category{S}et$. To see why this is a presheaf, consider the following. $\oppCategory{J}$ is the base category, and $F$ assigns to each object $U \in \oppCategory{J}$ a set. This is the data over the fiber of $U$. For each morphism $f : V \to U$ in $\oppCategory{J}$, $F$ sends $f$ to a morphism going the other direction: $F(f): F(U) \to F(V)$. These are the restriction maps. The functor laws F1 and F2 ensure that the restriction maps are unital and transitive as required.

\end{Remark}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Natural transformations}

\noindent
A natural transformation maps one $\category{J}$-figure to another. It does this by connecting up all of the objects of the first figure with those of the second in lock-step.

Visually, we can think of constructing a natural transformation as follows. Suppose we have an indexing category $\category{J}$ that looks something like this:

\begin{diagram}

  \node (X) at (2, 3) {$X$};
  \node (Y) at (2, 2) {$Y$};
  \node (Z) at (2, 1) {$Y$};
  \draw[arrow,->] (X) to (Y);
  \draw[arrow,->] (Y) to (Z);
  \node (f) at (1.75, 2.5) {$f$};
  \node (g) at (1.75, 1.5) {$g$};

  \node at (-3, 1) {$\category{J}$};

\end{diagram}

\noindent
Next, suppose we have a diagram $\functor{F}$ of $\category{J}$ over on the left:

\begin{diagram}

  \node (X) at (2, 3) {$X$};
  \node (Y) at (2, 2) {$Y$};
  \node (Z) at (2, 1) {$Y$};
  \draw[arrow,->] (X) to (Y);
  \draw[arrow,->] (Y) to (Z);
  \node (f) at (1.75, 2.5) {$f$};
  \node (g) at (1.75, 1.5) {$g$};

  \node at (-3, 1) {$\category{J}$};
  \draw[dotted] (-3, 0.5) to (8, 0.5);
  \node at (-3, 0) {$\category{C}$};

  \node (FX) at (0, 0) {$\functor{F}(X)$};
  
  \node (FY) at (-1, -1.5) {$\functor{F}(Y)$};
  
  \node (FZ) at (0, -3) {$\functor{F}(Z)$};

  \node at (-1, -0.5) {$\functor{F}(f)$};
  \draw[arrow, ->] (FX) to (FY);
  \node at (-1, -2.5) {$\functor{F}(g)$};
  \draw[arrow, ->] (FY) to (FZ);

  \node at (-1, 1) {$\functor{F}$};
  \draw[arrow, ->, dotted] (X) to[out=200,in=120] (FX);
  \draw[arrow, ->, dotted] (Y) to[out=190,in=130] (FY);
  \draw[arrow, ->, dotted] (Z) to[out=180,in=170, looseness=2] (FZ);

\end{diagram}

\noindent
Then suppose we have another diagram $\functor{G}$ of $\category{J}$ over on the right:

\begin{diagram}

  \node (X) at (2, 3) {$X$};
  \node (Y) at (2, 2) {$Y$};
  \node (Z) at (2, 1) {$Y$};
  \draw[arrow,->] (X) to (Y);
  \draw[arrow,->] (Y) to (Z);
  \node (f) at (1.75, 2.5) {$f$};
  \node (g) at (1.75, 1.5) {$g$};

  \node at (-3, 1) {$\category{J}$};
  \draw[dotted] (-3, 0.5) to (8, 0.5);
  \node at (-3, 0) {$\category{C}$};

  \node (FX) at (0, 0) {$\functor{F}(X)$};
  \node (GX) at (4, 0) {$\functor{G}(X)$};
  
  \node (FY) at (-1, -1.5) {$\functor{F}(Y)$};
  \node (GY) at (5, -1.5) {$\functor{G}(Y)$};
  
  \node (FZ) at (0, -3) {$\functor{F}(Z)$};
  \node (GZ) at (4, -3) {$\functor{G}(Z)$};

  \node at (-1, -0.5) {$\functor{F}(f)$};
  \draw[arrow, ->] (FX) to (FY);
  \node at (-1, -2.5) {$\functor{F}(g)$};
  \draw[arrow, ->] (FY) to (FZ);
  \node at (5, -0.5) {$\functor{G}(f)$};
  \draw[arrow, ->] (GX) to (GY);
  \node at (5, -2.5) {$\functor{G}(g)$};
  \draw[arrow, ->] (GY) to (GZ);

  \node at (5, 1) {$\functor{G}$};
  \draw[arrow, ->, dotted] (X) to[out=340,in=60] (GX);
  \draw[arrow, ->, dotted] (Y) to[out=350,in=50] (GY);
  \draw[arrow, ->, dotted] (Z) to[out=0,in=10, looseness=2] (GZ);

\end{diagram}

\noindent
in other words, we have two diagrams of $\category{J}$ side by side in $\category{C}$:

\begin{diagram}

  \node (FX) at (0, 0) {$\functor{F}(X)$};
  \node (GX) at (4, 0) {$\functor{G}(X)$};
  
  \node (FY) at (-1, -1.5) {$\functor{F}(Y)$};
  \node (GY) at (5, -1.5) {$\functor{G}(Y)$};
  
  \node (FZ) at (0, -3) {$\functor{F}(Z)$};
  \node (GZ) at (4, -3) {$\functor{G}(Z)$};

  \node at (-1, -0.5) {$\functor{F}(f)$};
  \draw[arrow, ->] (FX) to (FY);
  \node at (-1, -2.5) {$\functor{F}(g)$};
  \draw[arrow, ->] (FY) to (FZ);
  \node at (5, -0.5) {$\functor{G}(f)$};
  \draw[arrow, ->] (GX) to (GY);
  \node at (5, -2.5) {$\functor{G}(g)$};
  \draw[arrow, ->] (GY) to (GZ);

\end{diagram}

\noindent
We can map the one diagram ($F$) to the other ($G$) as follows. First, for each object in the left-hand $\category{J}$-figure, pick a morphism that goes over to the corresponding object in the right-hand $\category{J}$-figure. For instance, for the $X$-component, pick a morphism that goes from $\functor{F}(X)$ to $\functor{G}(X)$ (call it $\natTrans{\alpha}{X}$):

\begin{diagram}

  \node (FX) at (0, 0) {$\functor{F}(X)$};
  \node (GX) at (4, 0) {$\functor{G}(X)$};
  
  \node (FY) at (-1, -1.5) {$\functor{F}(Y)$};
  \node (GY) at (5, -1.5) {$\functor{G}(Y)$};
  
  \node (FZ) at (0, -3) {$\functor{F}(Z)$};
  \node (GZ) at (4, -3) {$\functor{G}(Z)$};

  \node at (-1, -0.5) {$\functor{F}(f)$};
  \draw[arrow, ->] (FX) to (FY);
  \node at (-1, -2.5) {$\functor{F}(g)$};
  \draw[arrow, ->] (FY) to (FZ);
  \node at (5, -0.5) {$\functor{G}(f)$};
  \draw[arrow, ->] (GX) to (GY);
  \node at (5, -2.5) {$\functor{G}(g)$};
  \draw[arrow, ->] (GY) to (GZ);
  
  \node at (2, -0.25) {$\natTrans{\alpha}{X}$};
  \draw[arrow, ->, dashed] (FX) to (GX);

\end{diagram}

\noindent
Then, for the $Y$-component, pick a morphism that connects $\functor{F}(Y)$ to $\functor{G}(Y)$:

\begin{diagram}

  \node (FX) at (0, 0) {$\functor{F}(X)$};
  \node (GX) at (4, 0) {$\functor{G}(X)$};
  
  \node (FY) at (-1, -1.5) {$\functor{F}(Y)$};
  \node (GY) at (5, -1.5) {$\functor{G}(Y)$};
  
  \node (FZ) at (0, -3) {$\functor{F}(Z)$};
  \node (GZ) at (4, -3) {$\functor{G}(Z)$};

  \node at (-1, -0.5) {$\functor{F}(f)$};
  \draw[arrow, ->] (FX) to (FY);
  \node at (-1, -2.5) {$\functor{F}(g)$};
  \draw[arrow, ->] (FY) to (FZ);
  \node at (5, -0.5) {$\functor{G}(f)$};
  \draw[arrow, ->] (GX) to (GY);
  \node at (5, -2.5) {$\functor{G}(g)$};
  \draw[arrow, ->] (GY) to (GZ);
  
  \node at (2, -0.25) {$\natTrans{\alpha}{X}$};
  \draw[arrow, ->, dashed] (FX) to (GX);
  \node at (2, -1.75) {$\natTrans{\alpha}{Y}$};
  \draw[arrow, ->, dashed] (FY) to (GY);

\end{diagram}

\noindent
Finally, for the $Z$-component, pick a morphism that connects $\functor{F}(Z)$ to $\functor{G}(Z)$:

\begin{diagram}

  \node (FX) at (0, 0) {$\functor{F}(X)$};
  \node (GX) at (4, 0) {$\functor{G}(X)$};
  
  \node (FY) at (-1, -1.5) {$\functor{F}(Y)$};
  \node (GY) at (5, -1.5) {$\functor{G}(Y)$};
  
  \node (FZ) at (0, -3) {$\functor{F}(Z)$};
  \node (GZ) at (4, -3) {$\functor{G}(Z)$};

  \node at (-1, -0.5) {$\functor{F}(f)$};
  \draw[arrow, ->] (FX) to (FY);
  \node at (-1, -2.5) {$\functor{F}(g)$};
  \draw[arrow, ->] (FY) to (FZ);
  \node at (5, -0.5) {$\functor{G}(f)$};
  \draw[arrow, ->] (GX) to (GY);
  \node at (5, -2.5) {$\functor{G}(g)$};
  \draw[arrow, ->] (GY) to (GZ);
  
  \node at (2, -0.25) {$\natTrans{\alpha}{X}$};
  \draw[arrow, ->, dashed] (FX) to (GX);
  \node at (2, -1.75) {$\natTrans{\alpha}{Y}$};
  \draw[arrow, ->, dashed] (FY) to (GY);
  \node at (2, -3.25) {$\natTrans{\alpha}{Z}$};
  \draw[arrow, ->, dashed] (FZ) to (GZ);

\end{diagram}

\noindent
By doing this, we connect each object from the left-hand figure with an object on the right-hand figure. 

A natural transformation is just such a family of connecting wires. It is a family because there are many of them: there is one such connecting wire for each ``component'' (object) of the figure. Thus, it is a family $\{ \natTrans{\alpha}{i} \}_{i \in \objects/(\category{J})}$. We can think of it as a stack of bridges: each ``bridge'' (morphism) lets us travel from a component in the left-hand figure to the corresponding component in the right-hand figure.

However, we cannot pick just any set of ``bridges'' and call it a natural transformation. The choice of bridges has to be ``natural,'' which means that our choice of bridges has to keep paths through the two figures in lock-step. In other words, we must be able to travel along a morphism in either figure, and it won't matter if we go over the bridge before or after we go down. We'll get to the same place either way.

For instance, in our picture, if we selected our connecting bridges correctly, then it won't matter if we go down $\functor{F}(f)$ in the left figure and then go over the bridge $\natTrans{\alpha}{Y}$, or whether we go over the bridge $\natTrans{\alpha}{X}$ first and then go down $\functor{G}(f)$. Either way, we'll get the same results. In other words, this square of the picture must commute (i.e., both paths through the diagram must be equal):

\begin{diagram}

  \node (FX) at (0, 0) {$\functor{F}(X)$};
  \node (GX) at (4, 0) {$\functor{G}(X)$};
  
  \node (FY) at (-1, -1.5) {$\functor{F}(Y)$};
  \node (GY) at (5, -1.5) {$\functor{G}(Y)$};
  
  \node at (-1, -0.5) {$\functor{F}(f)$};
  \draw[arrow, ->] (FX) to (FY);
  \node at (5, -0.5) {$\functor{G}(f)$};
  \draw[arrow, ->] (GX) to (GY);
  
  \node at (2, -0.25) {$\natTrans{\alpha}{X}$};
  \draw[arrow, ->, dashed] (FX) to (GX);
  \node at (2, -1.75) {$\natTrans{\alpha}{Y}$};
  \draw[arrow, ->, dashed] (FY) to (GY);
  
\end{diagram}

In order to qualify as a natural transformation, our choice of bridges has to be such that \emph{all} such squares in the stack of bridges commute. This requirement is called the naturality condition. It is a fairly strict requirement. It is not always possible to find a natural transformation from one diagram to another. 

% ----------------------------------------
\begin{Definition}[Natural transformations]

Given two diagrams $\functor{F}, \functor{G} : \category{J} \to \category{C}$, a natural transformation $\natTrans{\alpha}{}$ is a family of morphisms $\{ \natTrans{\alpha}{i} : \functor{F}(i) \to \functor{G}(i) \}_{i \in \objects/(\category{J})}$ in $\category{C}$. Each such $\natTrans{\alpha}{i}$ is called a ``component'' of $\natTrans{\alpha}{}$, or the ``$i$-component'' of $\natTrans{\alpha}{}$.

Further, the components of $\natTrans{\alpha}{}$ must be chosen in such a way that they satisfy the following naturality condition. For any morphism $f : X \to Y$ in $\category{J}$, $\natTrans{\alpha}{Y} \compose/ \functor{F}(f)$ = $\functor{G}(f) \compose/ \natTrans{\alpha}{X}$. In other words, for every morphism $f : X \to Y$ in $\category{J}$, the following must commute:

\begin{diagram}

  \node (FX) at (0, 0) {$\functor{F}(X)$};
  \node (GX) at (3, 0) {$\functor{G}(X)$};
  \node (FY) at (0, -3) {$\functor{F}(Y)$};
  \node (GY) at (3, -3) {$\functor{G}(Y)$};

  \draw[arrow, ->] (FX) to (FY);
  \draw[arrow, ->] (GX) to (GY);
  \draw[arrow, ->, dashed] (FX) to (GX);
  \draw[arrow, ->, dashed] (FY) to (GY);
  
  \node at (-0.5, -1.5) {$\functor{F}(f)$};
  \node at (3.5, -1.5) {$\functor{G}(f)$};
  \node at (1.5, -0.25) {$\natTrans{\alpha}{X}$};
  \node at (1.5, -3.25) {$\natTrans{\alpha}{Y}$};

\end{diagram}

\end{Definition}

\begin{Remark}

Given an indexing category $\category{J}$ and another category $\category{C}$, the diagrams (functors) from $\category{J}$ to $\category{C}$ form a category, denoted $\category{C}^{\category{J}}$ or $[\category{J}, \category{C}]$. The objects of the category are the diagrams, and the morphisms are natural transformations. Since functors of the shape $F : \oppCategory{J} \to \category{S}et$ are presheaves, a category of $\category{S}et$-valued diagrams $\category{S}et^{\oppCategory{J}}$ (alternatively written $[\oppCategory{J}, \category{S}et]$) is called a presheaf category, or a category of presheaves.

\end{Remark}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Limits}

\noindent
TODO.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{(Co)Terminals, (Co)Products, (Co)Pullbacks}

\noindent
TODO.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Exponentials}

\noindent
TODO? I think the fibrational setting is easier to describe. Maybe do that instead.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Topos Theory}
\label{sec:topos-theory}

\noindent
In this section, we cover the parts of topos theory that we will utilize in the rest of the paper. Readers familiar with topos theory can skip this section.

A topos is often described as a category that has enough internal structure to it that you can do ``sets''-like reasoning in it. In other words, it has an internal logic that very much resembles the kind of first-order logic that we often model in universes of sets. 

However, it is important to recognize that the key feature of first-order logic is its ability to speak about \emph{subsets} of sets. Indeed, in first-order logic, a predicate $P(x)$ is typically said to hold when $x$ belongs to the subset of things that satisfy $P$. This is why one can say that first-order logic really boils down to a system for reasoning about the ``parts'' of sets (their subsets).

Topos theory generalizes this considerably. Topos theory characterizes categories in which we can reason not just about sets and their ``parts'' (subsets), but about a great variety of other kinds of objects and their ``parts'' (subobjects). In the category $\category{S}et$, the objects are sets, and the ``parts'' or subobjects of a set are its subsets. But in other categories the appropriate ``part'' or subobject might be different. For instance, in the category of directed multi-graphs, the objects are directed multi-graphs, and the ``parts'' or subobjects of such a graph are its subgraphs. 

Whatever sort of objects they may be, if they are the objects of a topos, then the topos has an internal logic that provides a consistent way to reason about those objects and their ``parts'' (subobjects). So, it is perhaps more appropriate to say that a topos is a category that has enough internal structure that we can do ``parts''-like reasoning in it. A topos is a category that has an internal ``parts''-like reasoning system built-in for free.

We will not give a definition of a topos, since the details are not important for our purposes. There are a number of different equivalent definitions of a topos, and all are easy to find in the literature (see, for instance, \cite{Goldblatt:1984}, \cite{MacLaneAndMoerdijk:1994}, or \cite{Borceux:1994}). Here, we will focus on explaining how notions like predicates and logical connectives are realized in the internal logic of a topos.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Subobjects}

\noindent
In the category $\category{S}et$, it is natural to think of a ``part'' of a set as a subset. For example, suppose $D = \{ a, b, c \}$: 

\begin{diagram}

  \node at (-4.75, -2) {$D$};
  \draw (-2.75, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=left:{$a$}] (Da) at (-3.5, -2) {};
  \node[dot, label=left:{$b$}] (Db) at (-2.75, -2) {};
  \node[dot, label=left:{$c$}] (Dc) at (-2, -2) {};

\end{diagram}

Now consider the ``parts'' of $D$.  For instance, take $C = \{ a, b \}$. We can picture the fact that $C$ is a ``part'' of $D$ by drawing a circle around $C$'s elements to make it clear that the elements of $C$ live ``inside'' $D$:

\begin{diagram}

  \node at (-4.75, -2) {$D$};
  \draw[wire2] (-3.25, -2) ellipse (0.825cm and 0.5cm);
  \draw (-2.75, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=left:{$a$}] (Da) at (-3.5, -2) {};
  \node[dot, label=left:{$b$}] (Db) at (-2.75, -2) {};
  \node[dot, label=left:{$c$}] (Dc) at (-2, -2) {};

  \node (C) at (-1.5, -0.5) {$C$};
  \draw[arrow, ->, wire2] (C) to (-2.5, -1.75);

\end{diagram}

Thinking of $C$ as a ``part'' of $D$ in this way is fine, but it is very specific to the way that sets work. We can generalize by thinking about $C$ as an insertion map $i : C \to D$ that injects $C$ into $D$:

\begin{diagram}

  \node at (-4.75, 1) {$C$};
  \draw (-3.25, 1) ellipse (1cm and 0.5cm);
  \node[dot, label=left:{$a$}] (Ca) at (-3.5, 1) {};
  \node[dot, label=left:{$b$}] (Cb) at (-2.75, 1) {};

  \node at (-4.75, -2) {$D$};
  \draw[dashed] (-3.25, -2) ellipse (0.825cm and 0.5cm);
  \draw (-2.75, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=left:{$a$}] (Da) at (-3.5, -2) {};
  \node[dot, label=left:{$b$}] (Db) at (-2.75, -2) {};
  \node[dot, label=left:{$c$}] (Dc) at (-2, -2) {};
  
  \draw[arrow, ->] (Ca) to node[midway, left] {$i$} (Da);
  \draw[arrow, ->] (Cb) to (Db);

\end{diagram}

Once we think of a subset as an insertion map, it becomes clear that the names of the elements in $C$ are irrelevant. In order to pick out the subset $\{ a, b \}$, a function from any two-element set that picks out $a$ and $b$ will do: 

\begin{diagram}

  \draw (-3.125, 1) ellipse (1cm and 0.5cm);
  \node[dot] (Ca) at (-3.5, 1) {};
  \node[dot] (Cb) at (-2.75, 1) {};

  \node at (-4.75, -2) {$D$};
  \draw[dashed] (-3.25, -2) ellipse (0.825cm and 0.5cm);
  \draw (-2.75, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=left:{$a$}] (Da) at (-3.5, -2) {};
  \node[dot, label=left:{$b$}] (Db) at (-2.75, -2) {};
  \node[dot, label=left:{$c$}] (Dc) at (-2, -2) {};
  
  \draw[arrow, ->] (Ca) to node[midway, left] {$i$} (Da);
  \draw[arrow, ->] (Cb) to (Db);

\end{diagram}

Further, we can pick another subset of $D$ with a different insertion map. For instance, we can pick out $\{ b, c \}$ as follows:

\begin{diagram}

  \draw (-3.125, 1) ellipse (1cm and 0.5cm);
  \node[dot] (Ca) at (-3.5, 1) {};
  \node[dot] (Cb) at (-2.75, 1) {};

  \node at (-4.75, -2) {$D$};
  \draw[dashed] (-2.5, -2) ellipse (0.825cm and 0.5cm);
  \draw (-2.75, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=left:{$a$}] (Da) at (-3.5, -2) {};
  \node[dot, label=left:{$b$}] (Db) at (-2.75, -2) {};
  \node[dot, label=left:{$c$}] (Dc) at (-2, -2) {};
  
  \draw[arrow, ->] (Ca) to node[midway, left] {$j$} (Db);
  \draw[arrow, ->] (Cb) to (Dc);

\end{diagram}

The essential feature of an insertion map is that it does not collapse any information. In other words, it is a mere pass-through: i.e., it keeps things distinct and doesn't equate things that aren't already equated. Or, to put it the other way around, if two things aren't already equal, an insertion map won't make them equal. A morphism that has this property is called a monomorphism.


% ----------------------------------------
\begin{Definition}[Monomorphism]

A morphism $i : C \to D$ in $\category{C}$ is a monomorphism iff:

\[
\forall B \in \category{C} \text{ and } \forall f, g : B \to C \in \category{C}, f \not = g \text{ implies } i \compose/ f \not = i \compose/ g.
\]

\noindent
Equivalently:

\[
\forall B \in \category{C} \text{ and } \forall f, g : B \to C \in \category{C}, i \compose/ f = i \compose/ g \text{ implies } f = g.
\]

\end{Definition}


% ----------------------------------------
\begin{Example}

Consider a function $f : B \to C$ that looks like this:

\begin{diagram}

\node at (0, 1.25) {$B$};
\draw (0, -0.125) ellipse (0.5cm and 1cm);
\node[dot, label=below:{$r$}] (r) at (0, 0.5) {};
\node[dot, label=below:{$s$}] (s) at (0, -0.5) {};

\node at (4, 1.25) {$C$};
\draw (4, -0.125) ellipse (0.5cm and 1cm);
\node[dot, label=below:{$t$}] (t) at (4, 0.5) {};
\node[dot, label=below:{$u$}] (u) at (4, -0.5) {};

\node at (2, 1) {\textcolor{wire2}{$f$}};
\draw[arrow, ->, wire2] (r) to (t);
\draw[arrow, ->, wire2] (s) to (u);

\end{diagram}

\noindent
Suppose we also have another, non-equal function $g : B \to C$:

\begin{diagram}

\node at (0, 1.25) {$B$};
\draw (0, -0.125) ellipse (0.5cm and 1cm);
\node[dot, label=below:{$r$}] (r) at (0, 0.5) {};
\node[dot, label=below:{$s$}] (s) at (0, -0.5) {};

\node at (4, 1.25) {$C$};
\draw (4, -0.125) ellipse (0.5cm and 1cm);
\node[dot, label=below:{$t$}] (t) at (4, 0.5) {};
\node[dot, label=below:{$u$}] (u) at (4, -0.5) {};

\node at (2, 1) {\textcolor{wire2}{$f$}};
\draw[arrow, ->, wire2] (r) to (t);
\draw[arrow, ->, wire2] (s) to (u);

\node at (2, -1) {\textcolor{wire3}{$g$}};
\draw[arrow, ->, wire3] (r) to (u);
\draw[arrow, ->, wire3] (s) to (t);

\end{diagram}

\noindent
Since $f$ and $g$ are not equal, they send their inputs to different places. However, if we compose them with a function that collapses points, we can make them send their inputs to the same place. For instance, suppose we follow $f$ and $g$ with the following function $h : C \to D$:

\begin{diagram}

\node at (0, 1.25) {$B$};
\draw (0, -0.125) ellipse (0.5cm and 1cm);
\node[dot, label=below:{$r$}] (r) at (0, 0.5) {};
\node[dot, label=below:{$s$}] (s) at (0, -0.5) {};

\node at (4, 1.25) {$C$};
\draw (4, -0.125) ellipse (0.5cm and 1cm);
\node[dot, label=below:{$t$}] (t) at (4, 0.5) {};
\node[dot, label=below:{$u$}] (u) at (4, -0.5) {};

\node at (8, 1.5) {$D$};
\draw (8, -0.125) ellipse (0.5cm and 1.25cm);
\node[dot, label=below:{$v$}] (v) at (8, 0.75) {};
\node[dot, label=below:{$w$}] (w) at (8, 0) {};
\node[dot, label=below:{$z$}] (z) at (8, -0.75) {};

\node at (2, 1) {\textcolor{wire2}{$f$}};
\draw[arrow, ->, wire2] (r) to (t);
\draw[arrow, ->, wire2] (s) to (u);

\node at (2, -1) {\textcolor{wire3}{$g$}};
\draw[arrow, ->, wire3] (r) to (u);
\draw[arrow, ->, wire3] (s) to (t);

\node at (6, 1) {$h$};
\draw[arrow, ->] (t) to (w);
\draw[arrow, ->] (u) to (w);

\end{diagram}

\noindent
Since, $h$ collapses information --- that is to say, since it sends both $t$ and $u$ to the same output $w$ --- by composing $f$ and $g$ with $h$, we can make them send their inputs to the same place too (namely, $w$). Since we can make a non-equal $f$ and $g$ yield equal results by composing them with $h$, we know that $h$ therefore collapses information, and so $h$ is \emph{not} a monomorphism.

Now consider what happens when we compose $f$ and $g$ with a monomorphism $i : C \to D$:

\begin{diagram}

\node at (0, 1.25) {$B$};
\draw (0, -0.125) ellipse (0.5cm and 1cm);
\node[dot, label=below:{$r$}] (r) at (0, 0.5) {};
\node[dot, label=below:{$s$}] (s) at (0, -0.5) {};

\node at (4, 1.25) {$C$};
\draw (4, -0.125) ellipse (0.5cm and 1cm);
\node[dot, label=below:{$t$}] (t) at (4, 0.5) {};
\node[dot, label=below:{$u$}] (u) at (4, -0.5) {};

\node at (8, 1.5) {$D$};
\draw (8, -0.125) ellipse (0.5cm and 1.25cm);
\node[dot, label=below:{$v$}] (v) at (8, 0.75) {};
\node[dot, label=below:{$w$}] (w) at (8, 0) {};
\node[dot, label=below:{$z$}] (z) at (8, -0.75) {};

\node at (2, 1) {\textcolor{wire2}{$f$}};
\draw[arrow, ->, wire2] (r) to (t);
\draw[arrow, ->, wire2] (s) to (u);

\node at (2, -1) {\textcolor{wire3}{$g$}};
\draw[arrow, ->, wire3] (r) to (u);
\draw[arrow, ->, wire3] (s) to (t);

\node at (6, 1) {$i$};
\draw[arrow, ->] (t) to (v);
\draw[arrow, ->] (u) to (w);

\end{diagram}

\noindent
Here, we can see that $i$ is just a pass-through: it does not collapse any points but rather simply passes on whatever $f$ and $g$ give it, keeping the inputs it receives distinct. So unlike $h$, $i$ cannot ever help $f$ and $g$ send their inputs to the same place. 

Further, we can see that $i$ will behave this way with \emph{any} pair of non-equal morphisms $f$ and $g$: if they already result in distinct outputs, $i$ will keep them distinct. That is what it means for $i$ to be a monomorphism.

\end{Example}

The previous examples were taken from the category $\category{S}et$, but the definition of a monomorphism does not depend on the nature of the sets and functions involved. It works in any category. 

Monomorphisms therefore give us a general way to talk about the subobjects of objects, in any category whatever. We can thus identify the subobjects of any object with the monomorphisms into it.

% ----------------------------------------
\begin{Definition}[Subobject]

Given an object $D$ in a category $\category{C}$, a subobject $i$ of $D$ is a monomorphism $i: C \to D$.

\end{Definition}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Subobject classifiers}

\noindent
A predicate $P$ on o domain $B$ is often defined as a function, let's call it $\characteristic{P}$, from $B$ to $2 = \{ true, false \}$, where elements of $B$ that satisfy the predicate $P$ are sent to ``$true$'' and those that don't are sent to ``$false$.'' For instance, suppose we have a set $B = \{ a, b, c \}$, and a predicate $P$ with $P(a) = true$, $P(b) = true$, and $P(c) = false$. For concreteness, suppose $B$ is the set of students in a class, and $P(x)$ is the predicate expressing that a student is passing the class. As a picture:

\begin{diagram}

  \node at (-4.75, -2) {$B$};
  \draw[dashed] (-3.25, -2) ellipse (0.825cm and 0.5cm);
  \draw (-2.75, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=left:{$a$}] (Ba) at (-3.5, -2) {};
  \node[dot, label=left:{$b$}] (Bb) at (-2.75, -2) {};
  \node[dot, label=left:{$c$}] (Bc) at (-2, -2) {};
  
  \node at (5, -2) {$2$};  
  \draw (3, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=right:{$true$}] (true) at (2, -2) {};
  \node[dot, label=right:{$false$}] (false) at (3.25, -2) {};

  \node at (0, -2) {$\characteristic{P}$};
  \draw[arrow, ->] (Ba) to[out=30, in=145] (true);
  \draw[arrow, ->] (Bb) to[out=45, in=120] (true);
  \draw[arrow, ->] (Bc) to[out=330, in=220] (false);

\end{diagram}

In essence, $\characteristic{P}$ is a characteristic function: it ``classifies'' a subset $A$ of $B$ by telling us which elements of $B$ belong in that subset $A$ and which ones do not. In this case, the subset that gets classified by $\characteristic{P}$ is $A = \{ a, b \}$, i.e., the subset of students who are passing the class. This subset is precisely the extension of the predicate $P$ --- it is the set of elements in $B$ that satisfy the predicate $P$, i.e., the set of students in the class who are passing.

Categorically, we can find $A$ through a pullback. The key feature of a characteristic function like $\characteristic{P}$ is that it sends the elements that it classifies to $true$. So, let's pick out $true$ with a morphism (call it $\top$ for ``true'') from the terminal object $1$ to $2$:

\begin{diagram}

  \node at (3, 1) {$1$};
  \draw (2, 1) ellipse (0.6cm and 0.5cm);
  \node[dot, label=right:{$\ast$}] (1) at (2, 1) {};

  \node at (-4.75, -2) {$B$};
  \draw[dashed] (-3.25, -2) ellipse (0.825cm and 0.5cm);
  \draw (-2.75, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=left:{$a$}] (Ba) at (-3.5, -2) {};
  \node[dot, label=left:{$b$}] (Bb) at (-2.75, -2) {};
  \node[dot, label=left:{$c$}] (Bc) at (-2, -2) {};
  
  \node at (5, -2) {$2$};  
  \draw (3, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=right:{$true$}] (true) at (2, -2) {};
  \node[dot, label=right:{$false$}] (false) at (3.25, -2) {};

  \node at (0, -2) {$\characteristic{P}$};
  \draw[arrow, ->] (Ba) to[out=30, in=145] (true);
  \draw[arrow, ->] (Bb) to[out=45, in=120] (true);
  \draw[arrow, ->] (Bc) to[out=330, in=220] (false);

  \node at (2.25, -0.825) {$\top$};
  \draw[arrow, ->] (1) to (true);  

\end{diagram}

Next, pull back $\top : 1 \to 2$ along $\characteristic{P}$ to get the preimage of $\characteristic{P}$ on $true$:

\begin{diagram}

  \draw[fill=lightgray]
     (2, 0) -- (2, -0.5) -- (-2.25, -0.5) -- (-2.25, -0.75) -- 
     (-2.5, -0.25) -- (-2.25, 0.25) -- (-2.25, 0) -- cycle;
  \node at (0, -0.25) {\textsf{pull back}};

  \node at (-4.75, 1) {$A$};
  \draw (-3.25, 1) ellipse (1cm and 0.5cm);
  \node[dot, label=left:{$a$}] (Aa) at (-3.5, 1) {};
  \node[dot, label=left:{$b$}] (Ab) at (-2.75, 1) {};

  \node at (3, 1) {$1$};
  \draw (2, 1) ellipse (0.6cm and 0.5cm);
  \node[dot, label=right:{$\ast$}] (1) at (2, 1) {};

  \node at (-4.75, -2) {$B$};
  \draw[dashed] (-3.25, -2) ellipse (0.825cm and 0.5cm);
  \draw (-2.75, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=left:{$a$}] (Ba) at (-3.5, -2) {};
  \node[dot, label=left:{$b$}] (Bb) at (-2.75, -2) {};
  \node[dot, label=left:{$c$}] (Bc) at (-2, -2) {};
  
  \node at (5, -2) {$2$};  
  \draw (3, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=right:{$true$}] (true) at (2, -2) {};
  \node[dot, label=right:{$false$}] (false) at (3.25, -2) {};

  \node at (0, -2) {$\characteristic{P}$};
  \draw[arrow, ->] (Ba) to[out=30, in=145] (true);
  \draw[arrow, ->] (Bb) to[out=45, in=120] (true);
  \draw[arrow, ->] (Bc) to[out=330, in=220] (false);

  \draw[arrow, ->] (Aa) to[out=20, in=160] (1);
  \draw[arrow, ->] (Ab) to[out=20, in=160] (1);

  \draw[arrow, ->] (Aa) to (Ba);
  \draw[arrow, ->] (Ab) to (Bb);

  \node at (2.25, -0.825) {$\top$};
  \draw[arrow, ->] (1) to (true);  

\end{diagram}

This gives us another way to think about the predicate $P$. It is the map on the left-hand side of the pullback square that inserts $A$ into $B$. In other words, it is the subobject (monomorphism) on the left-hand side of the pullback. Let's call it $P : A \to B$:

\begin{diagram}

  \draw[fill=lightgray]
     (2, 0) -- (2, -0.5) -- (-2.25, -0.5) -- (-2.25, -0.75) -- 
     (-2.5, -0.25) -- (-2.25, 0.25) -- (-2.25, 0) -- cycle;
  \node at (0, -0.25) {\textsf{pull back}};

  \node at (-4.75, 1) {$A$};
  \draw (-3.25, 1) ellipse (1cm and 0.5cm);
  \node[dot, label=left:{$a$}] (Aa) at (-3.5, 1) {};
  \node[dot, label=left:{$b$}] (Ab) at (-2.75, 1) {};

  \node at (3, 1) {$1$};
  \draw (2, 1) ellipse (0.6cm and 0.5cm);
  \node[dot, label=right:{$\ast$}] (1) at (2, 1) {};

  \node at (-4.75, -2) {$B$};
  \draw[dashed] (-3.25, -2) ellipse (0.825cm and 0.5cm);
  \draw (-2.75, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=left:{$a$}] (Ba) at (-3.5, -2) {};
  \node[dot, label=left:{$b$}] (Bb) at (-2.75, -2) {};
  \node[dot, label=left:{$c$}] (Bc) at (-2, -2) {};
  
  \node at (5, -2) {$2$};  
  \draw (3, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=right:{$true$}] (true) at (2, -2) {};
  \node[dot, label=right:{$false$}] (false) at (3.25, -2) {};

  \node at (0, -2) {$\characteristic{P}$};
  \draw[arrow, ->] (Ba) to[out=30, in=145] (true);
  \draw[arrow, ->] (Bb) to[out=45, in=120] (true);
  \draw[arrow, ->] (Bc) to[out=330, in=220] (false);

  \draw[arrow, ->] (Aa) to[out=20, in=160] (1);
  \draw[arrow, ->] (Ab) to[out=20, in=160] (1);

  \node at (-4, -0.825) {$P$};
  \draw[arrow, ->] (Aa) to (Ba);
  \draw[arrow, ->] (Ab) to (Bb);

  \node at (2.25, -0.825) {$\top$};
  \draw[arrow, ->] (1) to (true);  

\end{diagram}

$P$ and $\characteristic{P}$ give us two perspectives on the same thing. Taken in itself, $P$ identifies a subset of $B$ (e.g., a subset of students in the class). By contrast, $\characteristic{P}$ has more of a logical interpretation: given a student $x$ in $B$, it tells you if they satisfy the predicate $P$ (i.e., it tells you if it is true that they are passing or not). The pullback makes it clear how these two maps --- $P$ and $\characteristic{P}$ --- are essentially related to truth values.

What is crucial about this pullback construction is the object $2$ of truth-values on the right, along with the monomorphism $\top$ that picks out the ``true'' part of $2$. In $\category{S}et$, we can pull back $\top$ along any morphism into $2$ to identify the corresponding predicate on $2$. 

This construction generalizes to other categories beyond $\category{S}et$. In other categories too, it often happens that we have an object of truth values, call it $\Omega$, and a monomorphism $\top : 1 \to \Omega$ that picks out the ``true'' part of $\Omega$, which is such that we can pull back along any morphism into $\Omega$ to get a predicate on it. 


% ----------------------------------------
\begin{Definition}[Subobject Classifier]

In a category $\category{E}$ with a terminal object $1$, a subobject classifier is an object, denoted $\Omega$, along with a morphism $\top : 1 \to \Omega$ which is such that, for any monomorphism $P : A \to B$, there is a unique morphism $\characteristic{P} : B \to \Omega$ that makes the following a pullback:

\begin{diagram}

  \node (A) at (-3, 3) {$A$};
  \node (B) at (-3, 0) {$B$};
  \node (1) at (0, 3) {$1$};
  \node (Omega) at (0, 0) {$\Omega$};

  \draw[arrow, ->] (A) to node[midway, left] {$P$}  (B);
  \draw[arrow, ->] (B) to node[midway, below] {$\characteristic{P}$} (Omega);
  \draw[arrow, ->] (A) to (1);
  \draw[arrow, ->] (1) to node[midway, right] {$\top$} (Omega);

\end{diagram}

\end{Definition}


% ----------------------------------------
\begin{Example}

In $\category{S}et$, as we saw, $\Omega$ is the set of boolean truth values $\{ true, false \}$, with $\top : 1 \to \Omega$ picking out $true$:

\begin{diagram}

  \node at (3, 0) {$1$};
  \draw (2, 0) ellipse (0.6cm and 0.5cm);
  \node[dot, label=right:{$\ast$}] (1) at (2, 0) {};

  \node at (5, -2) {$\Omega$};  
  \draw (3, -2) ellipse (1.5cm and 0.75cm);
  \node[dot, label=right:{$true$}] (true) at (2, -2) {};
  \node[dot, label=right:{$false$}] (false) at (3.25, -2) {};

  \node at (2.25, -0.825) {$\top$};
  \draw[arrow, ->] (1) to (true);  

\end{diagram}

\noindent
Note that $\top$ is a monomorphism. It picks out a genuine subset of $\Omega$: namely $\{ true \} \subseteq \Omega$.

\end{Example}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{An Extended Example}

\noindent
In more complicated categories, the subobject classifier works just as it does in $\category{S}et$, but the set of truth values might be different, and the morphisms may be more complex. This is particularly useful when it is so binary a matter whether something satisfies a predicate.

In this section, we will consider how the subobject classifier works in a category of diagrams. We will omit proofs, and proceed in an expositional style. Readers familiar with subobject classifiers can skip this section.

The diagrams we are interested in here are the ones whose indexing category $\category{J}$ has the following shape:

\begin{diagram}

  \node (E) at (0, 0) {$E$};
  \node (V) at (2, 0) {$V$};
  \draw[arrow, ->] (0.2, 0.1) to node[midway, above] {$s$}  (1.8, 0.1);
  \draw[arrow, ->] (0.2, -0.1) to node[midway, below] {$t$} (1.8, -0.1);

\end{diagram}

$\category{S}et$-valued diagrams of this shape (i.e., functors from $\category{J}$ to $\category{S}et$) correspond to directed multi-graphs. Each such functor sends $E$ to a set of edges, it sends $V$ to a set of vertices, and what it picks for $s$ and $t$ send edges to their respective source and target vertices. For instance, let $F: \category{J} \to \category{S}et$ be given as follows:

\begin{itemize}

\item $F(E) = \{ e_{1}, e_{2} \}$
\item $F(V) = \{ p, q, r \}$
\item $F(s)(e_{1}) = p$, $F(s)(e_{2}) = p$
\item $F(t)(e_{1}) = r$, $F(t)(e_{2}) = q$

\end{itemize}

If we draw that graph, we get this:

\begin{diagram}

  \node at (-3.75, 1) {$F$};
  \draw (-3.5, -0.625) rectangle (-0.5, 1.25);
  \node[dot, label=above:{$p$}] (p) at (-2, 0.5) {};
  \node[dot, label=below:{$q$}] (q) at (-3, 0) {};
  \node[dot, label=below:{$r$}] (r) at (-1, 0) {};
  \draw[arrow, ->] (p) to node[midway, above] {$e_{2}$} (q);
  \draw[arrow, ->] (p) to node[midway, above] {$e_{1}$}  (r);

\end{diagram}

Now suppose we have another functor $G: \category{J} \to \category{S}et$, given as follows:

\begin{itemize}

\item $G(E) = \{ e_{3} \}$
\item $G(V) = \{ w, v \}$
\item $G(s)(e_{3}) = w$
\item $G(t)(e_{3}) = v$

\end{itemize}

If we draw $G$ as a graph, we get this:

\begin{diagram}

  \node at (-3, 0.75) {$G$};
  \draw (-2.75, -0.5) rectangle (-0.25, 1);
  \node[dot, label=above left:{$w$}] (w) at (-2, 0.5) {};
  \node[dot, label=below right:{$v$}] (v) at (-1, 0) {};
  \draw[arrow, ->] (w) to node[midway, above] {$e_{3}$} (v);

\end{diagram}

$G$ can be inserted into $F$ as a subgraph. Since $F$ and $G$ are diagrams in the category $\category{S}et^{\category{J}}$, morphisms between them are natural transformations. Hence, an insertion map $\natTrans{\alpha}{} : G \to F$ will be a natural transformation that inserts $G$ directly into $F$ without collapsing any of $G$. There are two such insertions here, but let us pick the one that sends $w$ to $p$, $v$ to $r$, and $e_{3}$ to $e_{1}$:

\begin{diagram}

  \node at (-3, 3.75) {$G$};
  \draw (-2.75, 2.5) rectangle (-0.25, 4);
  \node[dot, label=above left:{$w$}] (w) at (-2, 3.5) {};
  \node[dot, label=below right:{$v$}] (v) at (-1, 3) {};
  \draw[arrow, ->] (w) to node[midway, above] {$e_{3}$}  (v);

  \node at (-3.75, 1) {$F$};
  \draw (-3.5, -0.625) rectangle (-0.5, 1.25);
  \node[dot, label=below:{$p$}] (p) at (-2, 0.5) {};
  \node[dot, label=below:{$q$}] (q) at (-3, 0) {};
  \node[dot, label=below:{$r$}] (r) at (-1, 0) {};
  \draw[arrow, ->] (p) to node[midway, above] {$e_{2}$} (q);
  \draw[arrow, ->] (p) to node[midway, above] {$e_{1}$} (r);
  
  \draw[dashed, rounded corners=3pt] 
    (-2.5, 1.25) -- (-0.75, 0.25) -- (-0.75, -0.75) -- (-2.5, 0.325) -- (-2.5, 1.25);
  
  \node at (-2.5, 2) {$\natTrans{\alpha}{}$};
  \draw[arrow, ->, wire1] (w) to[out=250, in=110] (p);
  \draw[arrow, ->, wire1] (v) to[out=250, in=110] (r);
  \draw[arrow, ->, wire2] (-1.5, 3.425) to[out=250, in=110] (-1.6, 0.7);
    
\end{diagram}

Now that we have picked out a subobject $G$ of $F$, suppose next that we want to define a predicate $P$ on $F$ whose extension is precisely the subobject $G$. For instance, suppose $F$ describes a fork $p$ on a bike path, with $e_{1}$ going to the park $r$ and $e_{2}$ going to the museum $q$. Given this interpretation of $F$, let us introduce a predicate $P$ that means something like ``is on the route to the park.'' The extension of this predicate is exactly the subgraph $G$.

But how exactly do we define such a predicate, formally? With sets, a predicate takes a point (an element of a set) as input and then it tells you in response whether that point satisfies the predicate or not. More exactly, it takes a point $x$ and returns ``$true$'' or ``$false$,'' depending on whether $x$ is in the extension (subobject) of the predicate.

To do something similar for graphs, we have to generalize:

\begin{itemize}

\item A predicate on sets takes only \emph{one} kind of input (a point in a set), but a predicate on graphs needs to take \emph{two} kinds of inputs (vertices and edges). 

\item A predicate on sets tells you if a point is in the \emph{subset} of the predicate's domain, but a predicate on graphs needs to tell you if a vertex or edge is in the \emph{subgraph} of the predicate's domain.

\item A predicate on sets gives you a binary ``in'' or ``out'' answer (either the point is \emph{in} the predicate's extension or it is \emph{out}), but a predicate on graphs needs to give a more variegated answer:

\begin{itemize}

\item With respect to vertices, a given vertex is either inside or outside of a subgraph.

\item With respect to edges, we have five options:

\begin{itemize}

\item The edge lives entirely outside of the subgraph (its source and target vertices are not part of the subgraph at all). 
\item The edge starts outside the subgraph and ends up inside the subgraph (its source is outside the subgraph, and its target is inside the subgraph).
\item The edge starts inside the subgraph and ends up outside the subgraph (its source is inside the subgraph, but its target is outside the subgraph).
\item The edge travels outside the subgraph and then comes back in (its source and target are inside the subgraph, but the edge itself is outside the subgraph).
\item The edge lives entirely inside the subgraph (its source and target vertices are inside the subgraph, and the edge itself stays inside the subgraph and does not travel outside the subgraph). 

\end{itemize}

\end{itemize}

\end{itemize}

This makes it clear that the logic of graphs is more discriminating than the logic of sets. With a predicate on sets, if you ask it whether a given input satisfies a predicate, it gives you a simple yes or no answer, because the given element either is or is not inside the given subset. This makes sense, of course. There is no more structure to sets than the points, so there is no more to say about the matter beyond stating whether the given point is or is not in the extension of the predicate.

A graph is different. There is much more structure to a directed graph, and so if you ask a predicate whether a given input (a vertex or an edge) satisfies that predicate, it cannot give you such a simple answer. It can tell you whether a given vertex falls inside the extension of the predicate with a yes/no answer, but if you ask it about an edge, it cannot give you a simple yes/no answer. It must instead tell you the degree to which the edge falls inside the extension of the predicate, since an edge can be partly in, partly out, etc.

A simple binary set $\{ true, false \}$ is thus not sufficient to serve as the object of truth values in this category of directed multi-graphs. Instead, $\Omega$ in this category has to look like the following:

\begin{diagram}

  \node at (9.375, 1) {$\Omega$};
  \draw (4, -1.5) rectangle (9, 1.5);
  \node[dot, label=below:{\small{$in$}}] (1) at (5, 0) {};
  \node[dot, label=right:{\small{$out$}}] (0) at (7, 0) {};

  \draw[arrow, ->] 
    (1) 
    to[out=60, in=150, looseness=30]  
    node[midway, above] {\small{$all\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=310, in=210, looseness=30] 
    node[midway, below] {\small{$edge\mhyphen out$}} 
    (1);
  \draw[arrow, ->] 
    (0) 
    to[out=60, in=300, looseness=35] 
    node[midway, above right] {\small{$all\mhyphen out$}} 
    (0);
  \draw[arrow, ->] 
    (0) 
    to[out=160, in=20] 
    node[midway, above] {\small{$ends\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=340, in=200] 
    node[midway, below] {\small{$ends\mhyphen out$}} 
    (0);

\end{diagram}

There are two vertices in this graph, labeled ``$in$'' and ``$out$,'' and they represent whether a given vertex is inside or outside of the given subgraph. There are five edges, each of which represents one of the five options described above:

\begin{itemize}

\item The edge labeled ``$all\mhyphen out$'' represents an edge that is outside the given subgraph and whose vertices are outside it too. Notice that both its source and target vertices are ``$out$,'' i.e., they are vertices that live outside the given subgraph.

\item The edge labeled ``$ends\mhyphen in$'' represents an edge that starts outside the given subgraph and ends inside the subgraph. Notice that its source vertex is ``$out$'' and its target vertex is ``$in$.''

\item The edge labeled ``$ends\mhyphen out$'' represents an edge that starts inside the given subgraph and ends outside the subgraph. Notice that its source vertex is ``$in$'' and its target vertex is ``$out$.''

\item The edge labeled ``$edge\mhyphen out$'' represents an edge that starts inside the given subgraph, travels outside the subgraph, and then travels back in. Notice that its source and target vertices are both ``$in$.''

\item The edge labeled ``$all\mhyphen in$'' represents an edge that lives inside the given subgraph and whose vertices are also inside the subgraph.

\end{itemize}

With this version of $\Omega$, we can classify all of the different ways a vertex or edge in a predicate's domain can be part of a a given subgraph. For instance, consider $F$ and the subgraph $G$:

\begin{diagram}

  \node at (-3.75, 1) {$F$};
  \draw (-3.5, -0.625) rectangle (-0.5, 1.25);
  \node[dot, label=below:{$p$}] (p) at (-2, 0.5) {};
  \node[dot, label=below:{$q$}] (q) at (-3, 0) {};
  \node[dot, label=below:{$r$}] (r) at (-1, 0) {};
  \draw[arrow, ->] (p) to node[midway, above] {$e_{2}$} (q);
  \draw[arrow, ->] (p) to node[midway, above] {$e_{1}$} (r);
  
  \draw[dashed, rounded corners=3pt] 
    (-2.5, 1.25) -- (-0.75, 0.25) -- (-0.75, -0.75) -- (-2.5, 0.325) -- (-2.5, 1.25);

\end{diagram}

With sets, we can define a characteristic morphism into $\Omega$ that ``classifies'' which points in the predicate's domain belong in the given subset. But in this setting, how do we define a characteristic morphism $\characteristic{\alpha}$ into $\Omega$ that ``classifies'' which parts of $F$ belong in $G$?

\begin{diagram}

  \node at (-3.75, 1) {$F$};
  \draw (-3.5, -0.625) rectangle (-0.5, 1.25);
  \node[dot, label=below:{$p$}] (p) at (-2, 0.5) {};
  \node[dot, label=below:{$q$}] (q) at (-3, 0) {};
  \node[dot, label=below:{$r$}] (r) at (-1, 0) {};
  \draw[arrow, ->] (p) to node[midway, above] {$e_{2}$} (q);
  \draw[arrow, ->] (p) to node[midway, above] {$e_{1}$} (r);
  
  \draw[dashed, rounded corners=3pt] 
    (-2.5, 1.25) -- (-0.75, 0.25) -- (-0.75, -0.75) -- (-2.5, 0.325) -- (-2.5, 1.25);

  \node at (9.375, 1) {$\Omega$};
  \draw (4, -1.5) rectangle (9, 1.5);
  \node[dot, label=below:{\small{$in$}}] (1) at (5, 0) {};
  \node[dot, label=right:{\small{$out$}}] (0) at (7, 0) {};

  \draw[arrow, ->] 
    (1) 
    to[out=60, in=150, looseness=30]  
    node[midway, above] {\small{$all\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=310, in=210, looseness=30] 
    node[midway, below] {\small{$edge\mhyphen out$}} 
    (1);
  \draw[arrow, ->] 
    (0) 
    to[out=60, in=300, looseness=35] 
    node[midway, above right] {\small{$all\mhyphen out$}} 
    (0);
  \draw[arrow, ->] 
    (0) 
    to[out=160, in=20] 
    node[midway, above] {\small{$ends\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=340, in=200] 
    node[midway, below] {\small{$ends\mhyphen out$}} 
    (0);

  \draw[arrow, ->, wire2] (0, 0.5) to node[midway, below] {$\characteristic{\alpha}?$} (3.5, 0.5);

\end{diagram}

First, we send the vertices $p$ and $r$ to ``$in$'' (since they are inside $G$) and we send the vertex $q$ to ``$out$,'' since it is outside $G$:

\begin{diagram}

  \node at (-3.75, 1) {$F$};
  \draw (-3.5, -0.625) rectangle (-0.5, 1.25);
  \node[dot, label=below:{$p$}] (p) at (-2, 0.5) {};
  \node[dot, label=below:{$q$}] (q) at (-3, 0) {};
  \node[dot, label=below:{$r$}] (r) at (-1, 0) {};
  \draw[arrow, ->] (p) to node[midway, above] {$e_{2}$} (q);
  \draw[arrow, ->] (p) to node[midway, above] {$e_{1}$} (r);
  
  \draw[dashed, rounded corners=3pt] 
    (-2.5, 1.25) -- (-0.75, 0.25) -- (-0.75, -0.75) -- (-2.5, 0.325) -- (-2.5, 1.25);

  \node at (9.375, 1) {$\Omega$};
  \draw (4, -1.5) rectangle (9, 1.5);
  \node[dot, label=below:{\small{$in$}}] (1) at (5, 0) {};
  \node[dot, label=right:{\small{$out$}}] (0) at (7, 0) {};

  \draw[arrow, ->] 
    (1) 
    to[out=60, in=150, looseness=30]  
    node[midway, above] {\small{$all\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=310, in=210, looseness=30] 
    node[midway, below] {\small{$edge\mhyphen out$}} 
    (1);
  \draw[arrow, ->] 
    (0) 
    to[out=60, in=300, looseness=35] 
    node[midway, above right] {\small{$all\mhyphen out$}} 
    (0);
  \draw[arrow, ->] 
    (0) 
    to[out=160, in=20] 
    node[midway, above] {\small{$ends\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=340, in=200] 
    node[midway, below] {\small{$ends\mhyphen out$}} 
    (0);

  \node at (2, -0.25) {$\characteristic{\alpha}$};
  \draw[arrow, ->, wire1] (q) to[out=340, in=240] (0);
  \draw[arrow, ->, wire1] (p) to[out=20, in=160] (1);
  \draw[arrow, ->, wire1] (r) to[out=10, in=170] (1);

\end{diagram}

Hence, by this classification, $p$ and $r$ fall under the extension of the predicate, while $q$ does not. This matches what we expect. Is the fork $p$ on the route to the park (i.e., does $P(p)$ hold)? Yes, and the same goes for the park $q$ ($P(q)$ holds). But the museum $q$ is not on the route to the park, so $P(q)$ does not hold.

Next, we send $e_{1}$ to ``$all\mhyphen in$'' because it lives inside $G$:

\begin{diagram}

  \node at (-3.75, 1) {$F$};
  \draw (-3.5, -0.625) rectangle (-0.5, 1.25);
  \node[dot, label=below:{$p$}] (p) at (-2, 0.5) {};
  \node[dot, label=below:{$q$}] (q) at (-3, 0) {};
  \node[dot, label=below:{$r$}] (r) at (-1, 0) {};
  \draw[arrow, ->] (p) to node[midway, above] {$e_{2}$} (q);
  \draw[arrow, ->] (p) to node[midway, above] {$e_{1}$} (r);
  
  \draw[dashed, rounded corners=3pt] 
    (-2.5, 1.25) -- (-0.75, 0.25) -- (-0.75, -0.75) -- (-2.5, 0.325) -- (-2.5, 1.25);

  \node at (9.375, 1) {$\Omega$};
  \draw (4, -1.5) rectangle (9, 1.5);
  \node[dot, label=below:{\small{$in$}}] (1) at (5, 0) {};
  \node[dot, label=right:{\small{$out$}}] (0) at (7, 0) {};

  \draw[arrow, ->] 
    (1) 
    to[out=60, in=150, looseness=30]  
    node[midway, above] {\small{$all\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=310, in=210, looseness=30] 
    node[midway, below] {\small{$edge\mhyphen out$}} 
    (1);
  \draw[arrow, ->] 
    (0) 
    to[out=60, in=300, looseness=35] 
    node[midway, above right] {\small{$all\mhyphen out$}} 
    (0);
  \draw[arrow, ->] 
    (0) 
    to[out=160, in=20] 
    node[midway, above] {\small{$ends\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=340, in=200] 
    node[midway, below] {\small{$ends\mhyphen out$}} 
    (0);

  \node at (2, -0.25) {$\characteristic{\alpha}$};
  \draw[arrow, ->, wire1] (q) to[out=340, in=240] (0);
  \draw[arrow, ->, wire1] (p) to[out=20, in=160] (1);
  \draw[arrow, ->, wire1] (r) to[out=10, in=170] (1);
  \draw[arrow, ->, wire2] (-1.4, 0.5) to[out=30, in=160] (4.425, 1);

\end{diagram}

This matches our intuitions about the meaning of the predicate ``is on the route to the park'' too. Since $e_{1}$ is the path from the fork $p$ to the park $r$, it makes sense that $P(e_{1})$ holds.

Finally, we send $e_{2}$ to ``$ends\mhyphen out$'' because although it begins \emph{inside} of $G$ (at $p$), it leaves $G$ and ends up outside of $G$ (at $q$):

\begin{diagram}

  \node at (-3.75, 1) {$F$};
  \draw (-3.5, -0.625) rectangle (-0.5, 1.25);
  \node[dot, label=below:{$p$}] (p) at (-2, 0.5) {};
  \node[dot, label=below:{$q$}] (q) at (-3, 0) {};
  \node[dot, label=below:{$r$}] (r) at (-1, 0) {};
  \draw[arrow, ->] (p) to node[midway, above] {$e_{2}$} (q);
  \draw[arrow, ->] (p) to node[midway, above] {$e_{1}$} (r);
  
  \draw[dashed, rounded corners=3pt] 
    (-2.5, 1.25) -- (-0.75, 0.25) -- (-0.75, -0.75) -- (-2.5, 0.325) -- (-2.5, 1.25);

  \node at (9.375, 1) {$\Omega$};
  \draw (4, -1.5) rectangle (9, 1.5);
  \node[dot, label=below:{\small{$in$}}] (1) at (5, 0) {};
  \node[dot, label=right:{\small{$out$}}] (0) at (7, 0) {};

  \draw[arrow, ->] 
    (1) 
    to[out=60, in=150, looseness=30]  
    node[midway, above] {\small{$all\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=310, in=210, looseness=30] 
    node[midway, below] {\small{$edge\mhyphen out$}} 
    (1);
  \draw[arrow, ->] 
    (0) 
    to[out=60, in=300, looseness=35] 
    node[midway, above right] {\small{$all\mhyphen out$}} 
    (0);
  \draw[arrow, ->] 
    (0) 
    to[out=160, in=20] 
    node[midway, above] {\small{$ends\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=340, in=200] 
    node[midway, below] {\small{$ends\mhyphen out$}} 
    (0);

  \node at (2, -0.25) {$\characteristic{\alpha}$};
  \draw[arrow, ->, wire1] (q) to[out=340, in=240] (0);
  \draw[arrow, ->, wire1] (p) to[out=20, in=160] (1);
  \draw[arrow, ->, wire1] (r) to[out=10, in=170] (1);
  \draw[arrow, ->, wire2] (-1.4, 0.5) to[out=30, in=160] (4.425, 1);
  \draw[arrow, ->, wire2] (-2.5, 0.2) to[out=325, in=230] (6.175, -0.625);

\end{diagram}

This also classifies $e_{2}$ appropriately. Does the path to the museum fall on the route to the park? Well, the beginning part of it does, at the fork $p$. But after that, it does not. So $P(e_{2})$ does not hold unequivocally. But nor does it fail to hold unequivocally. The edge $e_{2}$ is classified as being partly in and partly out of the extension of the predicate.

What is the unequivocal ``true'' part of $\Omega$? That is to say, what is the subobject of $\Omega$ that represents ``true'' unequivocally? With sets, we pick out the ``$\{ true \}$'' subobject of $\Omega$ with a monomorphism from the terminal object $1$. In this category, the terminal object is the one-vertex graph with a single edge:

\begin{diagram}

  \node at (5.75, 3.75) {$1$};
  \draw (4.5, 2.5) rectangle (5.5, 4);
  \node[dot, label=below:{$\ast$}] (term_1) at (5, 3) {};
  \draw[arrow, ->] (term_1) to[out=50, in=130, looseness=30] (term_1);

\end{diagram}

The $\top$ monomorphism from $1$ into $\Omega$ has to pick out the ``true'' subobject of $\Omega$, but in this case that means it will have to pick out the subgraph of $\Omega$ that represents when a given input (vertex or edge) is unequivocally inside the extension of the predicate. 

Some of the possible cases represented by $\Omega$ are not entirely ``in'' the extension of the predicate, e.g. when an edge is partly in, and partly out. The only \emph{unequivocal} case is when an edge and both of its vertices are \emph{entirely} inside the given subgraph. Thus, $\top$ must pick out the subgraph consisting of the vertex labeled ``$in$'' and the edge labeled ``$all\mhyphen in$'': 

\begin{diagram}

  \node at (5.75, 3.75) {$1$};
  \draw (4.5, 2.5) rectangle (5.5, 4);
  \node[dot, label=below:{$\ast$}] (term_1) at (5, 3) {};
  \draw[arrow, ->] (term_1) to[out=50, in=130, looseness=30] (term_1);

  \node at (9.375, 1) {$\Omega$};
  \draw (4, -1.5) rectangle (9, 1.5);
  \node[dot, label=below:{\small{$in$}}] (1) at (5, 0) {};
  \node[dot, label=right:{\small{$out$}}] (0) at (7, 0) {};
  
  \node at (5.825, 1.875) {$\top$};
  \draw[arrow, ->, wire1] (5, 2.625) to[out=265, in=105] (1);
  \draw[arrow, ->, wire2] (5.25, 3.25) to[out=300, in=60] (5.25, 1);
  
  \draw[arrow, ->] 
    (1) 
    to[out=60, in=150, looseness=30]  
    node[midway, above] {\small{$all\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=310, in=210, looseness=30] 
    node[midway, below] {\small{$edge\mhyphen out$}} 
    (1);
  \draw[arrow, ->] 
    (0) 
    to[out=60, in=300, looseness=35] 
    node[midway, above right] {\small{$all\mhyphen out$}} 
    (0);
  \draw[arrow, ->] 
    (0) 
    to[out=160, in=20] 
    node[midway, above] {\small{$ends\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=340, in=200] 
    node[midway, below] {\small{$ends\mhyphen out$}} 
    (0);

  \draw[dashed, rounded corners=5pt]
    (5, -0.575) -- (5.425, -0.25) -- (5.425, 1.25) -- (4.175, 1.25) -- (4.175, -0.25) -- (5, -0.575);

\end{diagram}

\noindent
This is the subobject classifier for the category at hand, and it yields the correct characteristic morphisms when we pull $\top$ back. For instance, in the case of $F$ and $G$:

\begin{diagram}

  \node at (-3, 3.75) {$G$};
  \draw (-2.75, 2.5) rectangle (-0.25, 4);
  \node[dot, label=above left:{$w$}] (w) at (-2, 3.5) {};
  \node[dot, label=below right:{$v$}] (v) at (-1, 3) {};
  \draw[arrow, ->] (w) to (v);

  \node at (5.75, 3.75) {$1$};
  \draw (4.5, 2.5) rectangle (5.5, 4);
  \node[dot, label=below:{$\ast$}] (term_1) at (5, 3) {};
  \draw[arrow, ->] (term_1) to[out=50, in=130, looseness=30] (term_1);

  \node at (-3.75, 1) {$F$};
  \draw (-3.5, -0.625) rectangle (-0.5, 1.25);
  \node[dot, label=above left:{$p$}] (p) at (-2, 0.5) {};
  \node[dot, label=below:{$q$}] (q) at (-3, 0) {};
  \node[dot, label=below:{$r$}] (r) at (-1, 0) {};
  \draw[arrow, ->] (p) to (q);
  \draw[arrow, ->] (p) to (r);
  
  \draw[dashed, rounded corners=3pt] 
    (-2.5, 1.25) -- (-0.75, 0.25) -- (-0.75, -0.75) -- (-2.5, 0.325) -- (-2.5, 1.25);

  \node at (9.375, 1) {$\Omega$};
  \draw (4, -1.5) rectangle (9, 1.5);
  \node[dot, label=below:{\small{$in$}}] (1) at (5, 0) {};
  \node[dot, label=right:{\small{$out$}}] (0) at (7, 0) {};
  
  \draw[arrow, ->, wire1] (w) to[out=10, in=160] (term_1);
  \draw[arrow, ->, wire1] (v) to[out=5, in=170] (term_1);
  \draw[arrow, ->, wire2] (-1.5, 3.4) to[out=15, in=160] (4.7, 3.5);
 
  \node at (5.825, 1.875) {$\top$};
  \draw[arrow, ->, wire1] (5, 2.625) to[out=265, in=105] (1);
  \draw[arrow, ->, wire2] (5.25, 3.25) to[out=300, in=60] (5.25, 1);

  \node at (-2.5, 2) {$\natTrans{\alpha}{}$};
  \draw[arrow, ->, wire1] (w) to[out=250, in=110] (p);
  \draw[arrow, ->, wire1] (v) to[out=250, in=110] (r);
  \draw[arrow, ->, wire2] (-1.5, 3.25) to[out=250, in=110] (-1.6, 0.4);
  
  \node at (2, -0.25) {$\characteristic{\alpha}$};
  \draw[arrow, ->, wire1] (q) to[out=340, in=240] (0);
  \draw[arrow, ->, wire1] (p) to[out=20, in=160] (1);
  \draw[arrow, ->, wire1] (r) to[out=10, in=170] (1);
  \draw[arrow, ->, wire2] (-1.6, 0.3) to[out=30, in=160] (4.425, 1);
  \draw[arrow, ->, wire2] (-2.5, 0.2) to[out=325, in=230] (6.175, -0.625);
  
  \draw[arrow, ->] 
    (1) 
    to[out=60, in=150, looseness=30]  
    node[midway, above] {\small{$all\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=310, in=210, looseness=30] 
    node[midway, below] {\small{$edge\mhyphen out$}} 
    (1);
  \draw[arrow, ->] 
    (0) 
    to[out=60, in=300, looseness=35] 
    node[midway, above right] {\small{$all\mhyphen out$}} 
    (0);
  \draw[arrow, ->] 
    (0) 
    to[out=160, in=20] 
    node[midway, above] {\small{$ends\mhyphen in$}} 
    (1);
  \draw[arrow, ->] 
    (1) 
    to[out=340, in=200] 
    node[midway, below] {\small{$ends\mhyphen out$}} 
    (0);

  \draw[dashed, rounded corners=5pt]
    (5, -0.575) -- (5.425, -0.25) -- (5.425, 1.25) -- (4.175, 1.25) -- (4.175, -0.25) -- (5, -0.575);

\end{diagram}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Logical Connectives}

\noindent
In a topos, predicates are realized as characteristic morphisms into the subobject classifier $\Omega$. A characteristic arrow, say, $\characteristic{\alpha}$, ``classifies'' or identifies a subobject $\alpha$ as a par tof the predicate's domain. Logical connectives generally take one or more such things and say whether they are true in combination.

For example, suppose we have $P(r)$ and $Q(s)$. The connective ``$and$'' takes $P$ and $Q$ and tells us whether they are both true together. In a topos, this is realized as a morphism $and : \Omega \times \Omega \to \Omega$. 

Specifically, start with the product of $\Omega$, namely $\Omega \times \Omega$. Since ``$and$'' requires that both conjuncts are true, take the pairing $\tuple{\top, \top} : 1 \to \Omega \times \Omega$, i.e., the morphism from the terminal object $1$ that picks out the ``true'' part of both sides of $\Omega \times \Omega$:

\begin{diagram}

  \node (1) at (2, 1) {$1$};

  \node (omega-times-omega) at (2, -2) {$\Omega \times \Omega$};

  \node (omega-times-omega-2) at (-3, -2) {$\Omega \times \Omega$};

  \draw[arrow, ->] (1) to node[midway, right] {$\tuple{\top, \top}$} (omega-times-omega);

\end{diagram}

This is just like $\top : 1 \to \Omega$, which picks out the ``true'' part of $\Omega$, except $\tuple{\top, \top}$ goes to the \emph{product} of $\Omega$, and so it picks out both ``true'' parts.

Next, suppose we have $\tuple{\pi_{1}, \pi_{2}}$, where $\pi_{1}$ is the first projection and $\pi_{2}$ is the second projection:

\begin{diagram}

  \node (1) at (2, 1) {$1$};

  \node (omega-times-omega) at (2, -2) {$\Omega \times \Omega$};

  \node (omega-times-omega-2) at (-3, -2) {$\Omega \times \Omega$};

  \draw[arrow, ->] (1) to node[midway, right] {$\tuple{\top, \top}$} (omega-times-omega);

  \draw[arrow, ->] 
    (omega-times-omega-2) 
    to node[midway, below] {$\tuple{\pi_{1}, \pi_{2}}$} 
    (omega-times-omega);

\end{diagram}

Now, pull pack $\tuple{\top, \top}$ along $\tuple{\pi_{1}, \pi_{2}}$ to find the pre-image $T$:

\begin{diagram}

  \draw[fill=lightgray]
     (2, 0) -- (2, -0.5) -- (-2.25, -0.5) -- (-2.25, -0.75) -- 
     (-2.5, -0.25) -- (-2.25, 0.25) -- (-2.25, 0) -- cycle;
  \node at (0, -0.25) {\textsf{pull back}};

  \node (1) at (2, 1) {$1$};

  \node (omega-times-omega) at (2, -2) {$\Omega \times \Omega$};

  \node (omega-times-omega-2) at (-3, -2) {$\Omega \times \Omega$};
  
  \node (T) at (-3, 1) {$T$};

  \draw[arrow, ->] (1) to node[midway, right] {$\tuple{\top, \top}$} (omega-times-omega);

  \draw[arrow, ->] 
    (omega-times-omega-2) 
    to node[midway, below] {$\tuple{\pi_{1}, \pi_{2}}$} 
    (omega-times-omega);

  \draw[arrow, ->] (T) to node[midway, left] {$i$} (omega-times-omega-2);

  \draw[arrow, ->] (T) to (1);

\end{diagram}

Since we pulled back from $\tuple{\top, \top}$, we end up with a monomorphism $i : T \to \Omega \times \Omega$ that inserts exactly the subobject of $\Omega \times \Omega$ that is ``true'' in both components.

But note that $i$ is itself a subobject, i.e., it inserts $T$ into $\Omega \times \Omega$. In a topos, there is always a unique morphism $\characteristic{i}$ that characterizes this subobject, and we can obtain it by pulling back $\top$. Hence, if we start with the subobject classifier:

\begin{diagram}

  \node (1) at (2, 1) {$1$};

  \node (omega) at (2, -2) {$\Omega$};

  \draw[arrow, ->] (1) to node[midway, right] {$\top$} (omega);

\end{diagram}

We can then get $\characteristic{i}$ by pulling back to $i: T \to \Omega \times \Omega$:

\begin{diagram}

  \draw[fill=lightgray]
     (2, 0) -- (2, -0.5) -- (-2.25, -0.5) -- (-2.25, -0.75) -- 
     (-2.5, -0.25) -- (-2.25, 0.25) -- (-2.25, 0) -- cycle;
  \node at (0, -0.25) {\textsf{pull back}};

  \node (1) at (2, 1) {$1$};

  \node (omega) at (2, -2) {$\Omega$};

  \node (omega-times-omega-2) at (-3, -2) {$\Omega \times \Omega$};
  
  \node (T) at (-3, 1) {$T$};

  \draw[arrow, ->] (1) to node[midway, right] {$\top$} (omega);

  \draw[arrow, ->] 
    (omega-times-omega-2) 
    to node[midway, below] {$\characteristic{i}$} 
    (omega);

  \draw[arrow, ->] (T) to node[midway, left] {$i$} (omega-times-omega-2);

  \draw[arrow, ->] (T) to (1);

\end{diagram}

Since $\characteristic{i}$ classifies $T$, and $T$ is the subject of $\Omega \times \Omega$ that has ``true'' in both components, it follows that $\characteristic{i}$ just is the ``$and$'' morphism: it characterizes logical conjunction. In other words, we might as well rename $i$ to $and$, since it picks out ``both true components,'' and then we can rename $\characteristic{i}$ to $\characteristic{and}$.


% ----------------------------------------
\begin{Definition}[Conjunction]

Conjunction is classified by $\characteristic{and} : \Omega \times \Omega \to \Omega$, where $and : T \to \Omega \times \Omega$ is obtained by pulling back $\tuple{\top, \top}: 1 \to \Omega \times \Omega$ along $\tuple{\pi_{1}, \pi_{2}} : \Omega \times \Omega \to \Omega \times \Omega$.

\end{Definition}


% ----------------------------------------
\begin{Example}

In $\category{S}et$, conjunction has a well-known truth table: a conjunction is true when both conjuncts are true. Thus, we need to identify the subobject of $\Omega \times \Omega$ that has both components true. To construct this, start with the product of $\Omega$:

\begin{diagram}

  \node at (5.75, -4) {$\Omega \times \Omega$};
  \draw (3.5, -2.875) ellipse (2.25cm and 1.5cm);
  \node[dot, label=below:{$\tuple{true, true}$}] (omega-11) at (2.5, -2) {};
  \node[dot, label=below:{$\tuple{true, false}$}] (omega-10) at (4.5, -2) {};
  \node[dot, label=above:{$\tuple{false, true}$}] (omega-01) at (2.5, -3.5) {};
  \node[dot, label=above:{$\tuple{false, false}$}] (omega-00) at (4.5, -3.5) {};

\end{diagram}

Use $\tuple{\top, \top}$ from the terminal object $1$ to select $\{ true, true \}$:

\begin{diagram}

  \node at (3.5, 1) {$1$};
  \draw (2.6, 1) ellipse (0.5cm and 0.4cm);
  \node[dot, label=right:{$\ast$}] (ast) at (2.5, 1) {};

  \node at (5.75, -4) {$\Omega \times \Omega$};
  \draw (3.5, -2.875) ellipse (2.25cm and 1.5cm);
  \node[dot, label=below:{$\tuple{true, true}$}] (omega-11) at (2.5, -2) {};
  \node[dot, label=below:{$\tuple{true, false}$}] (omega-10) at (4.5, -2) {};
  \node[dot, label=above:{$\tuple{false, true}$}] (omega-01) at (2.5, -3.5) {};
  \node[dot, label=above:{$\tuple{false, false}$}] (omega-00) at (4.5, -3.5) {};

  \draw[arrow, ->] (ast) to node[midway, right] {$\tuple{\top, \top}$} (omega-11);

\end{diagram}

To get the preimage/subobject of $\tuple{\top, \top}$, pull back:

\begin{diagram}

  \draw[fill=lightgray]
     (2.5, 0) -- (2.5, -0.5) -- (-1.75, -0.5) -- (-1.75, -0.75) -- 
     (-2, -0.25) -- (-1.75, 0.25) -- (-1.75, 0) -- cycle;
  \node at (0, -0.25) {\textsf{pull back}};

  \node at (-5, 1) {$T$};
  \draw (-3.375, 1) ellipse (1.25cm and 0.5cm);
  \node[dot, label=left:{$\tuple{true, true}$}] (T-11) at (-2.5, 1) {};

  \node at (3.5, 1) {$1$};
  \draw (2.6, 1) ellipse (0.5cm and 0.4cm);
  \node[dot, label=right:{$\ast$}] (ast) at (2.5, 1) {};

  \node at (-5.75, -4) {$\Omega \times \Omega$};
  \draw (-3.5, -2.875) ellipse (2.25cm and 1.5cm);
  \node[dot, label=below:{$\tuple{true, true}$}] (omega-b-11) at (-2.5, -2) {};
  \node[dot, label=below:{$\tuple{true, false}$}] (omega-b-10) at (-4.5, -2) {};
  \node[dot, label=above:{$\tuple{false, true}$}] (omega-b-01) at (-2.5, -3.5) {};
  \node[dot, label=above:{$\tuple{false, false}$}] (omega-b-00) at (-4.5, -3.5) {};

  \node at (5.75, -4) {$\Omega \times \Omega$};
  \draw (3.5, -2.875) ellipse (2.25cm and 1.5cm);
  \node[dot, label=below:{$\tuple{true, true}$}] (omega-11) at (2.5, -2) {};
  \node[dot, label=below:{$\tuple{true, false}$}] (omega-10) at (4.5, -2) {};
  \node[dot, label=above:{$\tuple{false, true}$}] (omega-01) at (2.5, -3.5) {};
  \node[dot, label=above:{$\tuple{false, false}$}] (omega-00) at (4.5, -3.5) {};

  \draw[arrow, ->] (T-11) to (ast);
  \draw[arrow, ->] (T-11) to node[midway, left] {$and$} (omega-b-11);
  \draw[arrow, ->] (ast) to node[midway, right] {$\tuple{\top, \top}$} (omega-11);

  \node at (0, -2.875) {$\tuple{\pi_{1}, \pi_{2}}$};
  \draw[arrow, ->] (omega-b-11) to[out=10, in=170] (omega-11);
  \draw[arrow, ->] (omega-b-10) to[out=10, in=170] (omega-10);
  \draw[arrow, ->] (omega-b-01) to[out=350, in=190] (omega-01);
  \draw[arrow, ->] (omega-b-00) to[out=350, in=190] (omega-00);

\end{diagram}

That yields the subobject/monomorphism that picks out $\tuple{true, true}$:

\begin{diagram}

  \node at (-5, 1) {$T$};
  \draw (-3.375, 1) ellipse (1.25cm and 0.5cm);
  \node[dot, label=left:{$\tuple{true, true}$}] (T-11) at (-2.5, 1) {};

  \node at (-5.75, -4) {$\Omega \times \Omega$};
  \draw (-3.5, -2.875) ellipse (2.25cm and 1.5cm);
  \node[dot, label=below:{$\tuple{true, true}$}] (omega-b-11) at (-2.5, -2) {};
  \node[dot, label=below:{$\tuple{true, false}$}] (omega-b-10) at (-4.5, -2) {};
  \node[dot, label=above:{$\tuple{false, true}$}] (omega-b-01) at (-2.5, -3.5) {};
  \node[dot, label=above:{$\tuple{false, false}$}] (omega-b-00) at (-4.5, -3.5) {};
  \draw[dashed] (-2.5, -2.25) ellipse (1.175cm and 0.5cm);

  \draw[arrow, ->] (T-11) to node[midway, left] {$and$} (omega-b-11);

\end{diagram}

Then, to get the characteristic morphism for ``$and$,'' take the subobject classifier:

\begin{diagram}

  \node at (3.5, 1) {$1$};
  \draw (2.6, 1) ellipse (0.5cm and 0.4cm);
  \node[dot, label=right:{$\ast$}] (ast) at (2.5, 1) {};

  \node at (5.75, -2.5) {$\Omega$};
  \draw (3.5, -2.175) ellipse (2cm and 0.75cm);
  \node[dot, label=below:{$true$}] (omega-1) at (2.5, -2) {};
  \node[dot, label=below:{$false$}] (omega-0) at (4.5, -2) {};

  \draw[arrow, ->] (ast) to node[midway, right] {$\top$} (omega-11);

\end{diagram}

Then pull back to get the desired characteristic morphism:

\begin{diagram}

  \draw[fill=lightgray]
     (2.5, 0) -- (2.5, -0.5) -- (-1.75, -0.5) -- (-1.75, -0.75) -- 
     (-2, -0.25) -- (-1.75, 0.25) -- (-1.75, 0) -- cycle;
  \node at (0, -0.25) {\textsf{pull back}};

  \node at (-5, 1) {$T$};
  \draw (-3.375, 1) ellipse (1.25cm and 0.5cm);
  \node[dot, label=left:{$\tuple{true, true}$}] (T-11) at (-2.5, 1) {};

  \node at (3.5, 1) {$1$};
  \draw (2.6, 1) ellipse (0.5cm and 0.4cm);
  \node[dot, label=right:{$\ast$}] (ast) at (2.5, 1) {};

  \node at (-5.75, -4) {$\Omega \times \Omega$};
  \draw (-3.5, -2.875) ellipse (2.25cm and 1.5cm);
  \node[dot, label=below:{$\tuple{true, true}$}] (omega-b-11) at (-2.5, -2) {};
  \node[dot, label=below:{$\tuple{true, false}$}] (omega-b-10) at (-4.5, -2) {};
  \node[dot, label=above:{$\tuple{false, true}$}] (omega-b-01) at (-2.5, -3.5) {};
  \node[dot, label=above:{$\tuple{false, false}$}] (omega-b-00) at (-4.5, -3.5) {};
  \draw[dashed] (-2.5, -2.25) ellipse (1.175cm and 0.5cm);

  \node at (5.75, -2.5) {$\Omega$};
  \draw (3.5, -2.175) ellipse (2cm and 0.75cm);
  \node[dot, label=below:{$true$}] (omega-1) at (2.5, -2) {};
  \node[dot, label=below:{$false$}] (omega-0) at (4.5, -2) {};

  \draw[arrow, ->] (T-11) to (ast);
  \draw[arrow, ->] (T-11) to node[midway, left] {$and$} (omega-b-11);
  \draw[arrow, ->] (ast) to node[midway, right] {$\top$} (omega-11);

  \node at (0, -2.5) {$\characteristic{and}$};
  \draw[arrow, ->] (omega-b-11) to[out=10, in=170] (omega-1);
  \draw[arrow, ->] (omega-b-10) to[out=10, in=170] (omega-0);
  \draw[arrow, ->] (omega-b-01) to[out=350, in=200] (omega-0);
  \draw[arrow, ->] (omega-b-00) to[out=350, in=210] (omega-0);

\end{diagram}

This construction can be repeated in any topos to yield the $\characteristic{and}$ morphism.

\end{Example}

Other connectives can be constructed in similar ways. We will not go into that here, but for details, see any of the standard references already mentioned.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The Internal Language of the Topos}

\noindent
TODO



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Mereological Reasoning in Toposes}
\label{sec:logic-in-toposes}

\noindent
TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Parts and Wholes, Logically}

\noindent
TODO: define wholes in the internal language, and define the parthood relation in the internal language. Formulate some definitions like overlap.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Mereological Logics For Free}
\label{sec:mereology-logics}

\noindent
TODO: prove some theorems like reflexivity, antisymmetry, and transitivity. discuss supplementation? extensionality? atoms?


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section{Materials and Methods}

% Materials and Methods should be described with sufficient details to allow others to replicate and build on published results. Please note that publication of your manuscript implicates that you must make all materials, data, computer code, and protocols associated with the publication available to readers. Please disclose at the submission stage any restrictions on the availability of materials or information. New methods and protocols should be described in detail while well-established methods can be briefly described and appropriately cited.

% In this section, where applicable, authors are required to disclose details of how gen-erative artificial intelligence (GenAI) has been used in this paper (e.g., to generate text, data, or graphics, or to assist in study design, data collection, analysis, or interpretation). The use of GenAI for superficial text editing (e.g., grammar, spelling, punctuation, and formatting) does not need to be declared.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}

TODO


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{6pt} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\authorcontributions{For research articles with several authors, a short paragraph specifying their individual contributions must be provided. The following statements should be used ``Conceptualization, X.X. and Y.Y.; methodology, X.X.; software, X.X.; validation, X.X., Y.Y. and Z.Z.; formal analysis, X.X.; investigation, X.X.; resources, X.X.; data curation, X.X.; writing---original draft preparation, X.X.; writing---review and editing, X.X.; visualization, X.X.; supervision, X.X.; project administration, X.X.; funding acquisition, Y.Y. All authors have read and agreed to the published version of the manuscript.'', please turn to the  \href{http://img.mdpi.org/data/contributor-role-instruction.pdf}{CRediT taxonomy} for the term explanation. Authorship must be limited to those who have contributed substantially to the work~reported.}

\funding{This research received no external funding.}

\acknowledgments{In this section you can acknowledge any support given which is not covered by the author contribution or funding sections. This may include administrative and technical support, or donations in kind (e.g., materials used for experiments). Where GenAI has been used for purposes such as generating text, data, or graphics, or for study design, data collection, analysis, or interpretation of data, please add During the preparation of this manuscript/study, the author(s) used [tool name, version information] for the purposes of [description of use]. The authors have reviewed and edited the output and take full responsibility for the content of this publication.}

\conflictsofinterest{The authors declare no conflicts of interest.} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Optional

% \abbreviations{Abbreviations}{
% The following abbreviations are used in this manuscript:
% \\

% \noindent 
% \begin{tabular}{@{}ll}
% MDPI & Multidisciplinary Digital Publishing Institute\\
% DOAJ & Directory of open access journals\\
% TLA & Three letter acronym\\
% LD & Linear dichroism
% \end{tabular}
% }


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\isPreprints{}{% This command is only used for ``preprints''.
\begin{adjustwidth}{-\extralength}{0cm}
%} % If the paper is ``preprints'', please uncomment this parenthesis.
%\printendnotes[custom] % Un-comment to print a list of endnotes

\reftitle{References}

% Please provide the correct journal abbreviation (e.g. according to the List of Title Word Abbreviations http://www.issn.org/services/online-services/access-to-the-ltwa/).

%=====================================
% References, variant A: external bibliography
%=====================================
\bibliography{references}

%=====================================
% References, variant B: internal bibliography
%=====================================

% ACS format
% \begin{thebibliography}{999}
% Reference 1
% \bibitem{ref-journal}
% Author~1, T. The title of the cited article. {\em Journal Abbreviation} {\bf 2008}, {\em 10}, 142--149.
% Reference 2
% \bibitem{ref-book1}
% Author~2, L. The title of the cited contribution. In {\em The Book Title}; Editor 1, F., Editor 2, A., Eds.; % Publishing House: City, Country, 2007; pp. 32--58.
% Reference 3
% \bibitem{ref-book2}
% Author 1, A.; Author 2, B. \textit{Book Title}, 3rd ed.; Publisher: Publisher Location, Country, 2008; pp. 154--196.
% Reference 4
% \bibitem{ref-unpublish}
% Author 1, A.B.; Author 2, C. Title of Unpublished Work. \textit{Abbreviated Journal Name} year, \textit{phrase indicating stage of publication (submitted; accepted; in press)}.
% Reference 5
% \bibitem{ref-url}
% Title of Site. Available online: URL (accessed on Day Month Year).
% Reference 6
% \bibitem{ref-proceeding}
% Author 1, A.B.; Author 2, C.D.; Author 3, E.F. Title of presentation. In Proceedings of the Name of the Conference, Location of Conference, Country, Date of Conference (Day Month Year); Abstract Number (optional), Pagination (optional).
% Reference 7
% \bibitem{ref-thesis}
% Author 1, A.B. Title of Thesis. Level of Thesis, Degree-Granting University, Location of University, Date of Completion.
% \end{thebibliography}

% For the MDPI journals use author-date citation, please follow the formatting guidelines on http://www.mdpi.com/authors/references
% To cite two works by the same author: \citeauthor{ref-journal-1a} (\citeyear{ref-journal-1a}, \citeyear{ref-journal-1b}). This produces: Whittaker (1967, 1975)
% To cite two works by the same author with specific pages: \citeauthor{ref-journal-3a} (\citeyear{ref-journal-3a}, p. 328; \citeyear{ref-journal-3b}, p.475). This produces: Wong (1999, p. 328; 2000, p. 475)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\PublishersNote{}
%\isPreprints{}{% This command is only used for ``preprints''.
\end{adjustwidth}
%} % If the paper is ``preprints'', please uncomment this parenthesis.
\end{document}

